<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>io7m-r2 0.2.0 Documentation</title><meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/><link rel="stylesheet" type="text/css" href="kstructural-layout.css"/><link rel="stylesheet" type="text/css" href="kstructural-colour.css"/><link rel="stylesheet" type="text/css" href="documentation.css"/></head><body><div class="st300_body"><div class="st300_document_title">io7m-r2 0.2.0 Documentation</div><ul class="st300_contents st300_document_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_part"><a href="#st300_p1" title="Link to part 1: Package Information">1. Package Information</a><ul class="st300_contents st300_part_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p1s1" title="Link to section 1.1: Orientation">1.1. Orientation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p1s2" title="Link to section 1.2: Installation">1.2. Installation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p1s3" title="Link to section 1.3: Platform Specific Issues">1.3. Platform Specific Issues</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p1s4" title="Link to section 1.4: License">1.4. License</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_part"><a href="#st300_p2" title="Link to part 2: Design And Implementation">2. Design And Implementation</a><ul class="st300_contents st300_part_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s1" title="Link to section 2.1: Conventions">2.1. Conventions</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s2" title="Link to section 2.2: Concepts">2.2. Concepts</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s3" title="Link to section 2.3: Coordinate Systems">2.3. Coordinate Systems</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s4" title="Link to section 2.4: Meshes">2.4. Meshes</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s5" title="Link to section 2.5: Transforms">2.5. Transforms</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s6" title="Link to section 2.6: Instances">2.6. Instances</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s7" title="Link to section 2.7: Render Targets">2.7. Render Targets</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s8" title="Link to section 2.8: Shaders">2.8. Shaders</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s9" title="Link to section 2.9: Shaders: Instance">2.9. Shaders: Instance</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s10" title="Link to section 2.10: Shaders: Light">2.10. Shaders: Light</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s11" title="Link to section 2.11: Stencils">2.11. Stencils</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s12" title="Link to section 2.12: Lighting">2.12. Lighting</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s13" title="Link to section 2.13: Lighting: Directional">2.13. Lighting: Directional</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s14" title="Link to section 2.14: Lighting: Spherical">2.14. Lighting: Spherical</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s15" title="Link to section 2.15: Lighting: Projective">2.15. Lighting: Projective</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s16" title="Link to section 2.16: Shadows">2.16. Shadows</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s17" title="Link to section 2.17: Shadows: Variance Mapping">2.17. Shadows: Variance Mapping</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s18" title="Link to section 2.18: Deferred Rendering">2.18. Deferred Rendering</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s19" title="Link to section 2.19: Deferred Rendering: Geometry">2.19. Deferred Rendering: Geometry</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s20" title="Link to section 2.20: Deferred Rendering: Lighting">2.20. Deferred Rendering: Lighting</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s21" title="Link to section 2.21: Deferred Rendering: Position Reconstruction">2.21. Deferred Rendering: Position Reconstruction</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s22" title="Link to section 2.22: Forward rendering (Translucency)">2.22. Forward rendering (Translucency)</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s23" title="Link to section 2.23: Normal Mapping">2.23. Normal Mapping</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s24" title="Link to section 2.24: Logarithmic Depth">2.24. Logarithmic Depth</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s25" title="Link to section 2.25: Environment Mapping">2.25. Environment Mapping</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s26" title="Link to section 2.26: Stippling">2.26. Stippling</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s27" title="Link to section 2.27: Generic Refraction">2.27. Generic Refraction</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s28" title="Link to section 2.28: Filter: Fog">2.28. Filter: Fog</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s29" title="Link to section 2.29: Filter: Screen Space Ambient Occlusion">2.29. Filter: Screen Space Ambient Occlusion</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s30" title="Link to section 2.30: Filter: Emission">2.30. Filter: Emission</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p2s31" title="Link to section 2.31: Filter: FXAA">2.31. Filter: FXAA</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_part"><a href="#st300_p3" title="Link to part 3: API Documentation">3. API Documentation</a><ul class="st300_contents st300_part_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_section"><a href="#st300_p3s1" title="Link to section 3.1: API Documentation">3.1. API Documentation</a></li></ul></li></ul><div class="st300_part_container"><a id="pkg"/><div class="st300_part_title_number"><a id="st300_p1" href="#st300_p1" title="Part 1: Package Information">1</a></div><div class="st300_part_title">Package Information</div><ul class="st300_contents st300_part_contents_outer st300_part_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p1s1" title="Link to section 1.1: Orientation">1.1. Orientation</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p1s1ss1" title="Link to subsection 1.1.1: Overview">1.1.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p1s1ss2" title="Link to subsection 1.1.2: Features">1.1.2. Features</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p1s2" title="Link to section 1.2: Installation">1.2. Installation</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p1s2ss1" title="Link to subsection 1.2.1: Source compilation">1.2.1. Source compilation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p1s2ss2" title="Link to subsection 1.2.2: Maven">1.2.2. Maven</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p1s3" title="Link to section 1.3: Platform Specific Issues">1.3. Platform Specific Issues</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p1s4" title="Link to section 1.4: License">1.4. License</a></li></ul><div class="st300_section_container"><a id="pkg.orientation"/><div class="st300_section_title_number"><a id="st300_p1s1" href="#st300_p1s1" title="Section 1.1: Orientation">1.1</a></div><div class="st300_section_title">Orientation</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p1s1ss1" title="Link to subsection 1.1.1: Overview">1.1.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p1s1ss2" title="Link to subsection 1.1.2: Features">1.1.2. Features</a></li></ul><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p1s1ss1" href="#st300_p1s1ss1" title="Subsection 1.1.1: Overview">1.1.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s1ss1c1" href="#st300_p1s1ss1c1" title="Paragraph 1.1.1.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package provides a minimalist deferred rendering system.</div></div></div><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p1s1ss2" href="#st300_p1s1ss2" title="Subsection 1.1.2: Features">1.1.2</a></div><div class="st300_subsection_title">Features</div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p1s1ss2c1" href="#st300_p1s1ss2c1" title="Formal item 1.1.2.1: Features">1.1.2.1 Features</a></div><div class="st300_formal_item_content"><ul class="st300_list_unordered"><li class="st300_list_item">A <span class="st300_term term">deferred rendering</span> core for <span class="st300_term term">opaque</span> objects.</li><li class="st300_list_item">A <span class="st300_term term">forward renderer</span>, supporting a subset of the features of the <span class="st300_term term">deferred renderer</span>, for rendering <span class="st300_term term">translucent</span> objects.</li><li class="st300_list_item">A full dynamic lighting system, including <span class="st300_term term">variance</span> shadow mapping. The use of <span class="st300_term term">deferred rendering</span> allows for potentially hundreds of dynamic lights per scene.</li><li class="st300_list_item">Ready-to-use shaders providing surfaces with a wide variety of effects such as <span class="st300_term term">normal mapping</span>, <span class="st300_term term">environment-mapped reflections</span>, <span class="st300_term term">generic refraction</span>, <span class="st300_term term">surface emission</span>, <span class="st300_term term">mapped specular highlights</span>, etc.</li><li class="st300_list_item">A variety of postprocessing effects such as <span class="st300_term term">box blurring</span>, <span class="st300_term term">screen-space ambient occlusion (SSAO)</span>, <span class="st300_term term">fast approximate antialiasing (FXAA)</span>, <span class="st300_term term">color correction</span>, <span class="st300_term term">bloom</span>, etc. Effects can be applied in any order.</li><li class="st300_list_item">Explicit control over all resource loading and caching. For all <span class="st300_term term">transient</span> resources, the programmer is required to provide the renderer with explicit <span class="st300_term term">pools</span>, and the pools themselves are responsible for allocating and loading resources.</li><li class="st300_list_item">Extensive use of static types. As with all <a class="st300_link_external" href="http://io7m.com">io7m</a> packages, there is extreme emphasis on using the type system to make it difficult to use the APIs incorrectly.</li><li class="st300_list_item">Portability. The renderer will run on any system supporting OpenGL <span class="st300_term constant">3.3</span> and Java 8.</li></ul></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p1s1ss2c2" href="#st300_p1s1ss2c2" title="Formal item 1.1.2.2: Non-features">1.1.2.2 Non-features</a></div><div class="st300_formal_item_content"><ul class="st300_list_unordered"><li class="st300_list_item">A scene graph. The renderer expects the programmer to provide a set of <span class="st300_term term">instances</span> (with associated <span class="st300_term term">shaders</span>) and <span class="st300_term term">lights</span> once per frame, and the renderer will obediently draw exactly those instances. This frees the programmer from having to interact with a clumsy and type-unsafe object-oriented scene graph as with other 3D engines, and from having to try to crowbar their own program's data structures into an existing graph system.</li><li class="st300_list_item">Spatial partitioning. The renderer knows nothing of the world the programmer is trying to render. The programmer is expected to have done the work of deciding which <span class="st300_term term">instances</span> and <span class="st300_term term">lights</span> contribute to the current image, and to provide only those <span class="st300_term term">lights</span> and <span class="st300_term term">instances</span> for the current frame. This means that the programmer is free to use any spatial partitioning system desired.</li><li class="st300_list_item">Input handling. The renderer knows nothing about keyboards, mice, joysticks. The programmer passes an immutable snapshot of a scene to the renderer, and the renderer returns an image. This means that the programmer is free to use any input system desired without having to painfully integrate their own code with an existing input system as with other 3D engines.</li><li class="st300_list_item">Audio. The renderer makes images, not sounds. This allows programmers to use any audio system they want in their programs.</li><li class="st300_list_item">Skeletal animation. The input to the renderer is a set of triangle <span class="st300_term term">meshes</span> in the form of <span class="st300_term term">vertex buffer objects</span>. This means that the programmer is free to use any skeletal animation system desired, providing that the system is capable of producing <span class="st300_term term">vertex buffer objects</span> of the correct type as a result.</li><li class="st300_list_item">Model loading. The input to the renderer is a set of triangle <span class="st300_term term">meshes</span> in the form of <span class="st300_term term">vertex buffer objects</span>. This means that the programmer is free to use any model loading system desired, providing that the system is capable of producing <span class="st300_term term">vertex buffer objects</span> of the correct type as a result.</li><li class="st300_list_item">Future proofing. The average lifetime of a rendering system is about five years. Due to the extremely rapid pace of advancement in graphics hardware, the methods use to render graphics <span class="st300_term term">today</span> will bear almost no relation to those used five years into the future. The <span class="st300_term package">r2</span> package is under no illusion that it will still be relevant in a decade's time. It is designed to get work done <span class="st300_term term">today</span>, using exactly those techniques that are relevant <span class="st300_term term">today</span>. It will not be indefinitely expanded and grown organically, as this would directly contradict the goal of having a <span class="st300_term term">minimalist</span> and <span class="st300_term term">correct</span> rendering system.</li><li class="st300_list_item">OpenGL ES 2 support. The ES 2 standard was written as a reaction to the insane committee politics that plagued the OpenGL 2.* standards. It is crippled to the point that it essentially cannot support almost any of the rendering techniques present in the <span class="st300_term package">r2</span> package, and is becoming increasingly irrelevant as the much saner ES 3 is adopted by hardware vendors.</li></ul></div></div></div></div><div class="st300_section_container"><a id="pkg.install"/><div class="st300_section_title_number"><a id="st300_p1s2" href="#st300_p1s2" title="Section 1.2: Installation">1.2</a></div><div class="st300_section_title">Installation</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p1s2ss1" title="Link to subsection 1.2.1: Source compilation">1.2.1. Source compilation</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p1s2ss2" title="Link to subsection 1.2.2: Maven">1.2.2. Maven</a></li></ul><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p1s2ss1" href="#st300_p1s2ss1" title="Subsection 1.2.1: Source compilation">1.2.1</a></div><div class="st300_subsection_title">Source compilation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s2ss1c1" href="#st300_p1s2ss1c1" title="Paragraph 1.2.1.1">1</a></div><div class="st300_paragraph">The project can be compiled and installed with <a class="st300_link_external" href="http://maven.apache.org">Maven</a>:</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s2ss1c2" href="#st300_p1s2ss1c2" title="Paragraph 1.2.1.2">2</a></div><div class="st300_paragraph"><pre class="st300_verbatim example">$ mvn -C clean install</pre></div></div></div><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p1s2ss2" href="#st300_p1s2ss2" title="Subsection 1.2.2: Maven">1.2.2</a></div><div class="st300_subsection_title">Maven</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s2ss2c1" href="#st300_p1s2ss2c1" title="Paragraph 1.2.2.1">1</a></div><div class="st300_paragraph">Regular releases are made to the <a class="st300_link_external" href="http://search.maven.org/#search%7Cga%7C1%7Cio7m-r2">Central Repository</a>, so it's possible to use the <span class="st300_term package">io7m-r2</span> package in your projects with the following Maven dependencies:</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s2ss2c2" href="#st300_p1s2ss2c2" title="Paragraph 1.2.2.2">2</a></div><div class="st300_paragraph"><pre class="st300_verbatim example">&lt;dependency&gt;
  &lt;groupId&gt;com.io7m.r2&lt;/groupId&gt;
  &lt;artifactId&gt;io7m-r2-main&lt;/artifactId&gt;
  &lt;version&gt;0.2.0&lt;/version&gt;
&lt;/dependency&gt;</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s2ss2c3" href="#st300_p1s2ss2c3" title="Paragraph 1.2.2.3">3</a></div><div class="st300_paragraph">All <a class="st300_link_external" href="http://io7m.com">io7m.com</a> packages use Semantic Versioning <span class="st300_footnote_reference">[<a href="#st300_f_906_0" id="st300_fr_864" title="Jump to footnote semver (reference 0)">0</a>]</span>, which implies that it is always safe to use version ranges with an exclusive upper bound equal to the next major version - the API of the package will not change in a backwards-incompatible manner before the next major version.</div></div></div></div><div class="st300_section_container"><a id="pkg.platform"/><div class="st300_section_title_number"><a id="st300_p1s3" href="#st300_p1s3" title="Section 1.3: Platform Specific Issues">1.3</a></div><div class="st300_section_title">Platform Specific Issues</div><span/><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s3ss2c1" href="#st300_p1s3ss2c1" title="Paragraph 1.3.2.1">1</a></div><div class="st300_paragraph">There are currently no known platform-specific issues.</div></div></div><div class="st300_section_container"><a id="pkg.license"/><div class="st300_section_title_number"><a id="st300_p1s4" href="#st300_p1s4" title="Section 1.4: License">1.4</a></div><div class="st300_section_title">License</div><span/><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p1s4ss2c1" href="#st300_p1s4ss2c1" title="Paragraph 1.4.2.1">1</a></div><div class="st300_paragraph">All files distributed with the <span class="st300_term package">io7m-r2</span> package are placed under the following license: <pre class="st300_verbatim license">Copyright © 2016 &lt;code@io7m.com&gt; http://io7m.com

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.</pre></div></div></div></div><div class="st300_part_container"><a id="di"/><div class="st300_part_title_number"><a id="st300_p2" href="#st300_p2" title="Part 2: Design And Implementation">2</a></div><div class="st300_part_title">Design And Implementation</div><ul class="st300_contents st300_part_contents_outer st300_part_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s1" title="Link to section 2.1: Conventions">2.1. Conventions</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s1ss1" title="Link to subsection 2.1.1: Overview">2.1.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s1ss2" title="Link to subsection 2.1.2: Mathematics">2.1.2. Mathematics</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s2" title="Link to section 2.2: Concepts">2.2. Concepts</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss1" title="Link to subsection 2.2.1: Overview">2.2.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss2" title="Link to subsection 2.2.2: Renderer">2.2.2. Renderer</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss3" title="Link to subsection 2.2.3: Render Target">2.2.3. Render Target</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss4" title="Link to subsection 2.2.4: Geometry Buffer">2.2.4. Geometry Buffer</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss5" title="Link to subsection 2.2.5: Light Buffer">2.2.5. Light Buffer</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss6" title="Link to subsection 2.2.6: Mesh">2.2.6. Mesh</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss7" title="Link to subsection 2.2.7: Transform">2.2.7. Transform</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss8" title="Link to subsection 2.2.8: Instance">2.2.8. Instance</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss9" title="Link to subsection 2.2.9: Light">2.2.9. Light</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss10" title="Link to subsection 2.2.10: Light Clip Group">2.2.10. Light Clip Group</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss11" title="Link to subsection 2.2.11: Light Group">2.2.11. Light Group</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss12" title="Link to subsection 2.2.12: Shader">2.2.12. Shader</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s2ss13" title="Link to subsection 2.2.13: Material">2.2.13. Material</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s3" title="Link to section 2.3: Coordinate Systems">2.3. Coordinate Systems</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss1" title="Link to subsection 2.3.1: Conventions">2.3.1. Conventions</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss2" title="Link to subsection 2.3.2: Object Space">2.3.2. Object Space</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss3" title="Link to subsection 2.3.3: World Space">2.3.3. World Space</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss4" title="Link to subsection 2.3.4: Eye Space">2.3.4. Eye Space</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss5" title="Link to subsection 2.3.5: Clip Space">2.3.5. Clip Space</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss6" title="Link to subsection 2.3.6: Normalized-Device Space">2.3.6. Normalized-Device Space</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s3ss7" title="Link to subsection 2.3.7: Screen Space">2.3.7. Screen Space</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s4" title="Link to section 2.4: Meshes">2.4. Meshes</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s4ss1" title="Link to subsection 2.4.1: Overview">2.4.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s4ss2" title="Link to subsection 2.4.2: Attributes">2.4.2. Attributes</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s4ss3" title="Link to subsection 2.4.3: Types">2.4.3. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s5" title="Link to section 2.5: Transforms">2.5. Transforms</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s5ss1" title="Link to subsection 2.5.1: Overview">2.5.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s5ss2" title="Link to subsection 2.5.2: Types">2.5.2. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s6" title="Link to section 2.6: Instances">2.6. Instances</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s6ss1" title="Link to subsection 2.6.1: Overview">2.6.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s6ss2" title="Link to subsection 2.6.2: Single">2.6.2. Single</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s6ss3" title="Link to subsection 2.6.3: Batched">2.6.3. Batched</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s6ss4" title="Link to subsection 2.6.4: Billboarded">2.6.4. Billboarded</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s6ss5" title="Link to subsection 2.6.5: Types">2.6.5. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s7" title="Link to section 2.7: Render Targets">2.7. Render Targets</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s7ss1" title="Link to subsection 2.7.1: Overview">2.7.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s7ss2" title="Link to subsection 2.7.2: Types">2.7.2. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s8" title="Link to section 2.8: Shaders">2.8. Shaders</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s8ss1" title="Link to subsection 2.8.1: Overview">2.8.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s8ss2" title="Link to subsection 2.8.2: Interface And Calling Protocol">2.8.2. Interface And Calling Protocol</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s8ss3" title="Link to subsection 2.8.3: Shader Modules">2.8.3. Shader Modules</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s8ss4" title="Link to subsection 2.8.4: Types">2.8.4. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s9" title="Link to section 2.9: Shaders: Instance">2.9. Shaders: Instance</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s9ss1" title="Link to subsection 2.9.1: Overview">2.9.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s9ss2" title="Link to subsection 2.9.2: Materials">2.9.2. Materials</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s9ss3" title="Link to subsection 2.9.3: Provided Shaders">2.9.3. Provided Shaders</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s9ss4" title="Link to subsection 2.9.4: Types">2.9.4. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s10" title="Link to section 2.10: Shaders: Light">2.10. Shaders: Light</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s10ss1" title="Link to subsection 2.10.1: Overview">2.10.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s10ss2" title="Link to subsection 2.10.2: Types">2.10.2. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s11" title="Link to section 2.11: Stencils">2.11. Stencils</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s11ss1" title="Link to subsection 2.11.1: Overview">2.11.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s11ss2" title="Link to subsection 2.11.2: Reserved Bits">2.11.2. Reserved Bits</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s11ss3" title="Link to subsection 2.11.3: Allow Bit">2.11.3. Allow Bit</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s12" title="Link to section 2.12: Lighting">2.12. Lighting</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s12ss1" title="Link to subsection 2.12.1: Overview">2.12.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s12ss2" title="Link to subsection 2.12.2: Diffuse/Specular Terms">2.12.2. Diffuse/Specular Terms</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s12ss3" title="Link to subsection 2.12.3: Diffuse-Only Lights">2.12.3. Diffuse-Only Lights</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s12ss4" title="Link to subsection 2.12.4: Attenuation">2.12.4. Attenuation</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s13" title="Link to section 2.13: Lighting: Directional">2.13. Lighting: Directional</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s13ss1" title="Link to subsection 2.13.1: Overview">2.13.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s13ss2" title="Link to subsection 2.13.2: Attenuation">2.13.2. Attenuation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s13ss3" title="Link to subsection 2.13.3: Application">2.13.3. Application</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s13ss4" title="Link to subsection 2.13.4: Types">2.13.4. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s14" title="Link to section 2.14: Lighting: Spherical">2.14. Lighting: Spherical</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s14ss1" title="Link to subsection 2.14.1: Overview">2.14.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s14ss2" title="Link to subsection 2.14.2: Attenuation">2.14.2. Attenuation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s14ss3" title="Link to subsection 2.14.3: Application">2.14.3. Application</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s14ss4" title="Link to subsection 2.14.4: Types">2.14.4. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s15" title="Link to section 2.15: Lighting: Projective">2.15. Lighting: Projective</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s15ss1" title="Link to subsection 2.15.1: Overview">2.15.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s15ss2" title="Link to subsection 2.15.2: Algorithm">2.15.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s15ss3" title="Link to subsection 2.15.3: Back projection">2.15.3. Back projection</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s15ss4" title="Link to subsection 2.15.4: Clamping">2.15.4. Clamping</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s15ss5" title="Link to subsection 2.15.5: Attenuation">2.15.5. Attenuation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s15ss6" title="Link to subsection 2.15.6: Application">2.15.6. Application</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s16" title="Link to section 2.16: Shadows">2.16. Shadows</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s16ss1" title="Link to subsection 2.16.1: Overview">2.16.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s16ss2" title="Link to subsection 2.16.2: Shadow Geometry">2.16.2. Shadow Geometry</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s17" title="Link to section 2.17: Shadows: Variance Mapping">2.17. Shadows: Variance Mapping</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s17ss1" title="Link to subsection 2.17.1: Overview">2.17.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s17ss2" title="Link to subsection 2.17.2: Algorithm">2.17.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s17ss3" title="Link to subsection 2.17.3: Advantages">2.17.3. Advantages</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s17ss4" title="Link to subsection 2.17.4: Disadvantages">2.17.4. Disadvantages</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s17ss5" title="Link to subsection 2.17.5: Types">2.17.5. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s18" title="Link to section 2.18: Deferred Rendering">2.18. Deferred Rendering</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s18ss1" title="Link to subsection 2.18.1: Overview">2.18.1. Overview</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s19" title="Link to section 2.19: Deferred Rendering: Geometry">2.19. Deferred Rendering: Geometry</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s19ss1" title="Link to subsection 2.19.1: Overview">2.19.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s19ss2" title="Link to subsection 2.19.2: Groups">2.19.2. Groups</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s19ss3" title="Link to subsection 2.19.3: Geometry Buffer">2.19.3. Geometry Buffer</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s19ss4" title="Link to subsection 2.19.4: Algorithm">2.19.4. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s19ss5" title="Link to subsection 2.19.5: Ordering/Batching">2.19.5. Ordering/Batching</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s19ss6" title="Link to subsection 2.19.6: Normal Compression">2.19.6. Normal Compression</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s20" title="Link to section 2.20: Deferred Rendering: Lighting">2.20. Deferred Rendering: Lighting</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s20ss1" title="Link to subsection 2.20.1: Overview">2.20.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s20ss2" title="Link to subsection 2.20.2: Light Buffer">2.20.2. Light Buffer</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s20ss3" title="Link to subsection 2.20.3: Light Clip Volumes">2.20.3. Light Clip Volumes</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s20ss4" title="Link to subsection 2.20.4: Types">2.20.4. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s21" title="Link to section 2.21: Deferred Rendering: Position Reconstruction">2.21. Deferred Rendering: Position Reconstruction</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s21ss1" title="Link to subsection 2.21.1: Overview">2.21.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s21ss2" title="Link to subsection 2.21.2: Recovering Eye space Z">2.21.2. Recovering Eye space Z</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s21ss3" title="Link to subsection 2.21.3: Recovering Eye space Z (Logarithmic depth encoding)">2.21.3. Recovering Eye space Z (Logarithmic depth encoding)</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s21ss4" title="Link to subsection 2.21.4: Recovering Eye space Z (Screen space depth encoding)">2.21.4. Recovering Eye space Z (Screen space depth encoding)</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s21ss5" title="Link to subsection 2.21.5: Recovering Eye space Position">2.21.5. Recovering Eye space Position</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s21ss6" title="Link to subsection 2.21.6: Implementation">2.21.6. Implementation</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s22" title="Link to section 2.22: Forward rendering (Translucency)">2.22. Forward rendering (Translucency)</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss1" title="Link to subsection 2.22.1: Overview">2.22.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss2" title="Link to subsection 2.22.2: Instances">2.22.2. Instances</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss3" title="Link to subsection 2.22.3: Blending">2.22.3. Blending</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss4" title="Link to subsection 2.22.4: Culling">2.22.4. Culling</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss5" title="Link to subsection 2.22.5: Ordering">2.22.5. Ordering</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss6" title="Link to subsection 2.22.6: Types">2.22.6. Types</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s22ss7" title="Link to subsection 2.22.7: Provided Shaders">2.22.7. Provided Shaders</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s23" title="Link to section 2.23: Normal Mapping">2.23. Normal Mapping</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s23ss1" title="Link to subsection 2.23.1: Overview">2.23.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s23ss2" title="Link to subsection 2.23.2: Tangent Space">2.23.2. Tangent Space</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s23ss3" title="Link to subsection 2.23.3: Tangent/Bitangent Generation">2.23.3. Tangent/Bitangent Generation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s23ss4" title="Link to subsection 2.23.4: Normal Maps">2.23.4. Normal Maps</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s23ss5" title="Link to subsection 2.23.5: Rendering With Normal Maps">2.23.5. Rendering With Normal Maps</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s24" title="Link to section 2.24: Logarithmic Depth">2.24. Logarithmic Depth</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s24ss1" title="Link to subsection 2.24.1: Overview">2.24.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s24ss2" title="Link to subsection 2.24.2: OpenGL Depth Issues">2.24.2. OpenGL Depth Issues</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s24ss3" title="Link to subsection 2.24.3: Logarithmic Encoding">2.24.3. Logarithmic Encoding</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s25" title="Link to section 2.25: Environment Mapping">2.25. Environment Mapping</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s25ss1" title="Link to subsection 2.25.1: Overview">2.25.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s25ss2" title="Link to subsection 2.25.2: Cube Maps">2.25.2. Cube Maps</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s25ss3" title="Link to subsection 2.25.3: Reflections">2.25.3. Reflections</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s25ss4" title="Link to subsection 2.25.4: Handedness">2.25.4. Handedness</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s26" title="Link to section 2.26: Stippling">2.26. Stippling</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s26ss1" title="Link to subsection 2.26.1: Overview">2.26.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s26ss2" title="Link to subsection 2.26.2: Algorithm">2.26.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s26ss3" title="Link to subsection 2.26.3: Types">2.26.3. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s27" title="Link to section 2.27: Generic Refraction">2.27. Generic Refraction</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss1" title="Link to subsection 2.27.1: Overview">2.27.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss2" title="Link to subsection 2.27.2: Algorithm">2.27.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss3" title="Link to subsection 2.27.3: Sources">2.27.3. Sources</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss4" title="Link to subsection 2.27.4: Vectors">2.27.4. Vectors</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss5" title="Link to subsection 2.27.5: Colors">2.27.5. Colors</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss6" title="Link to subsection 2.27.6: Masking">2.27.6. Masking</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s27ss7" title="Link to subsection 2.27.7: Types">2.27.7. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s28" title="Link to section 2.28: Filter: Fog">2.28. Filter: Fog</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s28ss1" title="Link to subsection 2.28.1: Overview">2.28.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s28ss2" title="Link to subsection 2.28.2: Algorithm">2.28.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s28ss3" title="Link to subsection 2.28.3: Types">2.28.3. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s29" title="Link to section 2.29: Filter: Screen Space Ambient Occlusion">2.29. Filter: Screen Space Ambient Occlusion</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss1" title="Link to subsection 2.29.1: Overview">2.29.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss2" title="Link to subsection 2.29.2: Ambient Occlusion Buffer">2.29.2. Ambient Occlusion Buffer</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss3" title="Link to subsection 2.29.3: Algorithm">2.29.3. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss4" title="Link to subsection 2.29.4: Noise Texture">2.29.4. Noise Texture</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss5" title="Link to subsection 2.29.5: Sample Kernel">2.29.5. Sample Kernel</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss6" title="Link to subsection 2.29.6: Halo Removal">2.29.6. Halo Removal</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss7" title="Link to subsection 2.29.7: Performance">2.29.7. Performance</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss8" title="Link to subsection 2.29.8: Types">2.29.8. Types</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s29ss9" title="Link to subsection 2.29.9: Shaders">2.29.9. Shaders</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s30" title="Link to section 2.30: Filter: Emission">2.30. Filter: Emission</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s30ss1" title="Link to subsection 2.30.1: Overview">2.30.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s30ss2" title="Link to subsection 2.30.2: Algorithm">2.30.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s30ss3" title="Link to subsection 2.30.3: Types">2.30.3. Types</a></li></ul></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p2s31" title="Link to section 2.31: Filter: FXAA">2.31. Filter: FXAA</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s31ss1" title="Link to subsection 2.31.1: Overview">2.31.1. Overview</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s31ss2" title="Link to subsection 2.31.2: Implementation">2.31.2. Implementation</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p2s31ss3" title="Link to subsection 2.31.3: Types">2.31.3. Types</a></li></ul></li></ul><div class="st300_section_container"><a id="di.conventions"/><div class="st300_section_title_number"><a id="st300_p2s1" href="#st300_p2s1" title="Section 2.1: Conventions">2.1</a></div><div class="st300_section_title">Conventions</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s1ss1" title="Link to subsection 2.1.1: Overview">2.1.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s1ss2" title="Link to subsection 2.1.2: Mathematics">2.1.2. Mathematics</a></li></ul><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p2s1ss1" href="#st300_p2s1ss1" title="Subsection 2.1.1: Overview">2.1.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s1ss1c1" href="#st300_p2s1ss1c1" title="Paragraph 2.1.1.1">1</a></div><div class="st300_paragraph">This section attempts to document the mathematical and typographical conventions used in the rest of the documentation.</div></div></div><div class="st300_subsection_container"><a id="di.conventions.math"/><div class="st300_subsection_title_number"><a id="st300_p2s1ss2" href="#st300_p2s1ss2" title="Subsection 2.1.2: Mathematics">2.1.2</a></div><div class="st300_subsection_title">Mathematics</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s1ss2c1" href="#st300_p2s1ss2c1" title="Paragraph 2.1.2.1">1</a></div><div class="st300_paragraph">Rather than rely on untyped and ambiguous mathematical notation, this documentation expresses all mathematics and type definitions in strict <a class="st300_link_external" href="http://www.haskell.org/onlinereport/haskell2010/">Haskell 2010</a> with no extensions. All Haskell sources are included along with the documentation and can therefore be executed from the command line <a class="st300_link_external" href="http://www.haskell.org/haskellwiki/GHC/GHCi">GHCi</a> tool in order to interactively check results and experiment with functions.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s1ss2c2" href="#st300_p2s1ss2c2" title="Paragraph 2.1.2.2">2</a></div><div class="st300_paragraph">When used within prose, functions are usually referred to using fully qualified notation, such as <span class="st300_term expression">(Vector3f.cross n t)</span>. This is the application of the <span class="st300_term function">cross</span> function defined in the <span class="st300_term package">Vector3f</span> module, to the arguments <span class="st300_term variable">n</span> and <span class="st300_term variable">t</span>.</div></div></div></div><div class="st300_section_container"><a id="di.concepts"/><div class="st300_section_title_number"><a id="st300_p2s2" href="#st300_p2s2" title="Section 2.2: Concepts">2.2</a></div><div class="st300_section_title">Concepts</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss1" title="Link to subsection 2.2.1: Overview">2.2.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss2" title="Link to subsection 2.2.2: Renderer">2.2.2. Renderer</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss3" title="Link to subsection 2.2.3: Render Target">2.2.3. Render Target</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss4" title="Link to subsection 2.2.4: Geometry Buffer">2.2.4. Geometry Buffer</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss5" title="Link to subsection 2.2.5: Light Buffer">2.2.5. Light Buffer</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss6" title="Link to subsection 2.2.6: Mesh">2.2.6. Mesh</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss7" title="Link to subsection 2.2.7: Transform">2.2.7. Transform</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss8" title="Link to subsection 2.2.8: Instance">2.2.8. Instance</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss9" title="Link to subsection 2.2.9: Light">2.2.9. Light</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss10" title="Link to subsection 2.2.10: Light Clip Group">2.2.10. Light Clip Group</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss11" title="Link to subsection 2.2.11: Light Group">2.2.11. Light Group</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss12" title="Link to subsection 2.2.12: Shader">2.2.12. Shader</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s2ss13" title="Link to subsection 2.2.13: Material">2.2.13. Material</a></li></ul><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p2s2ss1" href="#st300_p2s2ss1" title="Subsection 2.2.1: Overview">2.2.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss1c1" href="#st300_p2s2ss1c1" title="Paragraph 2.2.1.1">1</a></div><div class="st300_paragraph">This section attempts to provide a rough overview of the concepts present in the <span class="st300_term package">r2</span> package. Specific implementation details, mathematics, and other technical information is given in later sections that focus on each concept in detail.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.renderer"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss2" href="#st300_p2s2ss2" title="Subsection 2.2.2: Renderer">2.2.2</a></div><div class="st300_subsection_title">Renderer</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss2c1" href="#st300_p2s2ss2c1" title="Paragraph 2.2.2.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">renderer</span> is a function that takes an input of some type and produces an output to a <a class="st300_link" href="#di.concepts.render_target">render target</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss2c2" href="#st300_p2s2ss2c2" title="Paragraph 2.2.2.2">2</a></div><div class="st300_paragraph">The renderers expose an interface of stateless functions from inputs to outputs. That is, the renderers should be considered to simply take input and produce return images as output. In reality, because the Java language is not pure and because the code is required to perform I/O in order to speak to the GPU, the renderer functions are not <span class="st300_term emphasis">really</span> pure. Nevertheless, for the sake of ease of use, lack of surprising results, and correctness, the renderers at least attempt to adhere to the idea of pure functional rendering! This means that the renderers are very easy to integrate into any existing system: They are simply functions that are evaluated whenever the programmer wants an image. The renderers do not have their own main loop, they do not have any concept of time, do not remember any images that they have produced previously, do not maintain any state of their own, and simply write their results to a programmer-provided render target. Passing the same input to a renderer multiple times should result in the same image each time.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.render_target"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss3" href="#st300_p2s2ss3" title="Subsection 2.2.3: Render Target">2.2.3</a></div><div class="st300_subsection_title">Render Target</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss3c1" href="#st300_p2s2ss3c1" title="Paragraph 2.2.3.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">render target</span> is a rectangular region of memory allocated on the GPU that can accept the results of a rendering operation. The programmer typically allocates one render target, passes it to a renderer along with a renderer-specific input value, and the renderer populates the given render target with the results. The programmer can then copy the contents of this render target to the screen for viewing, pass it on to a separate filter for extra visual effects, use it as a texture to be applied to objects in further rendered images, etc.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.gbuffer"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss4" href="#st300_p2s2ss4" title="Subsection 2.2.4: Geometry Buffer">2.2.4</a></div><div class="st300_subsection_title">Geometry Buffer</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss4c1" href="#st300_p2s2ss4c1" title="Paragraph 2.2.4.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">geometry buffer</span> is a specific type of <a class="st300_link" href="#di.concepts.render_target">render target</a> that contains the surface attributes of a set of rendered <a class="st300_link" href="#di.concepts.instance">instances</a>. It is a fundamental part of <span class="st300_term term">deferred rendering</span> that allows lighting to be efficiently calculated in <a class="st300_link" href="#di.coords.screen">screen space</a>, touching only those pixels that will actually contribute to the final rendered image.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.lbuffer"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss5" href="#st300_p2s2ss5" title="Subsection 2.2.5: Light Buffer">2.2.5</a></div><div class="st300_subsection_title">Light Buffer</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss5c1" href="#st300_p2s2ss5c1" title="Paragraph 2.2.5.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">light buffer</span> is a specific type of <a class="st300_link" href="#di.concepts.render_target">render target</a> that contains the summed light contributions for each pixel in the currently rendered scene.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.mesh"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss6" href="#st300_p2s2ss6" title="Subsection 2.2.6: Mesh">2.2.6</a></div><div class="st300_subsection_title">Mesh</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss6c1" href="#st300_p2s2ss6c1" title="Paragraph 2.2.6.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">mesh</span> is a collection of vertices that define a polyhedral object, along with a list of indices that describe how to make triangles out of the given vertices.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss6c2" href="#st300_p2s2ss6c2" title="Paragraph 2.2.6.2">2</a></div><div class="st300_paragraph">Meshes are allocated on the GPU and can be shared between any number of <a class="st300_link" href="#di.concepts.instance">instances</a> (meaning that rendering 100 identical objects does not require storing 100 copies of the mesh data).</div></div></div><div class="st300_subsection_container"><a id="di.concepts.transform"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss7" href="#st300_p2s2ss7" title="Subsection 2.2.7: Transform">2.2.7</a></div><div class="st300_subsection_title">Transform</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss7c1" href="#st300_p2s2ss7c1" title="Paragraph 2.2.7.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">transform</span> moves coordinates in one <a class="st300_link" href="#di.coords">coordinate space</a> to another. Typically, a transform is used to position and orient a <a class="st300_link" href="#di.concepts.mesh">mesh</a> inside a visible set.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.instance"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss8" href="#st300_p2s2ss8" title="Subsection 2.2.8: Instance">2.2.8</a></div><div class="st300_subsection_title">Instance</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss8c1" href="#st300_p2s2ss8c1" title="Paragraph 2.2.8.1">1</a></div><div class="st300_paragraph">An <span class="st300_term term">instance</span> is essentially an object or group of objects that can be rendered. Instances come in several forms: <span class="st300_term term">single</span>, <span class="st300_term term">batched</span>, and <span class="st300_term term">billboarded</span>.</div></div><div class="st300_paragraph_container"><a id="di.concepts.instance.single"/><div class="st300_paragraph_number"><a id="st300_p2s2ss8c2" href="#st300_p2s2ss8c2" title="Paragraph 2.2.8.2">2</a></div><div class="st300_paragraph">A <span class="st300_term term">single</span> instance consists of a reference to a <a class="st300_link" href="#di.concepts.mesh">mesh</a> and a <a class="st300_link" href="#di.concepts.transform">transform</a> for positioning the instance within a scene.</div></div><div class="st300_paragraph_container"><a id="di.concepts.instance.batched"/><div class="st300_paragraph_number"><a id="st300_p2s2ss8c3" href="#st300_p2s2ss8c3" title="Paragraph 2.2.8.3">3</a></div><div class="st300_paragraph">A <span class="st300_term term">batched</span> instance consists of a reference to a mesh and an array of transforms. The results of rendering a batched instance are the same as if a single instance had been created and rendered for each transform in the array. The advantage of batched instances is efficiency: Batched instances are submitted to the GPU for rendering in a single <span class="st300_term term">draw call</span>. Reducing the total number of draw calls per scene is an important optimization on modern graphics hardware, and batched instances provide a means to achieve this.</div></div><div class="st300_paragraph_container"><a id="di.concepts.instance.billboarded"/><div class="st300_paragraph_number"><a id="st300_p2s2ss8c4" href="#st300_p2s2ss8c4" title="Paragraph 2.2.8.4">4</a></div><div class="st300_paragraph">A <span class="st300_term term">billboarded</span> instance is a further specialization of a <span class="st300_term term">batched</span> instance intended for rendering large numbers of objects that always face towards the observer. Billboarding is a technique that is often used to render large numbers of distant objects in a scene: Rather than incur the overhead of rendering lots of barely-visible objects at full detail, the objects are replaced with billboarded <span class="st300_term term">sprites</span> at a fraction of the cost. There is also a significant saving in the memory used to store transforms, because a billboarded sprite need only store a <span class="st300_term term">position</span> and <span class="st300_term term">scale</span> as opposed to a full transform matrix per rendered object.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.light"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss9" href="#st300_p2s2ss9" title="Subsection 2.2.9: Light">2.2.9</a></div><div class="st300_subsection_title">Light</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss9c1" href="#st300_p2s2ss9c1" title="Paragraph 2.2.9.1">1</a></div><div class="st300_paragraph">A <span class="st300_term light">light</span> describes a light source within a scene. There are many different types of lights, each with different behaviours. Lights may or may not cast shadows, depending on their type. All lighting in the <span class="st300_term package">r2</span> package is completely dynamic; there is no support for static lighting in any form. Shadows are exclusively provided via shadow mapping, resulting in efficient per-pixel shadows.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.light_clip_group"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss10" href="#st300_p2s2ss10" title="Subsection 2.2.10: Light Clip Group">2.2.10</a></div><div class="st300_subsection_title">Light Clip Group</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss10c1" href="#st300_p2s2ss10c1" title="Paragraph 2.2.10.1">1</a></div><div class="st300_paragraph">A <span class="st300_term light">light clip group</span> is a means of constraining the contributions of groups of <a class="st300_link" href="#di.concepts.light">lights</a> to a provided <span class="st300_term term">volume</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss10c2" href="#st300_p2s2ss10c2" title="Paragraph 2.2.10.2">2</a></div><div class="st300_paragraph">Because, like most renderers, the <span class="st300_term package">r2</span> package implements so-called <span class="st300_term term">local illumination</span>, lights that do not have explicit <span class="st300_term term">shadow mapping</span> enabled are able to bleed through solid objects:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s2ss10c3" href="#st300_p2s2ss10c3" title="Formal item 2.2.10.3: Local Light Bleed">2.2.10.3 Local Light Bleed</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Local light bleeding." src="images/lightbleed_noclip.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss10c4" href="#st300_p2s2ss10c4" title="Paragraph 2.2.10.4">4</a></div><div class="st300_paragraph">Enabling shadow mapping for every single light source would be prohibitively expensive <span class="st300_footnote_reference">[<a href="#st300_f_2627_0" id="st300_fr_2091" title="Jump to footnote di.concepts.shadow_expensive (reference 0)">3</a>]</span>, but for some scenes, acceptable results can be achieved by simply preventing the light source from affecting pixels outside of a given <span class="st300_term term">clip volume</span>.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s2ss10c5" href="#st300_p2s2ss10c5" title="Formal item 2.2.10.5: Local Light Clipped">2.2.10.5 Local Light Clipped</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Local light clipped to a volume." src="images/lightbleed_clip.png"/></div></div></div><div class="st300_subsection_container"><a id="di.concepts.light_group"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss11" href="#st300_p2s2ss11" title="Subsection 2.2.11: Light Group">2.2.11</a></div><div class="st300_subsection_title">Light Group</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss11c1" href="#st300_p2s2ss11c1" title="Paragraph 2.2.11.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">light group</span> is similar to a <a class="st300_link" href="#di.concepts.light_clip_group">light clip group</a> in that is intended to constrain the contributions of a set of lights. A light group instead requires the cooperation of a renderer that can mark groups of <a class="st300_link" href="#di.concepts.instance">instances</a> using the <span class="st300_term term">stencil</span> component of the current <a class="st300_link" href="#di.concepts.gbuffer">geometry buffer</a>. At most <span class="st300_term constant">15</span> light groups can be present in a given scene, and for a given light group <span class="st300_term variable">n</span>, only instances in group <span class="st300_term variable">n</span> will be affected by lights in group <span class="st300_term variable">n</span>. By default, if a group is not otherwise specified, all lights and instances are rendered in group <span class="st300_term constant">1</span>.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.shader"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss12" href="#st300_p2s2ss12" title="Subsection 2.2.12: Shader">2.2.12</a></div><div class="st300_subsection_title">Shader</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss12c1" href="#st300_p2s2ss12c1" title="Paragraph 2.2.12.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">shader</span> is a small program that executes on the GPU and is used to produce images. The <span class="st300_term package">r2</span> package provides a wide array of general-purpose shaders, and the intention is that users of the package will <span class="st300_term emphasis">not</span> typically have to write their own <span class="st300_footnote_reference">[<a href="#st300_f_2566_0" id="st300_fr_2318" title="Jump to footnote di.concepts.shader.r1_material (reference 0)">2</a>]</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss12c2" href="#st300_p2s2ss12c2" title="Paragraph 2.2.12.2">2</a></div><div class="st300_paragraph">The package roughly divides shaders into categories. <span class="st300_term term">Single instance shaders</span> are typically used to calculate and render the surface attributes of <a class="st300_link" href="#di.concepts.instance.single">single instances</a> into a <a class="st300_link" href="#di.concepts.gbuffer">geometry buffer</a>. <span class="st300_term term">Batched instance shaders</span> do the same for <a class="st300_link" href="#di.concepts.instance.batched">batched instances</a>. <span class="st300_term term">Light shaders</span> render the contributions of light sources into a <a class="st300_link" href="#di.concepts.lbuffer">light buffer</a>. There are many other types of shader in the <span class="st300_term package">r2</span> package but users are generally not exposed to them directly.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss12c3" href="#st300_p2s2ss12c3" title="Paragraph 2.2.12.3">3</a></div><div class="st300_paragraph">Shaders are intended to be effectively <span class="st300_term term">stateless</span>. A given shader <span class="st300_term type">S</span> is an opaque function that takes a single parameter value <span class="st300_term type">M</span>, and the user actually supplies <span class="st300_term type">M</span> by configuring a <a class="st300_link" href="#di.concepts.material">material</a> for <span class="st300_term type">S</span> and then using it each frame.</div></div></div><div class="st300_subsection_container"><a id="di.concepts.material"/><div class="st300_subsection_title_number"><a id="st300_p2s2ss13" href="#st300_p2s2ss13" title="Subsection 2.2.13: Material">2.2.13</a></div><div class="st300_subsection_title">Material</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s2ss13c1" href="#st300_p2s2ss13c1" title="Paragraph 2.2.13.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">material</span> is a pair consisting of a <a class="st300_link" href="#di.concepts.shader">shader</a> and a set of parameters for that shader <span class="st300_footnote_reference">[<a href="#st300_f_2495_0" id="st300_fr_2493" title="Jump to footnote di.concepts.material.r1_material (reference 0)">1</a>]</span>.</div></div></div></div><div class="st300_section_container"><a id="di.coords"/><div class="st300_section_title_number"><a id="st300_p2s3" href="#st300_p2s3" title="Section 2.3: Coordinate Systems">2.3</a></div><div class="st300_section_title">Coordinate Systems</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss1" title="Link to subsection 2.3.1: Conventions">2.3.1. Conventions</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss2" title="Link to subsection 2.3.2: Object Space">2.3.2. Object Space</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss3" title="Link to subsection 2.3.3: World Space">2.3.3. World Space</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss4" title="Link to subsection 2.3.4: Eye Space">2.3.4. Eye Space</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss5" title="Link to subsection 2.3.5: Clip Space">2.3.5. Clip Space</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss6" title="Link to subsection 2.3.6: Normalized-Device Space">2.3.6. Normalized-Device Space</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s3ss7" title="Link to subsection 2.3.7: Screen Space">2.3.7. Screen Space</a></li></ul><div class="st300_subsection_container"><a id="di.coords.conventions"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss1" href="#st300_p2s3ss1" title="Subsection 2.3.1: Conventions">2.3.1</a></div><div class="st300_subsection_title">Conventions</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss1c1" href="#st300_p2s3ss1c1" title="Paragraph 2.3.1.1">1</a></div><div class="st300_paragraph">This section attempts to describe the mathematical conventions that the <span class="st300_term package">r2</span> package uses with respect to coordinate systems. The <span class="st300_term package">r2</span> package generally does not deviate from standard OpenGL conventions, and this section does not attempt to give a rigorous formal definition of these existing conventions. It does however attempt to establish the naming conventions that the package uses to refer to the standard coordinate spaces <span class="st300_footnote_reference">[<a href="#st300_f_4874_0" id="st300_fr_2739" title="Jump to footnote di.coords.whining (reference 0)">10</a>]</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss1c2" href="#st300_p2s3ss1c2" title="Paragraph 2.3.1.2">2</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package uses the <a class="st300_link_external" href="http://io7m.github.io/jtensors">jtensors</a> package for all mathematical operations on the CPU, and therefore shares its conventions with regards to coordinate system handedness. Important parts are repeated here, but the documentation for the <span class="st300_term package">jtensors</span> package should be inspected for details.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss1c3" href="#st300_p2s3ss1c3" title="Paragraph 2.3.1.3">3</a></div><div class="st300_paragraph">Any of the matrix functions that deal with rotations assume a right-handed coordinate system. This matches the system conventionally used by <a class="st300_link_external" href="http://opengl.org">OpenGL</a> (and most mathematics literature) . A right-handed coordinate system assumes that if the viewer is standing at the origin and looking towards negative infinity on the Z axis, then the X axis runs horizontally (left towards negative infinity and right towards positive infinity) , and the Y axis runs vertically (down towards negative infinity and up towards positive infinity). The following image demonstrates this axis configuration:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss1c4" href="#st300_p2s3ss1c4" title="Formal item 2.3.1.4: Right Handed Coordinate System">2.3.1.4 Right Handed Coordinate System</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="A right handed coordinate system diagram." src="images/axes2.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss1c5" href="#st300_p2s3ss1c5" title="Paragraph 2.3.1.5">5</a></div><div class="st300_paragraph">The <span class="st300_term package">jtensors</span> package adheres to the convention that a positive rotation around an axis represents a counter-clockwise rotation when viewing the system along the negative direction of the axis in question.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss1c6" href="#st300_p2s3ss1c6" title="Formal item 2.3.1.6: Rotations">2.3.1.6 Rotations</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="A diagram of right-handed rotations." src="images/rotations.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss1c7" href="#st300_p2s3ss1c7" title="Paragraph 2.3.1.7">7</a></div><div class="st300_paragraph">The package uses the following matrices to define rotations around each axis:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss1c8" href="#st300_p2s3ss1c8" title="Formal item 2.3.1.8: Rotation of r radians around the X axis">2.3.1.8 Rotation of r radians around the X axis</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Rotation of r radians around the X axis." src="images/matrix_rx.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss1c9" href="#st300_p2s3ss1c9" title="Formal item 2.3.1.9: Rotation of r radians around the Y axis">2.3.1.9 Rotation of r radians around the Y axis</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Rotation of r radians around the Y axis." src="images/matrix_ry.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss1c10" href="#st300_p2s3ss1c10" title="Formal item 2.3.1.10: Rotation of r radians around the Z axis">2.3.1.10 Rotation of r radians around the Z axis</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Rotation of r radians around the Z axis." src="images/matrix_rz.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss1c11" href="#st300_p2s3ss1c11" title="Paragraph 2.3.1.11">11</a></div><div class="st300_paragraph">Which results in the following matrix for rotating <span class="st300_term expression">r</span> radians around the axis given by <span class="st300_term expression">(x, y, z)</span>, assuming <span class="st300_term expression">s = sin(r)</span> and <span class="st300_term expression">c = cos(r)</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss1c12" href="#st300_p2s3ss1c12" title="Formal item 2.3.1.12: Rotation of r radians around an arbitrary axis">2.3.1.12 Rotation of r radians around an arbitrary axis</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Rotation of r radians around an arbitrary axis." src="images/rot_matrix.png"/></div></div></div><div class="st300_subsection_container"><a id="di.coords.object"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss2" href="#st300_p2s3ss2" title="Subsection 2.3.2: Object Space">2.3.2</a></div><div class="st300_subsection_title">Object Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss2c1" href="#st300_p2s3ss2c1" title="Paragraph 2.3.2.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Object space</span> is the local coordinate system used to describe the positions of vertices in meshes. For example, a unit cube with the origin placed at the center of the cube would have eight vertices with positions expressed as object-space coordinates:</div></div><div class="st300_formal_item"><a id="di.coords.object.cube"/><div class="st300_formal_item_title"><a id="st300_p2s3ss2c2" href="#st300_p2s3ss2c2" title="Formal item 2.3.2.2: Unit cube vertices">2.3.2.2 Unit cube vertices</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">cube = {
  (-0.5, -0.5, -0.5),
  ( 0.5, -0.5, -0.5),
  ( 0.5, -0.5,  0.5),
  (-0.5, -0.5,  0.5),

  (-0.5,  0.5, -0.5),
  ( 0.5,  0.5, -0.5),
  ( 0.5,  0.5,  0.5),
  (-0.5,  0.5,  0.5)
}</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss2c3" href="#st300_p2s3ss2c3" title="Paragraph 2.3.2.3">3</a></div><div class="st300_paragraph">In other rendering systems, object space is sometimes referred to as <span class="st300_term term">local space</span>, or <span class="st300_term term">model space</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss2c4" href="#st300_p2s3ss2c4" title="Paragraph 2.3.2.4">4</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, object space is represented by the <a class="st300_link_external" href="apidocs/com/io7m/r2/spaces/R2SpaceObjectType.html">R2SpaceObjectType</a>.</div></div></div><div class="st300_subsection_container"><a id="di.coords.world"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss3" href="#st300_p2s3ss3" title="Subsection 2.3.3: World Space">2.3.3</a></div><div class="st300_subsection_title">World Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss3c1" href="#st300_p2s3ss3c1" title="Paragraph 2.3.3.1">1</a></div><div class="st300_paragraph">In order to position objects in a scene, they must be assigned a <a class="st300_link" href="#di.concepts.transform">transform</a> that can be applied to each of their <a class="st300_link" href="#di.coords.object">object space</a> vertices to yield absolute positions in so-called <span class="st300_term term">world space</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss3c2" href="#st300_p2s3ss3c2" title="Paragraph 2.3.3.2">2</a></div><div class="st300_paragraph">As an example, if the <a class="st300_link" href="#di.coords.object.cube">unit cube</a> described above was assigned a transform that moved its origin to <span class="st300_term expression">(3, 5, 1)</span>, then its object space vertex <span class="st300_term expression">(-0.5, 0.5, 0.5)</span> would end up at <span class="st300_term expression">(3 + -0.5, 5 + 0.5, 1 + 0.5) = (2.5, 5.5, 1.5)</span> in world space.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss3c3" href="#st300_p2s3ss3c3" title="Paragraph 2.3.3.3">3</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, a transform applied to an object produces a 4x4 <span class="st300_term term">model matrix</span>. Multiplying the model matrix with the positions of the object space vertices yields vertices in world space.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss3c4" href="#st300_p2s3ss3c4" title="Paragraph 2.3.3.4">4</a></div><div class="st300_paragraph">Note that, despite the name, <span class="st300_term term">world space</span> does not imply that users have to store their actual world representation in this coordinate space. For example, flight simulators often have to transform their planet-scale world representation to an <span class="st300_term term">aircraft relative</span> representation for rendering to work around the issues inherent in rendering extremely large scenes. The basic issue is that the relatively low level of floating point precision available on current graphics hardware means that if the coordinates of objects within the flight simulator's world were to be used directly, the values would tend to be drastically larger than those that could be expressed by the available limited-precision floating point types on the GPU. Instead, simulators often transform the locations of objects in their worlds such that the aircraft is placed at the origin <span class="st300_term expression">(0, 0, 0)</span> and the objects are positioned relative to the aircraft before being passed to the GPU for rendering. As a concrete example, within the simulator's world, the aircraft may be at <span class="st300_term expression">(1882838.3, 450.0, 5892309.0)</span>, and a control tower nearby may be at <span class="st300_term expression">(1883838.5, 0.0, 5892809.0)</span>. These coordinate values would be far too large to pass to the GPU if a reasonable level of precision is required, but if the current aircraft location is subtracted from all positions, the coordinates in <span class="st300_term term">aircraft relative space</span> of the aircraft become <span class="st300_term expression">(0, 0, 0)</span> and the coordinates of the tower become <span class="st300_term expression">(1883838.5 - 1882838.3, 0.0 - 450.0, 5892809.0 - 5892309.0) = (1000.19, -450.0, 500.0)</span>. The <span class="st300_term term">aircraft relative space</span> coordinates are certainly small enough to be given to the GPU directly without risking imprecision issues, and therefore the simulator would essentially treat <span class="st300_term term">aircraft relative space</span> and <span class="st300_term package">r2</span> <span class="st300_term term">world space</span> as equivalent <span class="st300_footnote_reference">[<a href="#st300_f_4904_0" id="st300_fr_3562" title="Jump to footnote di.coords.minecraft (reference 0)">11</a>]</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss3c5" href="#st300_p2s3ss3c5" title="Paragraph 2.3.3.5">5</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, world space is represented by the <a class="st300_link_external" href="apidocs/com/io7m/r2/spaces/R2SpaceWorldType.html">R2SpaceWorldType</a>.</div></div></div><div class="st300_subsection_container"><a id="di.coords.eye"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss4" href="#st300_p2s3ss4" title="Subsection 2.3.4: Eye Space">2.3.4</a></div><div class="st300_subsection_title">Eye Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss4c1" href="#st300_p2s3ss4c1" title="Paragraph 2.3.4.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Eye space</span> represents a coordinate system with the observer implicitly fixed at the origin <span class="st300_term expression">(0.0, 0.0, 0.0)</span> and looking towards infinity in the negative Z direction.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss4c2" href="#st300_p2s3ss4c2" title="Paragraph 2.3.4.2">2</a></div><div class="st300_paragraph">The main purpose of eye space is to simplify the mathematics required to implement various algorithms such as lighting. The problem with implementing these sorts of algorithms in <a class="st300_link" href="#di.coords.world">world space</a> is that one must constantly take into account the position of the observer (typically by subtracting the location of the observer from each set of world space coordinates and accounting for any change in orientation of the observer). By fixing the orientation of the observer towards negative Z, and the position of the observer at <span class="st300_term expression">(0.0, 0.0, 0.0)</span>, and by transforming all vertices of all objects into the same system, the mathematics of lighting are greatly simplified. The majority of the rendering algorithms used in the <span class="st300_term package">r2</span> package are implemented in eye space.</div></div><div class="st300_paragraph_container"><a id="di.coords.eye.modelview"/><div class="st300_paragraph_number"><a id="st300_p2s3ss4c3" href="#st300_p2s3ss4c3" title="Paragraph 2.3.4.3">3</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the observer produces a 4x4 <span class="st300_term term">view matrix</span>. Multiplying the view matrix with any given world space position yields a position in eye space. In practice, the view matrix <span class="st300_term expression">v</span> and the current object's model matrix <span class="st300_term expression">m</span> are concatenated (multiplied) to produce a <span class="st300_term term">model-view</span> matrix <span class="st300_term expression">mv = v * m</span> <span class="st300_footnote_reference">[<a href="#st300_f_4081_0" id="st300_fr_3808" title="Jump to footnote di.coords.eye.anticommut (reference 0)">5</a>]</span>, and <span class="st300_term expression">mv</span> is then passed directly to the renderer's vertex shaders to transform the current object's vertices <span class="st300_footnote_reference">[<a href="#st300_f_4090_0" id="st300_fr_3830" title="Jump to footnote di.coords.eye.efficient (reference 0)">6</a>]</span>.</div></div><div class="st300_paragraph_container"><a id="di.coords.eye.normal-matrix"/><div class="st300_paragraph_number"><a id="st300_p2s3ss4c4" href="#st300_p2s3ss4c4" title="Paragraph 2.3.4.4">4</a></div><div class="st300_paragraph">Additionally, as the <span class="st300_term package">r2</span> package does all lighting in eye space, it's necessary to transform the object space <span class="st300_term term">normal vectors</span> given in mesh data to eye space. However, the usual model-view matrix will almost certainly contain some sort of translational component and possibly a scaling component. Normal vectors are not supposed to be translated; they represent directions! A non-uniform scale applied to an object will also deform the normal vectors, making them non-perpendicular to the surface they're associated with:</div></div><div class="st300_formal_item"><a id="di.coords.eye.normals"/><div class="st300_formal_item_title"><a id="st300_p2s3ss4c5" href="#st300_p2s3ss4c5" title="Formal item 2.3.4.5: Unit cube vertices">2.3.4.5 Unit cube vertices</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Deformed normal vectors." src="images/normal_deform.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss4c6" href="#st300_p2s3ss4c6" title="Paragraph 2.3.4.6">6</a></div><div class="st300_paragraph">With the scaled triangle on the right, the normal vector is now not perpendicular to the surface (in addition to no longer being of unit length). The red vector indicates what the surface normal <span class="st300_term emphasis">should</span> be.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss4c7" href="#st300_p2s3ss4c7" title="Paragraph 2.3.4.7">7</a></div><div class="st300_paragraph">Therefore it's necessary to derive another 3x3 matrix known as the <span class="st300_term term">normal matrix</span> from the model-view matrix that contains just the rotational component of the original matrix. The full derivation of this matrix is given in <a class="st300_link_external" href="http://www.mathfor3dgameprogramming.com/">Mathematics for 3D Game Programming and Computer Graphics, Third Edition</a> <span class="st300_footnote_reference">[<a href="#st300_f_4074_0" id="st300_fr_4027" title="Jump to footnote di.coords.eye.math3dgame (reference 0)">4</a>]</span>. Briefly, the normal matrix is equal to the inverse transpose of the top left 3x3 elements of an arbitrary 4x4 model-view matrix.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss4c8" href="#st300_p2s3ss4c8" title="Paragraph 2.3.4.8">8</a></div><div class="st300_paragraph">In other rendering systems, eye space is sometimes referred to as <span class="st300_term term">camera space</span>, or <span class="st300_term term">view space</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss4c9" href="#st300_p2s3ss4c9" title="Paragraph 2.3.4.9">9</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, eye space is represented by the <a class="st300_link_external" href="apidocs/com/io7m/r2/spaces/R2SpaceEyeType.html">R2SpaceEyeType</a>.</div></div></div><div class="st300_subsection_container"><a id="di.coords.clip"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss5" href="#st300_p2s3ss5" title="Subsection 2.3.5: Clip Space">2.3.5</a></div><div class="st300_subsection_title">Clip Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss5c1" href="#st300_p2s3ss5c1" title="Paragraph 2.3.5.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Clip space</span> is a homogeneous coordinate system in which OpenGL performs clipping of primitives (such as triangles). In OpenGL, clip space is effectively a left-handed coordinate system by default <span class="st300_footnote_reference">[<a href="#st300_f_4502_0" id="st300_fr_4207" title="Jump to footnote di.coords.clip.invert (reference 0)">7</a>]</span>. Intuitively, coordinates in eye space are transformed with a <span class="st300_term term">projection</span> (normally either an <span class="st300_term term">orthographic</span> or <span class="st300_term term">perspective</span> projection) such that all vertices are projected into a homogeneous unit cube placed at the origin - <span class="st300_term term">clip space</span>  - resulting in four-dimensional <span class="st300_term expression">(x, y, z, w)</span> positions. Positions that end up outside of the cube are clipped (discarded) by dedicated clipping hardware, usually producing more triangles as a result.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss5c2" href="#st300_p2s3ss5c2" title="Formal item 2.3.5.2: Primitive Clipping">2.3.5.2 Primitive Clipping</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="A diagram of primitive clipping." src="images/clipping.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss5c3" href="#st300_p2s3ss5c3" title="Paragraph 2.3.5.3">3</a></div><div class="st300_paragraph">A <span class="st300_term term">projection</span> effectively determines how objects in the three-dimensional scene are projected onto the two-dimensional <span class="st300_term term">viewing plane</span> (a computer screen, in most cases) . A <span class="st300_term term">perspective</span> projection transforms vertices such that objects that are further away from the viewing plane appear to be smaller than objects that are close to it, while an <span class="st300_term term">orthographic</span> projection preserves the perceived sizes of objects regardless of their distance from the viewing plane.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss5c4" href="#st300_p2s3ss5c4" title="Formal item 2.3.5.4: Perspective projection">2.3.5.4 Perspective projection</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="A diagram of perspective projection." src="images/proj_perspective.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss5c5" href="#st300_p2s3ss5c5" title="Formal item 2.3.5.5: Orthographic projection">2.3.5.5 Orthographic projection</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="A diagram of orthographic projection." src="images/proj_ortho.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss5c6" href="#st300_p2s3ss5c6" title="Paragraph 2.3.5.6">6</a></div><div class="st300_paragraph">Because <a class="st300_link" href="#di.coords.eye">eye space</a> is a right-handed coordinate system by convention, but by default clip space is left-handed, the projection matrix used will invert the sign of the <span class="st300_term expression">z</span> component of any given point.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss5c7" href="#st300_p2s3ss5c7" title="Paragraph 2.3.5.7">7</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the observer produces a 4x4 <span class="st300_term term">projection matrix</span>. The projection matrix is passed, along with the <a class="st300_link" href="#di.coords.eye.modelview">model-view</a> matrix, to the renderer's vertex shaders. As is normal in OpenGL, the vertex shader produces clip space coordinates which are then used by the hardware rasterizer to produce color fragments onscreen.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss5c8" href="#st300_p2s3ss5c8" title="Paragraph 2.3.5.8">8</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, clip space is represented by the <a class="st300_link_external" href="apidocs/com/io7m/r2/spaces/R2SpaceClipType.html">R2SpaceClipType</a>.</div></div></div><div class="st300_subsection_container"><a id="di.coords.ndevice"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss6" href="#st300_p2s3ss6" title="Subsection 2.3.6: Normalized-Device Space">2.3.6</a></div><div class="st300_subsection_title">Normalized-Device Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss6c1" href="#st300_p2s3ss6c1" title="Paragraph 2.3.6.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Normalized-device space</span> is, by default, a left-handed <span class="st300_footnote_reference">[<a href="#st300_f_4678_0" id="st300_fr_4568" title="Jump to footnote di.coords.ndevice.left (reference 0)">8</a>]</span> coordinate space in which <a class="st300_link" href="#di.coords.clip">clip space</a> coordinates have been divided by their own <span class="st300_term expression">w</span> component (discarding the resulting <span class="st300_term expression">w = 1</span> component in the process), yielding three dimensional coordinates. The range of values in the resulting coordinates are effectively normalized by the division to fall within the ranges <span class="st300_term expression">[(-1, -1, -1), (1, 1, 1)]</span> <span class="st300_footnote_reference">[<a href="#st300_f_4699_0" id="st300_fr_4628" title="Jump to footnote di.coords.ndevice.division (reference 0)">9</a>]</span>. The coordinate space represents a simplifying intermediate step between having clip space coordinates and getting something projected into a two-dimensional image <a class="st300_link" href="#di.coords.screen">(screen space)</a> for viewing.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss6c2" href="#st300_p2s3ss6c2" title="Paragraph 2.3.6.2">2</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package does not directly use or manipulate values in normalized-device space; it is mentioned here for completeness.</div></div></div><div class="st300_subsection_container"><a id="di.coords.screen"/><div class="st300_subsection_title_number"><a id="st300_p2s3ss7" href="#st300_p2s3ss7" title="Subsection 2.3.7: Screen Space">2.3.7</a></div><div class="st300_subsection_title">Screen Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss7c1" href="#st300_p2s3ss7c1" title="Paragraph 2.3.7.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Screen space</span> is, by default, a left-handed coordinate system representing the screen (or window) that is displaying the actual results of rendering. If the screen is of width <span class="st300_term expression">w</span> and height <span class="st300_term expression">h</span>, and the current <span class="st300_term term">depth range</span> of the window is <span class="st300_term expression">[n, f]</span>, then the range of values in screen space coordinates runs from <span class="st300_term expression">[(0, 0, n), (w, h, f)]</span>. The origin <span class="st300_term expression">(0, 0, 0)</span> is assumed to be at the bottom-left corner.</div></div><div class="st300_paragraph_container"><a id="di.coords.screen.depth"/><div class="st300_paragraph_number"><a id="st300_p2s3ss7c2" href="#st300_p2s3ss7c2" title="Paragraph 2.3.7.2">2</a></div><div class="st300_paragraph">The depth range is actually a configurable value, but the <span class="st300_term package">r2</span> package keeps the OpenGL default. From the <span class="st300_term function">glDepthRange</span> function manual page:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s3ss7c3" href="#st300_p2s3ss7c3" title="Formal item 2.3.7.3: glDepthRange">2.3.7.3 glDepthRange</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">
After clipping and division by w, depth coordinates range from -1 to 1,
corresponding to the near and far clipping planes. glDepthRange specifies a
linear mapping of the normalized depth coordinates in this range to window
depth coordinates. Regardless of the actual depth buffer implementation,
window coordinate depth values are treated as though they range from 0
through 1 (like color components). Thus, the values accepted by
glDepthRange are both clamped to this range before they are accepted.
The setting of (0,1) maps the near plane to 0 and the far plane to 1.
With this mapping, the depth buffer range is fully utilized.</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s3ss7c4" href="#st300_p2s3ss7c4" title="Paragraph 2.3.7.4">4</a></div><div class="st300_paragraph">As OpenGL, by default, specifies a depth range of <span class="st300_term expression">[0, 1]</span>, the positive Z axis points away from the observer and so the coordinate system is left handed.</div></div></div></div><div class="st300_section_container"><a id="di.meshes"/><div class="st300_section_title_number"><a id="st300_p2s4" href="#st300_p2s4" title="Section 2.4: Meshes">2.4</a></div><div class="st300_section_title">Meshes</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s4ss1" title="Link to subsection 2.4.1: Overview">2.4.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s4ss2" title="Link to subsection 2.4.2: Attributes">2.4.2. Attributes</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s4ss3" title="Link to subsection 2.4.3: Types">2.4.3. Types</a></li></ul><div class="st300_subsection_container"><a id="di.meshes.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s4ss1" href="#st300_p2s4ss1" title="Subsection 2.4.1: Overview">2.4.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss1c1" href="#st300_p2s4ss1c1" title="Paragraph 2.4.1.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">mesh</span> is a collection of vertices that make up the triangles that define a polyhedral object, allocated on the GPU upon which the renderer is executing. In practical terms, a mesh is a pair <span class="st300_term expression">(a, i)</span>, where <span class="st300_term expression">a</span> is an OpenGL <span class="st300_term term">vertex buffer object</span> consisting of vertices, an <span class="st300_term expression">i</span> is an OpenGL <span class="st300_term term">element buffer object</span> consisting of indices that describe how to draw the mesh as a series of triangles.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss1c2" href="#st300_p2s4ss1c2" title="Paragraph 2.4.1.2">2</a></div><div class="st300_paragraph">The contents of <span class="st300_term expression">a</span> are mutable, but mesh references are considered to be immutable.</div></div></div><div class="st300_subsection_container"><a id="di.meshes.attributes"/><div class="st300_subsection_title_number"><a id="st300_p2s4ss2" href="#st300_p2s4ss2" title="Subsection 2.4.2: Attributes">2.4.2</a></div><div class="st300_subsection_title">Attributes</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss2c1" href="#st300_p2s4ss2c1" title="Paragraph 2.4.2.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">mesh</span> consists of <span class="st300_term term">vertices</span>. A vertex can be considered to be a value of a <span class="st300_term term">record type</span>, with the fields of the record referred to as the <span class="st300_term term">attributes</span> of the vertex. In the <span class="st300_term package">r2</span> package, an array buffer containing vertex data is specified using the array buffer types from <a class="st300_link_external" href="http://io7m.github.io/jcanephora">jcanephora</a>. The <span class="st300_term package">jcanephora</span> package allows programmers to specify the exact types of array buffers, allows for the full inspection of type information at runtime, including the ability to reference attributes by name, and allows for type-safe modification of the contents of array buffers using an efficient cursor interface.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss2c2" href="#st300_p2s4ss2c2" title="Paragraph 2.4.2.2">2</a></div><div class="st300_paragraph">Each attribute within an array buffer is assigned a numeric <span class="st300_term term">attribute index</span>. A numeric index is an arbitrary number between (including) <span class="st300_term constant">0</span> and some OpenGL implementation-defined upper limit. On modern graphics hardware, OpenGL allows for at least <span class="st300_term constant">16</span> numeric attributes. The indices are used to create an association between fields in the array buffer and <span class="st300_term term">shader</span> inputs. For the sake of sanity and consistency, it is the responsibility of rendering systems using OpenGL to establish conventions for the assignment of numeric attribute indices in shaders and array buffers <span class="st300_footnote_reference">[<a href="#st300_f_5527_0" id="st300_fr_5254" title="Jump to footnote di.meshes.failure (reference 0)">12</a>]</span>. For example, many systems state that attribute <span class="st300_term constant">0</span> should be of type <span class="st300_term type">vec4</span> and should represent vertex <span class="st300_term term">positions</span>. Shaders simply assume that data arriving on attribute input <span class="st300_term constant">0</span> represents position data, and programmers are expected to create meshes where attribute <span class="st300_term constant">0</span> points to the field within the array that contains position data.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss2c3" href="#st300_p2s4ss2c3" title="Paragraph 2.4.2.3">3</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package uses the following conventions everywhere:</div></div><div class="st300_formal_item"><a id="di.meshes.attributes.single"/><div class="st300_formal_item_title"><a id="st300_p2s4ss2c4" href="#st300_p2s4ss2c4" title="Formal item 2.4.2.4: Mesh attribute conventions">2.4.2.4 Mesh attribute conventions</a></div><div class="st300_formal_item_content"><table class="st300_table mesh_types" summary="Mesh attribute conventions"><thead class="st300_table_head"><tr><th class="st300_table_column_name">Index</th><th class="st300_table_column_name">Type</th><th class="st300_table_column_name">Description</th></tr></thead><tbody class="st300_table_body"><tr><td class="st300_table_cell"><span class="st300_term constant">0</span></td><td class="st300_table_cell"><span class="st300_term type">vec3</span></td><td class="st300_table_cell">The object-space position of the vertex</td></tr><tr><td class="st300_table_cell"><span class="st300_term constant">1</span></td><td class="st300_table_cell"><span class="st300_term type">vec2</span></td><td class="st300_table_cell">The UV coordinates of the vertex</td></tr><tr><td class="st300_table_cell"><span class="st300_term constant">2</span></td><td class="st300_table_cell"><span class="st300_term type">vec3</span></td><td class="st300_table_cell">The object-space normal vector of the vertex</td></tr><tr><td class="st300_table_cell"><span class="st300_term constant">3</span></td><td class="st300_table_cell"><span class="st300_term type">vec4</span></td><td class="st300_table_cell">The tangent vector of the vertex</td></tr></tbody></table></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss2c5" href="#st300_p2s4ss2c5" title="Paragraph 2.4.2.5">5</a></div><div class="st300_paragraph"><span class="st300_term term">Batched instances</span> are expected to use the following additional conventions:</div></div><div class="st300_formal_item"><a id="di.meshes.attributes.batched"/><div class="st300_formal_item_title"><a id="st300_p2s4ss2c6" href="#st300_p2s4ss2c6" title="Formal item 2.4.2.6: Batched instance attribute conventions">2.4.2.6 Batched instance attribute conventions</a></div><div class="st300_formal_item_content"><table class="st300_table mesh_types" summary="Mesh attribute conventions"><thead class="st300_table_head"><tr><th class="st300_table_column_name">Index</th><th class="st300_table_column_name">Type</th><th class="st300_table_column_name">Description</th></tr></thead><tbody class="st300_table_body"><tr><td class="st300_table_cell"><span class="st300_term constant">4</span></td><td class="st300_table_cell"><span class="st300_term type">vec4</span></td><td class="st300_table_cell">Column 0 of the per-instance model matrix for batched instances.</td></tr><tr><td class="st300_table_cell"><span class="st300_term constant">5</span></td><td class="st300_table_cell"><span class="st300_term type">vec4</span></td><td class="st300_table_cell">Column 1 of the per-instance model matrix for batched instances.</td></tr><tr><td class="st300_table_cell"><span class="st300_term constant">6</span></td><td class="st300_table_cell"><span class="st300_term type">vec4</span></td><td class="st300_table_cell">Column 2 of the per-instance model matrix for batched instances.</td></tr><tr><td class="st300_table_cell"><span class="st300_term constant">7</span></td><td class="st300_table_cell"><span class="st300_term type">vec4</span></td><td class="st300_table_cell">Column 3 of the per-instance model matrix for batched instances.</td></tr></tbody></table></div></div></div><div class="st300_subsection_container"><a id="di.meshes.types"/><div class="st300_subsection_title_number"><a id="st300_p2s4ss3" href="#st300_p2s4ss3" title="Subsection 2.4.3: Types">2.4.3</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s4ss3c1" href="#st300_p2s4ss3c1" title="Paragraph 2.4.3.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the given attribute conventions are specified by the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2AttributeConventions.html">R2AttributeConventions</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.transforms"/><div class="st300_section_title_number"><a id="st300_p2s5" href="#st300_p2s5" title="Section 2.5: Transforms">2.5</a></div><div class="st300_section_title">Transforms</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s5ss1" title="Link to subsection 2.5.1: Overview">2.5.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s5ss2" title="Link to subsection 2.5.2: Types">2.5.2. Types</a></li></ul><div class="st300_subsection_container"><a id="di.transforms.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s5ss1" href="#st300_p2s5ss1" title="Subsection 2.5.1: Overview">2.5.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s5ss1c1" href="#st300_p2s5ss1c1" title="Paragraph 2.5.1.1">1</a></div><div class="st300_paragraph">The ultimate purpose of a <span class="st300_term term">transform</span> is to produce one or more matrices that can be combined with other matrices and then finally passed to a <span class="st300_term term">shader</span>. The shader uses these matrices to transform vertices and normal vectors during the rendering of objects.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s5ss1c2" href="#st300_p2s5ss1c2" title="Paragraph 2.5.1.2">2</a></div><div class="st300_paragraph">A transform is effectively responsible for producing a <span class="st300_term term">model matrix</span> that transforms positions in <a class="st300_link" href="#di.coords.object">object space</a> to <a class="st300_link" href="#di.coords.world">world space</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s5ss1c3" href="#st300_p2s5ss1c3" title="Paragraph 2.5.1.3">3</a></div><div class="st300_paragraph">In practical terms, a <span class="st300_term term">transform</span> is a matrix used to position, scale, and rotate <a class="st300_link" href="#di.instances">instances</a> in a scene. This is achieved by multiplying the matrix with the object space positions of all vertices of the mesh that makes up the instance during rendering.</div></div></div><div class="st300_subsection_container"><a id="di.transforms.types"/><div class="st300_subsection_title_number"><a id="st300_p2s5ss2" href="#st300_p2s5ss2" title="Subsection 2.5.2: Types">2.5.2</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s5ss2c1" href="#st300_p2s5ss2c1" title="Paragraph 2.5.2.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, transforms are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2TransformType.html">R2TransformType</a>.</div></div></div></div><div class="st300_section_container"><a id="di.instances"/><div class="st300_section_title_number"><a id="st300_p2s6" href="#st300_p2s6" title="Section 2.6: Instances">2.6</a></div><div class="st300_section_title">Instances</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s6ss1" title="Link to subsection 2.6.1: Overview">2.6.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s6ss2" title="Link to subsection 2.6.2: Single">2.6.2. Single</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s6ss3" title="Link to subsection 2.6.3: Batched">2.6.3. Batched</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s6ss4" title="Link to subsection 2.6.4: Billboarded">2.6.4. Billboarded</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s6ss5" title="Link to subsection 2.6.5: Types">2.6.5. Types</a></li></ul><div class="st300_subsection_container"><a id="di.instances.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s6ss1" href="#st300_p2s6ss1" title="Subsection 2.6.1: Overview">2.6.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss1c1" href="#st300_p2s6ss1c1" title="Paragraph 2.6.1.1">1</a></div><div class="st300_paragraph">An <span class="st300_term term">instance</span> is a renderable object. There are several types of instances available in the <span class="st300_term package">r2</span> package: <a class="st300_link" href="#di.instances.single">single</a>, <a class="st300_link" href="#di.instances.batched">batched</a>, and <a class="st300_link" href="#di.instances.billboarded">billboarded</a>.</div></div></div><div class="st300_subsection_container"><a id="di.instances.single"/><div class="st300_subsection_title_number"><a id="st300_p2s6ss2" href="#st300_p2s6ss2" title="Subsection 2.6.2: Single">2.6.2</a></div><div class="st300_subsection_title">Single</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss2c1" href="#st300_p2s6ss2c1" title="Paragraph 2.6.2.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">single</span> instance is the simplest type of instance available in the <span class="st300_term package">r2</span> package. A <span class="st300_term term">single</span> instance is simply a pair <span class="st300_term expression">(m, t)</span>, where <span class="st300_term expression">m</span> is a <a class="st300_link" href="#di.meshes">mesh</a>, and <span class="st300_term expression">t</span> is a <a class="st300_link" href="#di.transforms">transform</a> capable of transforming the <a class="st300_link" href="#di.coords.object">object space</a> coordinates of the vertices contained within <span class="st300_term expression">m</span> to <a class="st300_link" href="#di.coords.world">world space</a>.</div></div></div><div class="st300_subsection_container"><a id="di.instances.batched"/><div class="st300_subsection_title_number"><a id="st300_p2s6ss3" href="#st300_p2s6ss3" title="Subsection 2.6.3: Batched">2.6.3</a></div><div class="st300_subsection_title">Batched</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss3c1" href="#st300_p2s6ss3c1" title="Paragraph 2.6.3.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">batched</span> instance represents a group of (identical) renderable objects. The reason for the existence of <span class="st300_term term">batched</span> instances is simple efficiency: On modern rendering hardware, rendering <span class="st300_term expression">n</span> <span class="st300_term term">single</span> instances means submitting <span class="st300_term expression">n</span> <span class="st300_term term">draw calls</span> to the GPU. As <span class="st300_term expression">n</span> becomes increasingly large, the overhead of the large number of draw calls becomes a bottleneck for rendering performance. A <span class="st300_term term">batched</span> instance of size <span class="st300_term expression">m</span> allows for rendering a given mesh <span class="st300_term expression">m</span> times in a single draw call.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss3c2" href="#st300_p2s6ss3c2" title="Paragraph 2.6.3.2">2</a></div><div class="st300_paragraph">A <span class="st300_term term">batched</span> instance of size <span class="st300_term expression">n</span> is a 3-tuple <span class="st300_term expression">(m, b, t)</span>, where <span class="st300_term expression">m</span> is a <a class="st300_link" href="#di.meshes">mesh</a>, <span class="st300_term expression">b</span> is a buffer of <span class="st300_term expression">n</span> <a class="st300_link" href="#di.meshes.attributes.batched">4x4 matrices</a> allocated on the GPU, and <span class="st300_term expression">t</span> is an array of <span class="st300_term expression">n</span> <a class="st300_link" href="#di.transforms">transforms</a> allocated on the CPU. For each <span class="st300_term expression">i</span> where <span class="st300_term expression">0 &lt;= i &lt; n</span>, <span class="st300_term expression">b[i]</span> is the 4x4 model matrix produced from <span class="st300_term expression">t[i]</span>. The contents of <span class="st300_term expression">b</span> are typically recalculated and uploaded to the GPU once per rendering frame.</div></div></div><div class="st300_subsection_container"><a id="di.instances.billboarded"/><div class="st300_subsection_title_number"><a id="st300_p2s6ss4" href="#st300_p2s6ss4" title="Subsection 2.6.4: Billboarded">2.6.4</a></div><div class="st300_subsection_title">Billboarded</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss4c1" href="#st300_p2s6ss4c1" title="Paragraph 2.6.4.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">billboarded</span> instance is a further specialization of <span class="st300_term term">batched</span> instances. <span class="st300_term term">Billboarding</span> is the name given to a rendering technique where instead of rendering full 3D objects, simple 2D images of those objects are rendered instead using flat rectangles that are arranged such that they are always facing directly towards the observer.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s6ss4c2" href="#st300_p2s6ss4c2" title="Formal item 2.6.4.2: Billboarded Render">2.6.4.2 Billboarded Render</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Billboarding" src="images/billboard_render.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s6ss4c3" href="#st300_p2s6ss4c3" title="Formal item 2.6.4.3: Billboarded Wireframe">2.6.4.3 Billboarded Wireframe</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Billboarding in wireframe view" src="images/billboard_wire.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s6ss4c4" href="#st300_p2s6ss4c4" title="Formal item 2.6.4.4: Billboarded Wireframe (Side)">2.6.4.4 Billboarded Wireframe (Side)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Billboarding in wireframe side view" src="images/billboard_wire_side.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss4c5" href="#st300_p2s6ss4c5" title="Paragraph 2.6.4.5">5</a></div><div class="st300_paragraph">A <span class="st300_term term">billboarded</span> instance of size <span class="st300_term expression">n</span> is a pair <span class="st300_term expression">(m, p)</span>, where <span class="st300_term expression">m</span> is a <a class="st300_link" href="#di.meshes">mesh</a> <span class="st300_footnote_reference">[<a href="#st300_f_6193_0" id="st300_fr_6170" title="Jump to footnote di.instances.unit_quad (reference 0)">13</a>]</span>, and <span class="st300_term expression">p</span> is a buffer of <span class="st300_term expression">n</span> <a class="st300_link" href="#di.coords.world">world space</a> positions allocated on the GPU.</div></div></div><div class="st300_subsection_container"><a id="di.instances.types"/><div class="st300_subsection_title_number"><a id="st300_p2s6ss5" href="#st300_p2s6ss5" title="Subsection 2.6.5: Types">2.6.5</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s6ss5c1" href="#st300_p2s6ss5c1" title="Paragraph 2.6.5.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, instances are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2InstanceType.html">R2InstanceType</a>.</div></div></div></div><div class="st300_section_container"><a id="di.render-target"/><div class="st300_section_title_number"><a id="st300_p2s7" href="#st300_p2s7" title="Section 2.7: Render Targets">2.7</a></div><div class="st300_section_title">Render Targets</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s7ss1" title="Link to subsection 2.7.1: Overview">2.7.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s7ss2" title="Link to subsection 2.7.2: Types">2.7.2. Types</a></li></ul><div class="st300_subsection_container"><a id="di.render-target.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s7ss1" href="#st300_p2s7ss1" title="Subsection 2.7.1: Overview">2.7.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s7ss1c1" href="#st300_p2s7ss1c1" title="Paragraph 2.7.1.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">render target</span> is a rectangular region of memory allocated on the GPU that can accept the results of a rendering operation.</div></div></div><div class="st300_subsection_container"><a id="di.render-target.types"/><div class="st300_subsection_title_number"><a id="st300_p2s7ss2" href="#st300_p2s7ss2" title="Subsection 2.7.2: Types">2.7.2</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s7ss2c1" href="#st300_p2s7ss2c1" title="Paragraph 2.7.2.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, render targets are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2RenderTargetType.html">R2RenderTargetType</a>.</div></div></div></div><div class="st300_section_container"><a id="di.shaders"/><div class="st300_section_title_number"><a id="st300_p2s8" href="#st300_p2s8" title="Section 2.8: Shaders">2.8</a></div><div class="st300_section_title">Shaders</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s8ss1" title="Link to subsection 2.8.1: Overview">2.8.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s8ss2" title="Link to subsection 2.8.2: Interface And Calling Protocol">2.8.2. Interface And Calling Protocol</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s8ss3" title="Link to subsection 2.8.3: Shader Modules">2.8.3. Shader Modules</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s8ss4" title="Link to subsection 2.8.4: Types">2.8.4. Types</a></li></ul><div class="st300_subsection_container"><a id="di.shaders.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s8ss1" href="#st300_p2s8ss1" title="Subsection 2.8.1: Overview">2.8.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss1c1" href="#st300_p2s8ss1c1" title="Paragraph 2.8.1.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">shader</span> is a small program that executes on the GPU and is used to produce images. In the <span class="st300_term package">r2</span> package, shaders perform a variety of tasks and the programmer is not always exposed to them directly. The primary shader types to which the programmer is directly exposed are <a class="st300_link" href="#di.shaders.instance">instance</a> and <a class="st300_link" href="#di.shaders.light">light</a> shaders.</div></div></div><div class="st300_subsection_container"><a id="di.shaders.interface"/><div class="st300_subsection_title_number"><a id="st300_p2s8ss2" href="#st300_p2s8ss2" title="Subsection 2.8.2: Interface And Calling Protocol">2.8.2</a></div><div class="st300_subsection_title">Interface And Calling Protocol</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss2c1" href="#st300_p2s8ss2c1" title="Paragraph 2.8.2.1">1</a></div><div class="st300_paragraph">Every shader in the <span class="st300_term package">r2</span> package has an associated Java class. Each class may implement one of the interfaces that are themselves subtypes of the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderType.html">R2ShaderType</a> interface. Each class is responsible for uploading parameters to the actual compiled GLSL shader on the GPU. Certain parameters, such as view matrices, the current size of the screen, etc, are only calculated during each rendering pass and therefore will be supplied to the shader classes at more or less the last possible moment. The calculated parameters are supplied via methods defined on the <span class="st300_term type">R2ShaderType</span> subinterfaces, and implementations of the subinterfaces can rely on the methods being called in a very strict predefined order. For example, instances of type <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderInstanceSingleUsableType.html">R2ShaderInstanceSingleUsableType</a> will receive calls in exactly this order:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s8ss2c2" href="#st300_p2s8ss2c2" title="Formal item 2.8.2.2: R2ShaderInstanceSingleUsableType call order">2.8.2.2 R2ShaderInstanceSingleUsableType call order</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">First, <span class="st300_term function">onActivate</span> will be called. It is the class's responsibility to <span class="st300_term term">activate</span> the GLSL shader at this point.</li><li class="st300_list_item">Then <span class="st300_term function">onReceiveViewValues</span> will be called when the current view-specific values have been calculated.</li><li class="st300_list_item">Now, for each material <span class="st300_term expression">m</span> that uses the current shader: <ol class="st300_list_ordered"><li class="st300_list_item"><span class="st300_term function">onReceiveMaterialValues</span> will be called once.</li><li class="st300_list_item">For each instance <span class="st300_term expression">i</span> using that uses a material that uses the current shader, <span class="st300_term function">onReceiveInstanceTransformValues</span> will be called, followed by <span class="st300_term function">onValidate</span>.</li></ol></li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss2c3" href="#st300_p2s8ss2c3" title="Paragraph 2.8.2.3">3</a></div><div class="st300_paragraph">The final <span class="st300_term function">onValidate</span> call allows the shader to check that all of the required method calls have actually been made by the caller, and the method is permitted to throw <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2ExceptionShaderValidationFailed.html">R2ExceptionShaderValidationFailed</a> if the caller makes a mistake at any point. The implicit promise is that callers will call all of the methods in the correct order and the correct number of times, and shaders are allowed to loudly complain if and when this does not happen.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss2c4" href="#st300_p2s8ss2c4" title="Paragraph 2.8.2.4">4</a></div><div class="st300_paragraph">Of course, actually requiring the programmer to manually implement all of the above for each new shader would be unreasonable and would just become a new source of bugs. The <span class="st300_term package">r2</span> provides <span class="st300_term term">verifiers</span> to perform the run-time checks listed above without forcing the programmer to implement them all manually. The <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderInstanceSingleVerifier.html">R2ShaderInstanceSingleVerifier</a> type, for example, implements the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderInstanceSingleUsableType.html">R2ShaderInstanceSingleUsableType</a> interface and wraps call calls to an existing shader in calls that enforce the invariants and call order described above. The programmer writes the simple version of the shader that simply uploads parameters, and the <span class="st300_term term">verifier</span> prevents callers from calling shader methods in the wrong order.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss2c5" href="#st300_p2s8ss2c5" title="Paragraph 2.8.2.5">5</a></div><div class="st300_paragraph">The calling protocol described both ensures that all shader parameters will be set and that the renderers themselves are insulated from the interfaces of actual GLSL shaders. Failing to set parameters, attempting to set parameters that no longer exist, or passing values of the wrong types to GLSL shaders is a common source of bugs in OpenGL programs and almost always results in either silent failure or corrupted visuals. The <span class="st300_term package">r2</span> package takes care to ensure that mistakes of that type are difficult to make.</div></div></div><div class="st300_subsection_container"><a id="di.shaders.modules"/><div class="st300_subsection_title_number"><a id="st300_p2s8ss3" href="#st300_p2s8ss3" title="Subsection 2.8.3: Shader Modules">2.8.3</a></div><div class="st300_subsection_title">Shader Modules</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss3c1" href="#st300_p2s8ss3c1" title="Paragraph 2.8.3.1">1</a></div><div class="st300_paragraph">Although the GLSL shading language is anti-modular in the sense that it has one large namespace, the <span class="st300_term package">r2</span> package attempts to relieve some of the pain of shader management by delegating to the <a class="st300_link_external" href="http://io7m.github.io/sombrero">sombrero</a> package. The <span class="st300_term package">sombrero</span> package provides a preprocessor for shader code, allowing shader code to make use of <span class="st300_term function">#include</span> directives. It also provides a system for publishing and importing modules full of shaders based internally on the standard Java <a class="st300_link_external" href="https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html">ServiceLoader</a> API. This allows users that want to write their own shaders to import much of the re-usable shader code from the <span class="st300_term package">r2</span> package into their own shaders without needing to do anything more than have the correct shader jar on the Java classpath <span class="st300_footnote_reference">[<a href="#st300_f_7086_0" id="st300_fr_6994" title="Jump to footnote di.shaders.modules.classpath (reference 0)">14</a>]</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss3c2" href="#st300_p2s8ss3c2" title="Paragraph 2.8.3.2">2</a></div><div class="st300_paragraph">As a simple example, if the user writing custom shaders wants to take advantage of the bilinear interpolation functions used in many <span class="st300_term package">r2</span> shaders, the following <span class="st300_term function">#include</span> is sufficient:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s8ss3c3" href="#st300_p2s8ss3c3" title="Formal item 2.8.3.3: Include">2.8.3.3 Include</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">#include &lt;com.io7m.r2.shaders.core/R2Bilinear.h&gt;

vec3 x = R2_bilinearInterpolate3(...);</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss3c4" href="#st300_p2s8ss3c4" title="Paragraph 2.8.3.4">4</a></div><div class="st300_paragraph">The text <span class="st300_term package">com.io7m.r2.shaders.core</span> is considered to be the module name, and the <span class="st300_term file">R2Bilinear.h</span> name refers to that file within the module. The <span class="st300_term package">sombrero</span> resolver maps the request to a concrete resource on the filesystem or in a jar file and returns the content for inclusion.</div></div></div><div class="st300_subsection_container"><a id="di.shaders.types"/><div class="st300_subsection_title_number"><a id="st300_p2s8ss4" href="#st300_p2s8ss4" title="Subsection 2.8.4: Types">2.8.4</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s8ss4c1" href="#st300_p2s8ss4c1" title="Paragraph 2.8.4.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, shaders are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderType.html">R2ShaderType</a>.</div></div></div></div><div class="st300_section_container"><a id="di.shaders.instance"/><div class="st300_section_title_number"><a id="st300_p2s9" href="#st300_p2s9" title="Section 2.9: Shaders: Instance">2.9</a></div><div class="st300_section_title">Shaders: Instance</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s9ss1" title="Link to subsection 2.9.1: Overview">2.9.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s9ss2" title="Link to subsection 2.9.2: Materials">2.9.2. Materials</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s9ss3" title="Link to subsection 2.9.3: Provided Shaders">2.9.3. Provided Shaders</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s9ss4" title="Link to subsection 2.9.4: Types">2.9.4. Types</a></li></ul><div class="st300_subsection_container"><a id="di.shaders.instance.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s9ss1" href="#st300_p2s9ss1" title="Subsection 2.9.1: Overview">2.9.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s9ss1c1" href="#st300_p2s9ss1c1" title="Paragraph 2.9.1.1">1</a></div><div class="st300_paragraph">An <span class="st300_term term">instance shader</span> is a shader used to render the surfaces of <a class="st300_link" href="#di.instances">instances</a>. Depending on the context, this may mean rendering the surface attributes of the instances into a <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a>, <span class="st300_term term">forward rendering</span> the instance directly to the screen (or
other image) , rendering only the <a class="st300_link" href="#di.shadows.variance">depth</a> of the surface, or perhaps not producing any output at all as shaders used simply for <a class="st300_link" href="#di.stencil">stencilling</a> are permitted to do. Instance shaders are most often exposed to the programmer via <a class="st300_link" href="#di.shaders.instance.material">materials</a>.</div></div></div><div class="st300_subsection_container"><a id="di.shaders.instance.material"/><div class="st300_subsection_title_number"><a id="st300_p2s9ss2" href="#st300_p2s9ss2" title="Subsection 2.9.2: Materials">2.9.2</a></div><div class="st300_subsection_title">Materials</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s9ss2c1" href="#st300_p2s9ss2c1" title="Paragraph 2.9.2.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">material</span> is a pair <span class="st300_term expression">(s, i, p)</span> where <span class="st300_term expression">p</span> is a value of type <span class="st300_term expression">m</span> that represents a set of shader parameters, <span class="st300_term expression">s</span> is a shader that takes parameters of type <span class="st300_term expression">m</span>, and <span class="st300_term expression">i</span> is a unique identifier for the material. Materials primarily exist to facilitate <a class="st300_link" href="#di.deferred.geom.ordering">batching</a>: By assigning each material a unique identifier, the system can assume that two materials are the same if they have the same identifier, without needing to perform a relatively expensive structural equality comparison between the shaders and shader parameters.</div></div></div><div class="st300_subsection_container"><a id="di.shaders.instance.provided"/><div class="st300_subsection_title_number"><a id="st300_p2s9ss3" href="#st300_p2s9ss3" title="Subsection 2.9.3: Provided Shaders">2.9.3</a></div><div class="st300_subsection_title">Provided Shaders</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s9ss3c1" href="#st300_p2s9ss3c1" title="Paragraph 2.9.3.1">1</a></div><div class="st300_paragraph">Writing shaders is difficult. The programmer must be aware of an endless series of pitfalls inherent in the OpenGL API and the shading language. While the <span class="st300_term package">r2</span> package does allow users to write their own shaders, the intention has always been to provide a small set of general purpose shaders that cover the majority of the use cases in modern games and simulations. The instance shaders provided by default are:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s9ss3c2" href="#st300_p2s9ss3c2" title="Formal item 2.9.3.2: Provided instance shaders">2.9.3.2 Provided instance shaders</a></div><div class="st300_formal_item_content"><table class="st300_table shaders" summary="Provided instance shaders"><thead class="st300_table_head"><tr><th class="st300_table_column_name">Shader</th><th class="st300_table_column_name">Description</th></tr></thead><tbody class="st300_table_body"><tr><td class="st300_table_cell"><a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/provided/R2SurfaceShaderBasicSingle.html">R2SurfaceShaderBasicSingle</a></td><td class="st300_table_cell">Basic textured surface with normal mapping, specular mapping, emission mapping, and conditional discarding based on alpha.</td></tr><tr><td class="st300_table_cell"><a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/provided/R2SurfaceShaderBasicReflectiveSingle.html">R2SurfaceShaderBasicReflectiveSingle</a></td><td class="st300_table_cell">Basic textured surface with pseudo reflections from a cube map, normal mapping, specular mapping, emission mapping, and conditional discarding based on alpha.</td></tr></tbody></table></div></div></div><div class="st300_subsection_container"><a id="di.shaders.instance.types"/><div class="st300_subsection_title_number"><a id="st300_p2s9ss4" href="#st300_p2s9ss4" title="Subsection 2.9.4: Types">2.9.4</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s9ss4c1" href="#st300_p2s9ss4c1" title="Paragraph 2.9.4.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, materials are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2MaterialType.html">R2MaterialType</a>. Geometry renderers primarily consume instances that are associated with values of the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2MaterialOpaqueSingleType.html">R2MaterialOpaqueSingleType</a> and <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2MaterialOpaqueBatchedType.html">R2MaterialOpaqueBatchedType</a> types. Instance shaders are instances of the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderInstanceSingle.html">R2ShaderInstanceSingleType</a> and <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderInstanceBatched.html">R2ShaderInstanceBatchedType</a> types.</div></div></div></div><div class="st300_section_container"><a id="di.shaders.light"/><div class="st300_section_title_number"><a id="st300_p2s10" href="#st300_p2s10" title="Section 2.10: Shaders: Light">2.10</a></div><div class="st300_section_title">Shaders: Light</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s10ss1" title="Link to subsection 2.10.1: Overview">2.10.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s10ss2" title="Link to subsection 2.10.2: Types">2.10.2. Types</a></li></ul><div class="st300_subsection_container"><a id="di.shaders.light.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s10ss1" href="#st300_p2s10ss1" title="Subsection 2.10.1: Overview">2.10.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s10ss1c1" href="#st300_p2s10ss1c1" title="Paragraph 2.10.1.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">light shader</span> is a shader used to render the contributions of a <a class="st300_link" href="#di.deferred.light">light source</a>. Light shaders in the <span class="st300_term package">r2</span> package are only used within the context of <a class="st300_link" href="#di.deferred">deferred rendering</a>.</div></div></div><div class="st300_subsection_container"><a id="di.shaders.light.types"/><div class="st300_subsection_title_number"><a id="st300_p2s10ss2" href="#st300_p2s10ss2" title="Subsection 2.10.2: Types">2.10.2</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s10ss2c1" href="#st300_p2s10ss2c1" title="Paragraph 2.10.2.1">1</a></div><div class="st300_paragraph">Light shaders are instances of the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderLightSingleType.html">R2ShaderLightSingleType</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.stencil"/><div class="st300_section_title_number"><a id="st300_p2s11" href="#st300_p2s11" title="Section 2.11: Stencils">2.11</a></div><div class="st300_section_title">Stencils</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s11ss1" title="Link to subsection 2.11.1: Overview">2.11.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s11ss2" title="Link to subsection 2.11.2: Reserved Bits">2.11.2. Reserved Bits</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s11ss3" title="Link to subsection 2.11.3: Allow Bit">2.11.3. Allow Bit</a></li></ul><div class="st300_subsection_container"><a id="di.stencil.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s11ss1" href="#st300_p2s11ss1" title="Subsection 2.11.1: Overview">2.11.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss1c1" href="#st300_p2s11ss1c1" title="Paragraph 2.11.1.1">1</a></div><div class="st300_paragraph">The <span class="st300_term term">stencil buffer</span> enables per-pixel control over rendering. The <span class="st300_term package">r2</span> package uses the stencil buffer to implement several rendering techniques internally, and also exposes limited control of the stencil buffer to users of the renderer via the <a class="st300_link" href="#di.stencil.allow_bit">allow bit</a>.</div></div></div><div class="st300_subsection_container"><a id="di.stencil.reserved"/><div class="st300_subsection_title_number"><a id="st300_p2s11ss2" href="#st300_p2s11ss2" title="Subsection 2.11.2: Reserved Bits">2.11.2</a></div><div class="st300_subsection_title">Reserved Bits</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss2c1" href="#st300_p2s11ss2c1" title="Paragraph 2.11.2.1">1</a></div><div class="st300_paragraph">The current stencil buffer layout used by the <span class="st300_term package">r2</span> package is as follows:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s11ss2c2" href="#st300_p2s11ss2c2" title="Formal item 2.11.2.2: Reserved bits">2.11.2.2 Reserved bits</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Reserved stencil bits." src="images/stencil_bits.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss2c3" href="#st300_p2s11ss2c3" title="Paragraph 2.11.2.3">3</a></div><div class="st300_paragraph">Bit <span class="st300_term constant">0</span> is used for <a class="st300_link" href="#di.deferred.light.clip_volumes">light clip volumes</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss2c4" href="#st300_p2s11ss2c4" title="Paragraph 2.11.2.4">4</a></div><div class="st300_paragraph">Bits <span class="st300_term constant">1-2</span> are reserved for future use.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss2c5" href="#st300_p2s11ss2c5" title="Paragraph 2.11.2.5">5</a></div><div class="st300_paragraph">Bits <span class="st300_term constant">3-6</span> are used for <a class="st300_link" href="#di.deferred.geom.group">groups</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss2c6" href="#st300_p2s11ss2c6" title="Paragraph 2.11.2.6">6</a></div><div class="st300_paragraph">Bit <span class="st300_term constant">7</span> is the <a class="st300_link" href="#di.stencil.allow_bit">allow bit</a>.</div></div></div><div class="st300_subsection_container"><a id="di.stencil.allow_bit"/><div class="st300_subsection_title_number"><a id="st300_p2s11ss3" href="#st300_p2s11ss3" title="Subsection 2.11.3: Allow Bit">2.11.3</a></div><div class="st300_subsection_title">Allow Bit</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss3c1" href="#st300_p2s11ss3c1" title="Paragraph 2.11.3.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package reserves a single bit in the current stencil buffer, known as the <span class="st300_term term">allow bit</span>. In all subsequent rendering operations, a pixel may only be written if the corresponding allow bit in the stencil buffer is <span class="st300_term constant">true</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s11ss3c2" href="#st300_p2s11ss3c2" title="Paragraph 2.11.3.2">2</a></div><div class="st300_paragraph">The stencil buffer allow bits are populated via the use of a <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2StencilRendererType.html">stencil renderer</a>. The user specifies a series of <a class="st300_link" href="#di.instances">instances</a> whose only purpose is to either enable or disable the allow bit for each rendered pixel. Users may specify whether instances are <span class="st300_term term">positive</span> or <span class="st300_term term">negative</span>. Positive instances set the allow bit to <span class="st300_term constant">true</span> for each overlapped pixel, and negative instances set the allow bit to <span class="st300_term constant">false</span> for each overlapped pixel.</div></div></div></div><div class="st300_section_container"><a id="di.lighting"/><div class="st300_section_title_number"><a id="st300_p2s12" href="#st300_p2s12" title="Section 2.12: Lighting">2.12</a></div><div class="st300_section_title">Lighting</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s12ss1" title="Link to subsection 2.12.1: Overview">2.12.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s12ss2" title="Link to subsection 2.12.2: Diffuse/Specular Terms">2.12.2. Diffuse/Specular Terms</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s12ss3" title="Link to subsection 2.12.3: Diffuse-Only Lights">2.12.3. Diffuse-Only Lights</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s12ss4" title="Link to subsection 2.12.4: Attenuation">2.12.4. Attenuation</a></li></ul><div class="st300_subsection_container"><a id="di.lighting.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s12ss1" href="#st300_p2s12ss1" title="Subsection 2.12.1: Overview">2.12.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss1c1" href="#st300_p2s12ss1c1" title="Paragraph 2.12.1.1">1</a></div><div class="st300_paragraph">The following sections of documentation attempt to describe the theory and implementation of <span class="st300_term term">lighting</span> in the <span class="st300_term package">r2</span> package. All lighting in the package is <span class="st300_term term">dynamic</span>- there is no support for precomputed lighting and all contributions from lights are recalculated every time a scene is rendered. Lighting is configured by adding instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2LightType.html">R2LightType</a> to a scene.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.diffuse-specular"/><div class="st300_subsection_title_number"><a id="st300_p2s12ss2" href="#st300_p2s12ss2" title="Subsection 2.12.2: Diffuse/Specular Terms">2.12.2</a></div><div class="st300_subsection_title">Diffuse/Specular Terms</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss2c1" href="#st300_p2s12ss2c1" title="Paragraph 2.12.2.1">1</a></div><div class="st300_paragraph">The light applied to a surface by a given light is divided into <span class="st300_term term">diffuse</span> and <span class="st300_term term">specular</span> terms <span class="st300_footnote_reference">[<a href="#st300_f_8557_0" id="st300_fr_7978" title="Jump to footnote di.lighting.no_ambient (reference 0)">15</a>]</span>. The actual light applied to a surface is dependent upon the properties of the surface. Conceptually, the diffuse and specular terms are multiplied by the final color of the surface and summed. In practice, the materials applied to surfaces have control over how light is actually applied to the surface. For example, materials may include a <span class="st300_term term">specular map</span> which is used to manipulate the specular term as it is applied to the surface. Additionally, if a light supports <span class="st300_term term">attenuation</span>, then the diffuse and specular terms are scaled by the attenuation factor prior to being applied.</div></div><div class="st300_paragraph_container"><a id="di.lighting.diffuse"/><div class="st300_paragraph_number"><a id="st300_p2s12ss2c2" href="#st300_p2s12ss2c2" title="Paragraph 2.12.2.2">2</a></div><div class="st300_paragraph">The <span class="st300_term term">diffuse</span> term is modelled by <a class="st300_link_external" href="http://en.wikipedia.org/wiki/Lambertian_reflectance">Lambertian reflectance</a>. Specifically, the amount of diffuse light reflected from a surface is given by <span class="st300_term function">diffuse</span> in <a class="st300_link_external" href="haskell/LightDiffuse.hs">LightDiffuse.hs</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss2c3" href="#st300_p2s12ss2c3" title="Formal item 2.12.2.3: Diffuse term">2.12.2.3 Diffuse term</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module LightDiffuse where

import qualified Color3
import qualified Direction
import qualified Normal
import qualified Spaces
import qualified Vector3f

diffuse ::  Direction.T Spaces.Eye -&gt; Normal.T -&gt; Color3.T -&gt; Float -&gt; Vector3f.T
diffuse stl n light_color light_intensity =
  let 
    factor       = max 0.0 (Vector3f.dot3 stl n)
    light_scaled = Vector3f.scale light_color light_intensity
  in 
    Vector3f.scale light_scaled factor</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss2c4" href="#st300_p2s12ss2c4" title="Paragraph 2.12.2.4">4</a></div><div class="st300_paragraph">Where <span class="st300_term variable">stl</span> is a unit length direction vector from the surface to the light source, <span class="st300_term variable">n</span> is the surface normal vector, <span class="st300_term variable">light_color</span> is the light color, and <span class="st300_term variable">light_intensity</span> is the light intensity. Informally, the algorithm determines how much diffuse light should be reflected from a surface based on how directly that surface points towards the light. When <span class="st300_term expression">stl == n</span>, <span class="st300_term expression">Vector3f.dot3 stl n == 1.0</span>, and therefore the light is reflected exactly as received. When <span class="st300_term expression">stl</span> is perpendicular to <span class="st300_term expression">n</span> (such that <span class="st300_term expression">Vector3f.dot3 stl n == 0.0</span> ), no light is reflected at all. If the two directions are greater than <span class="st300_term constant">90°</span> perpendicular, the dot product is negative, but the algorithm clamps negative values to <span class="st300_term constant">0.0</span> so the effect is the same.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss2c5" href="#st300_p2s12ss2c5" title="Formal item 2.12.2.5: Diffuse light">2.12.2.5 Diffuse light</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Diffuse light" src="images/directional_diffuse.png"/></div></div><div class="st300_paragraph_container"><a id="di.lighting.specular"/><div class="st300_paragraph_number"><a id="st300_p2s12ss2c6" href="#st300_p2s12ss2c6" title="Paragraph 2.12.2.6">6</a></div><div class="st300_paragraph">The specular term is modelled either by <a class="st300_link_external" href="http://en.wikipedia.org/wiki/Phong_reflection_model">Phong</a> or <a class="st300_link_external" href="https://en.wikipedia.org/wiki/Blinn%E2%80%93Phong_shading_model">Blinn-Phong</a> reflection. The <span class="st300_term package">r2</span> package provides light shaders that provide both Phong and Blinn-Phong specular lighting and the user may freely pick between implementations. For the sake of simplicity, the rest of this documentation assumes that Blinn-Phong shading is being used. Specifically, the amount of specular light reflected from a surface is given by <span class="st300_term function">specularBlinnPhong</span> in <a class="st300_link_external" href="haskell/LightSpecular.hs">LightSpecular.hs</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss2c7" href="#st300_p2s12ss2c7" title="Formal item 2.12.2.7: Specular Term">2.12.2.7 Specular Term</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module LightSpecular where

import qualified Color3
import qualified Direction
import qualified Normal
import qualified Reflection
import qualified Spaces
import qualified Specular
import qualified Vector3f

specularPhong :: Direction.T Spaces.Eye -&gt; Direction.T Spaces.Eye -&gt; Normal.T -&gt; Color3.T -&gt; Float -&gt; Specular.T -&gt; Vector3f.T
specularPhong stl view n light_color light_intensity (Specular.S surface_spec surface_exponent) =
  let 
    reflection   = Reflection.reflection view n
    factor       = (max 0.0 (Vector3f.dot3 reflection stl)) ** surface_exponent
    light_raw    = Vector3f.scale light_color light_intensity
    light_scaled = Vector3f.scale light_raw factor
  in 
    Vector3f.mult3 light_scaled surface_spec

specularBlinnPhong :: Direction.T Spaces.Eye -&gt; Direction.T Spaces.Eye -&gt; Normal.T -&gt; Color3.T -&gt; Float -&gt; Specular.T -&gt; Vector3f.T
specularBlinnPhong stl view n light_color light_intensity (Specular.S surface_spec surface_exponent) =
  let
    reflection   = Reflection.reflection view n
    factor       = (max 0.0 (Vector3f.dot3 reflection stl)) ** surface_exponent
    light_raw    = Vector3f.scale light_color light_intensity
    light_scaled = Vector3f.scale light_raw factor
  in
    Vector3f.mult3 light_scaled surface_spec</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss2c8" href="#st300_p2s12ss2c8" title="Paragraph 2.12.2.8">8</a></div><div class="st300_paragraph">Where <span class="st300_term variable">stl</span> is a unit length direction vector from the surface to the light source, <span class="st300_term variable">view</span> is a unit length direction vector from the observer to the surface, <span class="st300_term variable">n</span> is the surface normal vector, <span class="st300_term variable">light_color</span> is the light color, <span class="st300_term variable">light_intensity</span> is the light intensity, <span class="st300_term variable">surface_exponent</span> is the <span class="st300_term term">specular exponent</span> defined by the surface, and <span class="st300_term variable">surface_spec</span> is the surface specularity factor.</div></div><div class="st300_paragraph_container"><a id="di.lighting.diffuse-specular.specular-exponent"/><div class="st300_paragraph_number"><a id="st300_p2s12ss2c9" href="#st300_p2s12ss2c9" title="Paragraph 2.12.2.9">9</a></div><div class="st300_paragraph">The specular exponent is a value, ordinarily in the range <span class="st300_term expression">[0, 255]</span>, that controls how sharp the <span class="st300_term term">specular highlights</span> appear on the surface. The exponent is a property of the surface, as opposed to being a property of the light. Low specular exponents result in soft and widely dispersed specular highlights (giving the appearance of a rough surface), while high specular exponents result in hard and focused highlights (giving the appearance of a polished surface). As an example, three models lit with progressively lower specular exponents from left to right ( <span class="st300_term constant">128</span>, <span class="st300_term constant">32</span>, and <span class="st300_term constant">8</span>, respectively):</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss2c10" href="#st300_p2s12ss2c10" title="Formal item 2.12.2.10: Specular exponents">2.12.2.10 Specular exponents</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Specular exponents" src="images/directional_specular_exponents.png"/></div></div></div><div class="st300_subsection_container"><a id="di.lighting.diffuse-only"/><div class="st300_subsection_title_number"><a id="st300_p2s12ss3" href="#st300_p2s12ss3" title="Subsection 2.12.3: Diffuse-Only Lights">2.12.3</a></div><div class="st300_subsection_title">Diffuse-Only Lights</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss3c1" href="#st300_p2s12ss3c1" title="Paragraph 2.12.3.1">1</a></div><div class="st300_paragraph">Some lights have <span class="st300_term term">diffuse-only</span> variants. Little explanation is required: The <a class="st300_link" href="#di.lighting.specular">specular</a> term is simply not calculated and only the <span class="st300_term term">diffuse</span> term is used.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.attenuation"/><div class="st300_subsection_title_number"><a id="st300_p2s12ss4" href="#st300_p2s12ss4" title="Subsection 2.12.4: Attenuation">2.12.4</a></div><div class="st300_subsection_title">Attenuation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c1" href="#st300_p2s12ss4c1" title="Paragraph 2.12.4.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Attenuation</span> is the property of the influence of a given light on a surface in inverse proportion to the distance from the light to the surface. In other words, for lights that support attenuation, the further a surface is from a light source, the less that surface will appear to be lit by the light. For light types that support attenuation, an <span class="st300_term term">attenuation factor</span> is calculated based on a given <span class="st300_term variable">inverse_maximum_range</span> (where the <span class="st300_term variable">maximum_range</span> is a light-type specific positive value that represents the maximum possible range of influence for the light), a configurable <span class="st300_term term">inverse falloff</span> value, and the current <span class="st300_term variable">distance</span> between the surface being lit and the light source. The attenuation factor is a value in the range <span class="st300_term expression">[0.0, 1.0]</span>, with <span class="st300_term expression">1.0</span> meaning "no attenuation" and <span class="st300_term expression">0.0</span> meaning "maximum attenuation". The resulting attenuation factor is multiplied by the raw unattenuated light values produced for the light in order to produce the illusion of distance attenuation. Specifically:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss4c2" href="#st300_p2s12ss4c2" title="Formal item 2.12.4.2: Attenuation">2.12.4.2 Attenuation</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module Attenuation where

attenuation_from_inverses :: Float -&gt; Float -&gt; Float -&gt; Float
attenuation_from_inverses inverse_maximum_range inverse_falloff distance =
  max 0.0 (1.0 - (distance * inverse_maximum_range) ** inverse_falloff)

attenuation :: Float -&gt; Float -&gt; Float -&gt; Float
attenuation maximum_range falloff distance =
  attenuation_from_inverses (1.0 / maximum_range) (1.0 / falloff) distance
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c3" href="#st300_p2s12ss4c3" title="Paragraph 2.12.4.3">3</a></div><div class="st300_paragraph">Given the above definitions, a number of observations can be made.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c4" href="#st300_p2s12ss4c4" title="Paragraph 2.12.4.4">4</a></div><div class="st300_paragraph">If <span class="st300_term expression">falloff == 1</span>, then the attenuation is linear over distance <span class="st300_footnote_reference">[<a href="#st300_f_8974_0" id="st300_fr_8816" title="Jump to footnote di.lighting.attenuation.geogebra (reference 0)">16</a>]</span>:</div></div><div class="st300_formal_item"><a id="di.lighting.mathematics.attenuation-linear"/><div class="st300_formal_item_title"><a id="st300_p2s12ss4c5" href="#st300_p2s12ss4c5" title="Formal item 2.12.4.5: Linear attenuation">2.12.4.5 Linear attenuation</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Linear attenuation" src="images/attenuation_linear.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c6" href="#st300_p2s12ss4c6" title="Paragraph 2.12.4.6">6</a></div><div class="st300_paragraph">If <span class="st300_term expression">maximum_range == 0</span>, then the inverse range is undefined, and therefore the results of lighting are undefined. The <span class="st300_term package">r2</span> package handles this case by raising an exception when the light is created.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c7" href="#st300_p2s12ss4c7" title="Paragraph 2.12.4.7">7</a></div><div class="st300_paragraph">If <span class="st300_term expression">falloff == 0</span>, then the inverse falloff is undefined, and therefore the results of lighting are undefined. The <span class="st300_term package">r2</span> package handles this case by raising an exception when the light is created.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c8" href="#st300_p2s12ss4c8" title="Paragraph 2.12.4.8">8</a></div><div class="st300_paragraph">As <span class="st300_term expression">falloff</span> decreases towards <span class="st300_term expression">0.0</span>, then the attenuation curve remains at <span class="st300_term expression">1.0</span> for increasingly higher distance values before falling sharply to <span class="st300_term expression">0.0</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss4c9" href="#st300_p2s12ss4c9" title="Formal item 2.12.4.9: Low falloff attenuation">2.12.4.9 Low falloff attenuation</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Low falloff attenuation" src="images/attenuation_low_falloff.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s12ss4c10" href="#st300_p2s12ss4c10" title="Paragraph 2.12.4.10">10</a></div><div class="st300_paragraph">As <span class="st300_term expression">falloff</span> increases away from <span class="st300_term expression">0.0</span>, then the attenuation curve decreases more for lower distance values:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s12ss4c11" href="#st300_p2s12ss4c11" title="Formal item 2.12.4.11: High falloff attenuation">2.12.4.11 High falloff attenuation</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="High falloff attenuation" src="images/attenuation_high_falloff.png"/></div></div></div></div><div class="st300_section_container"><a id="di.lighting.directional"/><div class="st300_section_title_number"><a id="st300_p2s13" href="#st300_p2s13" title="Section 2.13: Lighting: Directional">2.13</a></div><div class="st300_section_title">Lighting: Directional</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s13ss1" title="Link to subsection 2.13.1: Overview">2.13.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s13ss2" title="Link to subsection 2.13.2: Attenuation">2.13.2. Attenuation</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s13ss3" title="Link to subsection 2.13.3: Application">2.13.3. Application</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s13ss4" title="Link to subsection 2.13.4: Types">2.13.4. Types</a></li></ul><div class="st300_subsection_container"><a id="di.lighting.directional.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s13ss1" href="#st300_p2s13ss1" title="Subsection 2.13.1: Overview">2.13.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s13ss1c1" href="#st300_p2s13ss1c1" title="Paragraph 2.13.1.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Directional lighting</span> is the most trivial form of lighting provided by the <span class="st300_term package">r2</span> package. A directional light is a light that emits parallel rays of light in a given eye space <span class="st300_term term">direction</span>. It has a <span class="st300_term term">color</span> and an <span class="st300_term term">intensity</span>, but does not have an <span class="st300_term term">origin</span> and therefore is not attenuated over distance. It does not cause objects to cast shadows.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s13ss1c2" href="#st300_p2s13ss1c2" title="Formal item 2.13.1.2: Directional lighting">2.13.1.2 Directional lighting</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Directional lighting" src="images/directional_diagram.png"/></div></div></div><div class="st300_subsection_container"><a id="di.lighting.directional.attenuation"/><div class="st300_subsection_title_number"><a id="st300_p2s13ss2" href="#st300_p2s13ss2" title="Subsection 2.13.2: Attenuation">2.13.2</a></div><div class="st300_subsection_title">Attenuation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s13ss2c1" href="#st300_p2s13ss2c1" title="Paragraph 2.13.2.1">1</a></div><div class="st300_paragraph">Directional lights do not have origins and cannot therefore be attenuated over distance.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.directional.application"/><div class="st300_subsection_title_number"><a id="st300_p2s13ss3" href="#st300_p2s13ss3" title="Subsection 2.13.3: Application">2.13.3</a></div><div class="st300_subsection_title">Application</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s13ss3c1" href="#st300_p2s13ss3c1" title="Paragraph 2.13.3.1">1</a></div><div class="st300_paragraph">The final light applied to the surface is given by <span class="st300_term function">directional</span> <a class="st300_link_external" href="haskell/Directional.hs">(Directional.hs)</a>, where <span class="st300_term variable">sr</span>, <span class="st300_term variable">sg</span>, <span class="st300_term variable">sb</span> are the red, green, and blue channels, respectively, of the surface being lit. Note that the surface-to-light vector <span class="st300_term variable">stl</span> is simply the negation of the light direction.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s13ss3c2" href="#st300_p2s13ss3c2" title="Formal item 2.13.3.2: Directional lighting (Application)">2.13.3.2 Directional lighting (Application)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module Directional where

import qualified Color4
import qualified Direction
import qualified LightDirectional
import qualified LightDiffuse
import qualified LightSpecular
import qualified Normal
import qualified Position3
import qualified Spaces
import qualified Specular
import qualified Vector3f
import qualified Vector4f

directional :: Direction.T Spaces.Eye -&gt; Normal.T -&gt; Position3.T Spaces.Eye -&gt; LightDirectional.T -&gt; Specular.T -&gt; Color4.T -&gt; Vector3f.T
directional view n position light specular (Vector4f.V4 sr sg sb _) =
  let
    stl             = Vector3f.normalize (Vector3f.negation position)
    light_color     = LightDirectional.color light
    light_intensity = LightDirectional.intensity light
    light_d         = LightDiffuse.diffuse stl n light_color light_intensity
    light_s         = LightSpecular.specularBlinnPhong stl view n light_color light_intensity specular
    lit_d           = Vector3f.mult3 (Vector3f.V3 sr sg sb) light_d
    lit_s           = Vector3f.add3 lit_d light_s
  in
    lit_s
</pre></div></div></div><div class="st300_subsection_container"><a id="di.lighting.directional.types"/><div class="st300_subsection_title_number"><a id="st300_p2s13ss4" href="#st300_p2s13ss4" title="Subsection 2.13.4: Types">2.13.4</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s13ss4c1" href="#st300_p2s13ss4c1" title="Paragraph 2.13.4.1">1</a></div><div class="st300_paragraph">Directional lights are represented in the <span class="st300_term package">r2</span> package by the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2LightDirectionalScreenSingle.html">R2LightDirectionalScreenSingle</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.lighting.spherical"/><div class="st300_section_title_number"><a id="st300_p2s14" href="#st300_p2s14" title="Section 2.14: Lighting: Spherical">2.14</a></div><div class="st300_section_title">Lighting: Spherical</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s14ss1" title="Link to subsection 2.14.1: Overview">2.14.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s14ss2" title="Link to subsection 2.14.2: Attenuation">2.14.2. Attenuation</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s14ss3" title="Link to subsection 2.14.3: Application">2.14.3. Application</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s14ss4" title="Link to subsection 2.14.4: Types">2.14.4. Types</a></li></ul><div class="st300_subsection_container"><a id="di.lighting.spherical.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s14ss1" href="#st300_p2s14ss1" title="Subsection 2.14.1: Overview">2.14.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s14ss1c1" href="#st300_p2s14ss1c1" title="Paragraph 2.14.1.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">spherical light</span> in the <span class="st300_term package">r2</span> package is a light that emits rays of light in all directions from a given <span class="st300_term term">origin</span> specified in <a class="st300_link" href="#di.coords.eye">eye space</a> up to a given maximum <span class="st300_term term">radius</span>.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s14ss1c2" href="#st300_p2s14ss1c2" title="Formal item 2.14.1.2: Spherical lighting">2.14.1.2 Spherical lighting</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Spherical lighting" src="images/spherical_diagram.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s14ss1c3" href="#st300_p2s14ss1c3" title="Paragraph 2.14.1.3">3</a></div><div class="st300_paragraph">The term <span class="st300_term term">spherical</span> comes from the fact that the light has a defined radius. Most rendering systems instead use <span class="st300_term term">point</span> lights that specify multiple <span class="st300_term term">attenuation</span> constants to control how light is attenuated over distance. The problem with this approach is that it requires solving a quadratic equation to determine a minimum bounding sphere that can contain the light. Essentially, the programmer/artist is forced to determine "at which radius does the contribution from this light effectively reach zero?". With spherical lights, the maximum radius is declared up front, and a single falloff value is used to determine the attenuation curve within that radius. This makes spherical lights more intuitive to use: The programmer/artist simply places a sphere within the scene and knows exactly from the radius which objects are lit by it. It also means that bounding light volumes can be trivially constructed from unit spheres by simply scaling those spheres by the light radius, when performing <a class="st300_link" href="#di.deferred">deferred rendering</a>.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.spherical.attenuation"/><div class="st300_subsection_title_number"><a id="st300_p2s14ss2" href="#st300_p2s14ss2" title="Subsection 2.14.2: Attenuation">2.14.2</a></div><div class="st300_subsection_title">Attenuation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s14ss2c1" href="#st300_p2s14ss2c1" title="Paragraph 2.14.2.1">1</a></div><div class="st300_paragraph">The light supports <a class="st300_link" href="#di.lighting.attenuation">attenuation</a> using the <span class="st300_term term">radius</span> as the maximum range.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.spherical.application"/><div class="st300_subsection_title_number"><a id="st300_p2s14ss3" href="#st300_p2s14ss3" title="Subsection 2.14.3: Application">2.14.3</a></div><div class="st300_subsection_title">Application</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s14ss3c1" href="#st300_p2s14ss3c1" title="Paragraph 2.14.3.1">1</a></div><div class="st300_paragraph">The final light applied to the surface is given by <span class="st300_term function">spherical</span> <a class="st300_link_external" href="haskell/Spherical.hs">(Spherical.hs)</a>, where <span class="st300_term variable">sr</span>, <span class="st300_term variable">sg</span>, <span class="st300_term variable">sb</span> are the red, green, and blue channels, respectively, of the surface being lit. The surface-to-light vector <span class="st300_term variable">stl</span> is calculated by normalizing the negation of the difference between the the current eye space <span class="st300_term variable">surface_position</span> and the eye space origin of the light.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s14ss3c2" href="#st300_p2s14ss3c2" title="Formal item 2.14.3.2: Spherical lighting (Application)">2.14.3.2 Spherical lighting (Application)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module Spherical where

import qualified Attenuation
import qualified Color4
import qualified Direction
import qualified LightDiffuse
import qualified LightSpecular
import qualified LightSpherical
import qualified Normal
import qualified Position3
import qualified Specular
import qualified Spaces
import qualified Vector3f
import qualified Vector4f

spherical :: Direction.T Spaces.Eye -&gt; Normal.T -&gt; Position3.T Spaces.Eye -&gt; LightSpherical.T -&gt; Specular.T -&gt; Color4.T -&gt; Vector3f.T
spherical view n surface_position light specular (Vector4f.V4 sr sg sb _) =
  let
    position_diff   = Position3.sub3 surface_position (LightSpherical.origin light)
    stl             = Vector3f.normalize (Vector3f.negation position_diff)
    distance        = Vector3f.magnitude (position_diff)
    attenuation     = Attenuation.attenuation (LightSpherical.radius light) (LightSpherical.falloff light) distance
    light_color     = LightSpherical.color light
    light_intensity = LightSpherical.intensity light
    light_d         = LightDiffuse.diffuse stl n light_color light_intensity
    light_s         = LightSpecular.specularBlinnPhong stl view n light_color light_intensity specular
    light_da        = Vector3f.scale light_d attenuation
    light_sa        = Vector3f.scale light_s attenuation
    lit_d           = Vector3f.mult3 (Vector3f.V3 sr sg sb) light_da
    lit_s           = Vector3f.add3 lit_d light_sa
  in
    lit_s
</pre></div></div></div><div class="st300_subsection_container"><a id="di.lighting.spherical.types"/><div class="st300_subsection_title_number"><a id="st300_p2s14ss4" href="#st300_p2s14ss4" title="Subsection 2.14.4: Types">2.14.4</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s14ss4c1" href="#st300_p2s14ss4c1" title="Paragraph 2.14.4.1">1</a></div><div class="st300_paragraph">Spherical lights are represented in the <span class="st300_term package">r2</span> package by the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2LightSphericalSingle.html">R2LightSphericalSingle</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.lighting.projective"/><div class="st300_section_title_number"><a id="st300_p2s15" href="#st300_p2s15" title="Section 2.15: Lighting: Projective">2.15</a></div><div class="st300_section_title">Lighting: Projective</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s15ss1" title="Link to subsection 2.15.1: Overview">2.15.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s15ss2" title="Link to subsection 2.15.2: Algorithm">2.15.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s15ss3" title="Link to subsection 2.15.3: Back projection">2.15.3. Back projection</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s15ss4" title="Link to subsection 2.15.4: Clamping">2.15.4. Clamping</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s15ss5" title="Link to subsection 2.15.5: Attenuation">2.15.5. Attenuation</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s15ss6" title="Link to subsection 2.15.6: Application">2.15.6. Application</a></li></ul><div class="st300_subsection_container"><a id="di.lighting.projective.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s15ss1" href="#st300_p2s15ss1" title="Subsection 2.15.1: Overview">2.15.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss1c1" href="#st300_p2s15ss1c1" title="Paragraph 2.15.1.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">projective light</span> in the <span class="st300_term package">r2</span> package is a light that <span class="st300_term term">projects</span>  a texture onto the scene from a given <span class="st300_term term">origin</span> specified in <a class="st300_link" href="#di.coords.eye">eye space</a> up to a given maximum <span class="st300_term term">radius</span>. Projective lights are the only types of lights in the <span class="st300_term package">r2</span> package that are able to project <span class="st300_term term">shadows</span>.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss1c2" href="#st300_p2s15ss1c2" title="Formal item 2.15.1.2: Projective lighting">2.15.1.2 Projective lighting</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Projective lighting" src="images/projective.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss1c3" href="#st300_p2s15ss1c3" title="Formal item 2.15.1.3: Projective lighting (Texture)">2.15.1.3 Projective lighting (Texture)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Projective lighting (Texture)" src="images/sunflower.png"/></div></div></div><div class="st300_subsection_container"><a id="di.lighting.projective.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s15ss2" href="#st300_p2s15ss2" title="Subsection 2.15.2: Algorithm">2.15.2</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss2c1" href="#st300_p2s15ss2c1" title="Paragraph 2.15.2.1">1</a></div><div class="st300_paragraph">At a basic level, a projective light performs the same operations that occur when an ordinary 3D position is projected onto the screen during rendering. During normal rendering, a point <span class="st300_term expression">p</span> given in <a class="st300_link" href="#di.coords.world">world space</a> is transformed to <a class="st300_link" href="#di.coords.eye">eye space</a> given the current camera's <span class="st300_term term">view matrix</span>, and is then transformed to <a class="st300_link" href="#di.coords.clip">clip space</a> using the current camera's <span class="st300_term term">projection matrix</span>. During rendering of a scene lit by a projective light, a given point <span class="st300_term expression">q</span> in the scene is transformed back to <span class="st300_term term">world space</span> given the current camera's <span class="st300_term term">inverse view matrix</span>, and is then transformed to <span class="st300_term term">eye space from the point of view of the light</span> (subsequently referred to as <span class="st300_term term">light eye space</span>) using the light's <span class="st300_term term">view matrix</span>. Finally, <span class="st300_term expression">q</span> is transformed to <span class="st300_term term">clip space from the point of view of the light</span> (subsequently referred to as <span class="st300_term term">light clip space</span>) using the light's <span class="st300_term term">projection matrix</span>. It should be noted (in order to indicate that there is nothing unusual about the light's view or projection matrices) that if the camera and light have the same position, orientation, scale, and projection, then the resulting transformed values of <span class="st300_term expression">q</span> and <span class="st300_term expression">p</span> are identical. The resulting transformed value of <span class="st300_term expression">q</span> is mapped from the range <span class="st300_term expression">[(-1, -1, -1), (1, 1, 1)]</span> to <span class="st300_term expression">[(0, 0, 0), (1, 1, 1)]</span>, and the resulting coordinates are used to retrieve a texel from the 2D texture associated with the light.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss2c2" href="#st300_p2s15ss2c2" title="Paragraph 2.15.2.2">2</a></div><div class="st300_paragraph">Intuitively, an ordinary <span class="st300_term term">perspective projection</span> will cause the light to appear to take the shape of a <span class="st300_term term">frustum</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss2c3" href="#st300_p2s15ss2c3" title="Formal item 2.15.2.3: Projective lighting (Frustum)">2.15.2.3 Projective lighting (Frustum)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Projective lighting (Frustum)" src="images/projective_frustum.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss2c4" href="#st300_p2s15ss2c4" title="Paragraph 2.15.2.4">4</a></div><div class="st300_paragraph">There are two issues with the projective lighting algorithm that also have to be solved: <a class="st300_link" href="#di.lighting.projective.back-projection">back projection</a> and <a class="st300_link" href="#di.lighting.projective.clamping">clamping</a>.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.projective.back-projection"/><div class="st300_subsection_title_number"><a id="st300_p2s15ss3" href="#st300_p2s15ss3" title="Subsection 2.15.3: Back projection">2.15.3</a></div><div class="st300_subsection_title">Back projection</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss3c1" href="#st300_p2s15ss3c1" title="Paragraph 2.15.3.1">1</a></div><div class="st300_paragraph">The <a class="st300_link" href="#di.lighting.projective.algorithm">algorithm</a> described above will produce a so-called <span class="st300_term term">dual</span> or <span class="st300_term term">back projection</span>. In other words, the texture will be projected along the view direction of the camera, but will also be projected along the <span class="st300_term term">negative</span> view direction <span class="st300_footnote_reference">[<a href="#st300_f_10157_0" id="st300_fr_10011" title="Jump to footnote di.lighting.projective.back_clip (reference 0)">17</a>]</span>. The visual result is that it appears that there are two projective lights in the scene, oriented in opposite directions. As <a class="st300_link" href="#di.coords.clip">mentioned previously</a>, given the typical projection matrix, the <span class="st300_term expression">w</span> component of a given clip space position is the negation of the eye space <span class="st300_term expression">z</span> component. Because it is assumed that the observer is looking towards the negative <span class="st300_term expression">z</span> direction, all positions that are in front of the observer must have positive <span class="st300_term expression">w</span> components. Therefore, if <span class="st300_term expression">w</span> is negative, then the position is behind the observer. The standard fix for this problem is to check to see if the <span class="st300_term expression">w</span> component of the <span class="st300_term term">light-clip space</span> coordinate is negative, and simply return a pure black color (indicating no light contribution) rather than sampling from the projected texture.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.projective.clamping"/><div class="st300_subsection_title_number"><a id="st300_p2s15ss4" href="#st300_p2s15ss4" title="Subsection 2.15.4: Clamping">2.15.4</a></div><div class="st300_subsection_title">Clamping</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss4c1" href="#st300_p2s15ss4c1" title="Paragraph 2.15.4.1">1</a></div><div class="st300_paragraph">The <a class="st300_link" href="#di.lighting.projective.algorithm">algorithm</a> described above takes an arbitrary point in the scene and projects it from the point of view of the light. There is no guarantee that the point actually falls within the light's view frustum (although this is mitigated slightly by the <span class="st300_term package">r2</span> package's use of light volumes for deferred rendering), and therefore the calculated texture coordinates used to sample from the projected texture are not guaranteed to be in the range <span class="st300_term expression">[(0, 0), (1, 1)]</span>. In order to get the intended visual effect, the texture used must be set to <span class="st300_term term">clamp-to-edge</span> and have black pixels on all of the edges of the texture image, or <span class="st300_term term">clamp-to-border</span> with a black border color. Failing to do this can result in strange visual anomalies, as the texture will be unexpectedly repeated or smeared across the area outside of the intersection between the light volume and the receiving surface:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss4c2" href="#st300_p2s15ss4c2" title="Formal item 2.15.4.2: Projective lighting (Correct, clamped)">2.15.4.2 Projective lighting (Correct, clamped)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Projective lighting (Correct, clamped)" src="images/projective_clamped.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss4c3" href="#st300_p2s15ss4c3" title="Formal item 2.15.4.3: Projective lighting (Incorrect, not clamped)">2.15.4.3 Projective lighting (Incorrect, not clamped)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Projective lighting (Incorrect, not clamped)" src="images/projective_not_clamped.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss4c4" href="#st300_p2s15ss4c4" title="Paragraph 2.15.4.4">4</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package will raise an exception if a non-clamped texture is assigned to a projective light.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.projective.attenuation"/><div class="st300_subsection_title_number"><a id="st300_p2s15ss5" href="#st300_p2s15ss5" title="Subsection 2.15.5: Attenuation">2.15.5</a></div><div class="st300_subsection_title">Attenuation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss5c1" href="#st300_p2s15ss5c1" title="Paragraph 2.15.5.1">1</a></div><div class="st300_paragraph">The light supports <a class="st300_link" href="#di.lighting.attenuation">attenuation</a> using the maximum range taken from the projection.</div></div></div><div class="st300_subsection_container"><a id="di.lighting.projective.application"/><div class="st300_subsection_title_number"><a id="st300_p2s15ss6" href="#st300_p2s15ss6" title="Subsection 2.15.6: Application">2.15.6</a></div><div class="st300_subsection_title">Application</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss6c1" href="#st300_p2s15ss6c1" title="Paragraph 2.15.6.1">1</a></div><div class="st300_paragraph">The final light applied to the surface is given by <span class="st300_term function">projective</span> in <a class="st300_link_external" href="haskell/Projective.hs">Projective.hs</a>, where <span class="st300_term variable">sr</span>, <span class="st300_term variable">sg</span>, <span class="st300_term variable">sb</span> are the red, green, and blue channels, respectively, of the surface being lit. The surface-to-light vector <span class="st300_term variable">stl</span> is calculated by normalizing the negation of the difference between the the current eye space <span class="st300_term variable">surface_position</span> and the eye space origin of the light.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss6c2" href="#st300_p2s15ss6c2" title="Formal item 2.15.6.2: Projective lighting (Application)">2.15.6.2 Projective lighting (Application)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module Projective where

import qualified Attenuation
import qualified Color3
import qualified Color4
import qualified Direction
import qualified LightDiffuse
import qualified LightSpecular
import qualified LightProjective
import qualified Normal
import qualified Position3
import qualified Specular
import qualified Spaces
import qualified Vector3f
import qualified Vector4f

projective :: Direction.T Spaces.Eye -&gt; Normal.T -&gt; Position3.T Spaces.Eye -&gt; LightProjective.T -&gt; Specular.T -&gt; Float -&gt; Color3.T -&gt; Color4.T -&gt; Vector3f.T
projective view n surface_position light specular shadow texture (Vector4f.V4 sr sg sb _) =
  let
    position_diff   = Position3.sub3 surface_position (LightProjective.origin light)
    stl             = Vector3f.normalize (Vector3f.negation position_diff)
    distance        = Vector3f.magnitude (position_diff)
    attenuation_raw = Attenuation.attenuation (LightProjective.radius light) (LightProjective.falloff light) distance
    attenuation     = attenuation_raw * shadow
    light_color     = Vector3f.mult3 (LightProjective.color light) texture
    light_intensity = LightProjective.intensity light
    light_d         = LightDiffuse.diffuse stl n light_color light_intensity
    light_s         = LightSpecular.specularBlinnPhong stl view n light_color light_intensity specular
    light_da        = Vector3f.scale light_d attenuation
    light_sa        = Vector3f.scale light_s attenuation
    lit_d           = Vector3f.mult3 (Vector3f.V3 sr sg sb) light_da
    lit_s           = Vector3f.add3 lit_d light_sa
  in 
    lit_s
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss6c3" href="#st300_p2s15ss6c3" title="Paragraph 2.15.6.3">3</a></div><div class="st300_paragraph">The given <span class="st300_term variable">shadow</span> factor is a value in the range <span class="st300_term expression">[0, 1]</span>, where <span class="st300_term expression">0</span> indicates that the lit point is fully in shadow for the current light, and <span class="st300_term expression">1</span> indicates that the lit point is not in shadow. This is calculated for <a class="st300_link" href="#di.shadows.variance">variance</a> shadows and is assumed to be <span class="st300_term expression">1</span> for lights without shadows. As can be seen, a value of <span class="st300_term expression">0</span> has the effect of fully attenuating the light.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s15ss6c4" href="#st300_p2s15ss6c4" title="Paragraph 2.15.6.4">4</a></div><div class="st300_paragraph">The color denoted by <span class="st300_term variable">texture</span> is assumed to have been sampled from the projected texture. Assuming the eye space position being shaded <span class="st300_term expression">p</span>, the matrix to get from eye space to light-clip space is given by The final light applied to the surface is given by <span class="st300_term function">projective_matrix</span> in <a class="st300_link_external" href="haskell/ProjectiveMatrix.hs">ProjectiveMatrix.hs</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s15ss6c5" href="#st300_p2s15ss6c5" title="Formal item 2.15.6.5: Projective matrix">2.15.6.5 Projective matrix</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ProjectiveMatrix where

import qualified Matrix4f

projective_matrix :: Matrix4f.T -&gt; Matrix4f.T -&gt; Matrix4f.T -&gt; Matrix4f.T
projective_matrix camera_view light_view light_projection =
  case Matrix4f.inverse camera_view of
    Just cv -&gt; Matrix4f.mult (Matrix4f.mult light_projection light_view) cv
    Nothing -&gt; undefined -- A view matrix is always invertible

</pre></div></div></div></div><div class="st300_section_container"><a id="di.shadows"/><div class="st300_section_title_number"><a id="st300_p2s16" href="#st300_p2s16" title="Section 2.16: Shadows">2.16</a></div><div class="st300_section_title">Shadows</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s16ss1" title="Link to subsection 2.16.1: Overview">2.16.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s16ss2" title="Link to subsection 2.16.2: Shadow Geometry">2.16.2. Shadow Geometry</a></li></ul><div class="st300_subsection_container"><a id="di.shadows.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s16ss1" href="#st300_p2s16ss1" title="Subsection 2.16.1: Overview">2.16.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s16ss1c1" href="#st300_p2s16ss1c1" title="Paragraph 2.16.1.1">1</a></div><div class="st300_paragraph">Because the <span class="st300_term package">r2</span> package implements <span class="st300_term term">local illumination</span>, it is necessary to associate <span class="st300_term term">shadows</span> with those light sources capable of projecting them (currently only <a class="st300_link" href="#di.lighting.projective">projective</a> lights). The <span class="st300_term package">r2</span> package currently only supports <a class="st300_link" href="#di.shadows.variance">variance</a> <span class="st300_term term">shadow mapping</span>. So-called <span class="st300_term term">mapped</span> shadows allow efficient per-pixel shadows to be calculated with varying degrees of visual quality.</div></div></div><div class="st300_subsection_container"><a id="di.shadows.shadow-geometry"/><div class="st300_subsection_title_number"><a id="st300_p2s16ss2" href="#st300_p2s16ss2" title="Subsection 2.16.2: Shadow Geometry">2.16.2</a></div><div class="st300_subsection_title">Shadow Geometry</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s16ss2c1" href="#st300_p2s16ss2c1" title="Paragraph 2.16.2.1">1</a></div><div class="st300_paragraph">Because the system requires the programmer to explicitly and separately state that an opaque instance is visible in the scene, and that an opaque instance is casting a shadow, it becomes possible to effectively specify different <span class="st300_term term">shadow geometry</span> for a given instance. As an example, a very complex and high resolution mesh may still have the silhouette of a simple sphere, and therefore the user can separately add the high resolution mesh to a scene as a visible instance, but add a low resolution version of the mesh as an invisible shadow-casting instance with the same <a class="st300_link" href="#di.transforms">transform</a>. As a rather extreme example, assuming a high resolution mesh <span class="st300_term variable">m0</span> added to the scene as both a visible instance and a shadow caster:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s16ss2c2" href="#st300_p2s16ss2c2" title="Formal item 2.16.2.2: Visible and shadow casting (High)">2.16.2.2 Visible and shadow casting (High)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Visible and shadow casting (High)" src="images/shadow_geo_0.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s16ss2c3" href="#st300_p2s16ss2c3" title="Paragraph 2.16.2.3">3</a></div><div class="st300_paragraph">A low resolution mesh <span class="st300_term variable">m1</span> added to the scene as both a visible instance and shadow caster:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s16ss2c4" href="#st300_p2s16ss2c4" title="Formal item 2.16.2.4: Visible and shadow casting (Low)">2.16.2.4 Visible and shadow casting (Low)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Visible and shadow casting (Low)" src="images/shadow_geo_1.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s16ss2c5" href="#st300_p2s16ss2c5" title="Paragraph 2.16.2.5">5</a></div><div class="st300_paragraph">Now, with <span class="st300_term variable">m1</span> added as only a shadow caster, and <span class="st300_term variable">m0</span> added as only a visible instance:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s16ss2c6" href="#st300_p2s16ss2c6" title="Formal item 2.16.2.6: Visible and shadow casting (Low shadow, high visible)">2.16.2.6 Visible and shadow casting (Low shadow, high visible)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Visible and shadow casting (Low shadow, high visible)" src="images/shadow_geo_2.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s16ss2c7" href="#st300_p2s16ss2c7" title="Paragraph 2.16.2.7">7</a></div><div class="st300_paragraph">Using lower resolution geometry for shadow casters can lead to efficiency gains on systems where vertex processing is expensive.</div></div></div></div><div class="st300_section_container"><a id="di.shadows.variance"/><div class="st300_section_title_number"><a id="st300_p2s17" href="#st300_p2s17" title="Section 2.17: Shadows: Variance Mapping">2.17</a></div><div class="st300_section_title">Shadows: Variance Mapping</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s17ss1" title="Link to subsection 2.17.1: Overview">2.17.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s17ss2" title="Link to subsection 2.17.2: Algorithm">2.17.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s17ss3" title="Link to subsection 2.17.3: Advantages">2.17.3. Advantages</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s17ss4" title="Link to subsection 2.17.4: Disadvantages">2.17.4. Disadvantages</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s17ss5" title="Link to subsection 2.17.5: Types">2.17.5. Types</a></li></ul><div class="st300_subsection_container"><a id="di.shadows.variance.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s17ss1" href="#st300_p2s17ss1" title="Subsection 2.17.1: Overview">2.17.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss1c1" href="#st300_p2s17ss1c1" title="Paragraph 2.17.1.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Variance shadow mapping</span> is a technique that can give attractive soft-edged shadows. Using the same view and projection matrices used to apply <a class="st300_link" href="#di.lighting.projective">projective lights</a>, a <span class="st300_term term">depth-variance</span> image of the current scene is rendered, and those stored depth distribution values are used to determine the probability that a given point in the scene is in shadow with respect to the current light.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss1c2" href="#st300_p2s17ss1c2" title="Paragraph 2.17.1.2">2</a></div><div class="st300_paragraph">The algorithm implemented in the <span class="st300_term package">r2</span> package is described in <a class="st300_link_external" href="http://http.developer.nvidia.com/GPUGems3/gpugems3_ch08.html">GPU Gems 3</a>, which is a set of improvements to the original variance shadow mapping algorithm by William Donnelly and Andrew Lauritzen. The <span class="st300_term package">r2</span> package implements all of the improvements to the algorithm except <span class="st300_term term">summed area tables</span>. The package also provides optional box blurring of shadows as described in the chapter.</div></div></div><div class="st300_subsection_container"><a id="di.shadows.variance.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s17ss2" href="#st300_p2s17ss2" title="Subsection 2.17.2: Algorithm">2.17.2</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c1" href="#st300_p2s17ss2c1" title="Paragraph 2.17.2.1">1</a></div><div class="st300_paragraph">Prior to actually <a class="st300_link" href="#di.deferred">rendering</a>  a scene, <span class="st300_term term">shadow maps</span> are generated for all <span class="st300_term term">shadow-projecting</span> lights in the scene. A <span class="st300_term term">shadow map</span> for variance shadow mapping, for a light <span class="st300_term expression">k</span>, is a two-component red/green image of all of the <a class="st300_link" href="#di.shadows.shadow-geometry">shadow casters</a> associated with <span class="st300_term expression">k</span> in the visible set. The image is produced by rendering the instances from the point of view of <span class="st300_term expression">k</span>. The red channel of each pixel in the image represents the <a class="st300_link" href="#di.log_depth">logarithmic depth</a> of the closest surface at that pixel, and the green channel represents the depth squared (literally <span class="st300_term expression">depth * depth</span> ). For example:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s17ss2c2" href="#st300_p2s17ss2c2" title="Formal item 2.17.2.2: Depth-variance image">2.17.2.2 Depth-variance image</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Depth-variance image" src="images/depth_variance.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c3" href="#st300_p2s17ss2c3" title="Paragraph 2.17.2.3">3</a></div><div class="st300_paragraph">Then, when actually applying lighting during rendering of the scene, a given <a class="st300_link" href="#di.coords.eye">eye space</a> position <span class="st300_term expression">p</span> is transformed to <a class="st300_link" href="#di.lighting.projective.algorithm">light-clip space</a> and then mapped to the range <span class="st300_term expression">[(0, 0, 0), (1, 1, 1)]</span> in order to sample the <span class="st300_term term">depth</span> and <span class="st300_term term">depth squared</span> values <span class="st300_term expression">(d, ds)</span> from the shadow map (as with sampling from a projected texture with projective lighting).</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c4" href="#st300_p2s17ss2c4" title="Paragraph 2.17.2.4">4</a></div><div class="st300_paragraph">As stated previously, the intent of variance shadow mapping is to essentially calculate the <span class="st300_term term">probability</span> that a given point is in shadow. A <span class="st300_term term">one-tailed</span> variant of <a class="st300_link_external" href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality">Chebyshev's inequality</a> is used to calculate the upper bound <span class="st300_term expression">u</span> on the probability that, given <span class="st300_term expression">(d, ds)</span>, a given point with depth <span class="st300_term expression">t</span> is in shadow:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s17ss2c5" href="#st300_p2s17ss2c5" title="Formal item 2.17.2.5: Chebyshev 0">2.17.2.5 Chebyshev 0</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ShadowVarianceChebyshev0 where

chebyshev :: (Float, Float) -&gt; Float -&gt; Float
chebyshev (d, ds) t =
  let p        = if t &lt;= d then 1.0 else 0.0
      variance = ds - (d * d)
      du       = t - d
      p_max    = variance / (variance + (du * du))
  in max p p_max

factor :: (Float, Float) -&gt; Float -&gt; Float
factor = chebyshev
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c6" href="#st300_p2s17ss2c6" title="Paragraph 2.17.2.6">6</a></div><div class="st300_paragraph">One of the improvements suggested to the original variance shadow algorithm is to clamp the minimum variance to some small value (the <span class="st300_term package">r2</span> package uses <span class="st300_term constant">0.00002</span> by default, but this is configurable on a per-shadow basis). The equation above becomes:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s17ss2c7" href="#st300_p2s17ss2c7" title="Formal item 2.17.2.7: Chebyshev 1">2.17.2.7 Chebyshev 1</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ShadowVarianceChebyshev1 where

data T = T {
  minimum_variance :: Float
} deriving (Eq, Show)

chebyshev :: (Float, Float) -&gt; Float -&gt; Float -&gt; Float
chebyshev (d, ds) min_variance t =
  let p        = if t &lt;= d then 1.0 else 0.0
      variance = max (ds - (d * d)) min_variance
      du       = t - d
      p_max    = variance / (variance + (du * du))
  in max p p_max

factor :: T -&gt; (Float, Float) -&gt; Float -&gt; Float
factor shadow (d, ds) t =
  chebyshev (d, ds) (minimum_variance shadow) t
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c8" href="#st300_p2s17ss2c8" title="Paragraph 2.17.2.8">8</a></div><div class="st300_paragraph">The above is sufficient to give shadows that are roughly equivalent in visual quality to basic shadow mapping with the added benefit of being generally better behaved and with far fewer artifacts. However, the algorithm can suffer from <span class="st300_term term">light bleeding</span>, where the penumbrae of overlapping shadows can be unexpectedly bright despite the fact that the entire area should be in shadow. One of the suggested improvements to reduce light bleeding is to modify the upper bound <span class="st300_term expression">u</span> such that all values below a configurable threshold are mapped to zero, and values above the threshold are rescaled to map them to the range <span class="st300_term expression">[0, 1]</span>. The original article suggests a linear step function applied to <span class="st300_term expression">u</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s17ss2c9" href="#st300_p2s17ss2c9" title="Formal item 2.17.2.9: Chebyshev 2">2.17.2.9 Chebyshev 2</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ShadowVarianceChebyshev2 where

data T = T {
  minimum_variance :: Float,
  bleed_reduction  :: Float
} deriving (Eq, Show)

chebyshev :: (Float, Float) -&gt; Float -&gt; Float -&gt; Float
chebyshev (d, ds) min_variance t =
  let p        = if t &lt;= d then 1.0 else 0.0
      variance = max (ds - (d * d)) min_variance
      du       = t - d
      p_max    = variance / (variance + (du * du))
  in max p p_max

clamp :: Float -&gt; (Float, Float) -&gt; Float
clamp x (lower, upper) = max (min x upper) lower

linear_step :: Float -&gt; Float -&gt; Float -&gt; Float
linear_step lower upper x = clamp ((x - lower) / (upper - lower)) (0.0, 1.0)

factor :: T -&gt; (Float, Float) -&gt; Float -&gt; Float
factor shadow (d, ds) t =
  let u = chebyshev (d, ds) (minimum_variance shadow) t in
    linear_step (bleed_reduction shadow) 1.0 u
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c10" href="#st300_p2s17ss2c10" title="Paragraph 2.17.2.10">10</a></div><div class="st300_paragraph">The amount of light bleed reduction is adjustable on a per-shadow basis.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c11" href="#st300_p2s17ss2c11" title="Paragraph 2.17.2.11">11</a></div><div class="st300_paragraph">To reduce problems involving numeric inaccuracy, the original article suggests the use of 32-bit floating point textures in depth variance maps. The <span class="st300_term package">r2</span> package allows 16-bit or 32-bit textures, configurable on a per-shadow basis.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss2c12" href="#st300_p2s17ss2c12" title="Paragraph 2.17.2.12">12</a></div><div class="st300_paragraph">Finally, as mentioned previously, the <span class="st300_term package">r2</span> package allows both optional box blurring and mipmap generation for shadow maps. Both blurring and mipmapping can reduce aliasing artifacts, with the former also allowing the edges of shadows to be significantly softened as a visual effect:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s17ss2c13" href="#st300_p2s17ss2c13" title="Formal item 2.17.2.13: Depth-variance shadows (Minimal blur)">2.17.2.13 Depth-variance shadows (Minimal blur)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Depth-variance shadows (Minimal blur)" src="images/variance_0.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s17ss2c14" href="#st300_p2s17ss2c14" title="Formal item 2.17.2.14: Depth-variance shadows (High blur)">2.17.2.14 Depth-variance shadows (High blur)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Depth-variance shadows (High blur)" src="images/variance_1.png"/></div></div></div><div class="st300_subsection_container"><a id="di.shadows.variance.advantages"/><div class="st300_subsection_title_number"><a id="st300_p2s17ss3" href="#st300_p2s17ss3" title="Subsection 2.17.3: Advantages">2.17.3</a></div><div class="st300_subsection_title">Advantages</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss3c1" href="#st300_p2s17ss3c1" title="Paragraph 2.17.3.1">1</a></div><div class="st300_paragraph">The main advantage of <span class="st300_term term">variance shadow mapping</span> is that they can essentially be thought of as much better behaved version of basic shadow mapping that just happen to have built-in softening and filtering. Variance shadows typically require far less in the way of scene-specific tuning to get good results.</div></div></div><div class="st300_subsection_container"><a id="di.shadows.variance.disadvantages"/><div class="st300_subsection_title_number"><a id="st300_p2s17ss4" href="#st300_p2s17ss4" title="Subsection 2.17.4: Disadvantages">2.17.4</a></div><div class="st300_subsection_title">Disadvantages</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss4c1" href="#st300_p2s17ss4c1" title="Paragraph 2.17.4.1">1</a></div><div class="st300_paragraph">One disadvantage of variance shadows is that for large shadow maps, filtering quickly becomes a major bottleneck. On reasonably old hardware such as the <a class="st300_link_external" href="https://en.wikipedia.org/wiki/Radeon_HD_4670">Radeon 4670</a>, one <span class="st300_term constant">8192x8192</span> shadow map with two 16-bit components takes too long to filter to give a reliable <span class="st300_term constant">60</span> frames per second rendering rate. Shadow maps of this size are usually used to simulate the influence of the sun over large outdoor scenes.</div></div></div><div class="st300_subsection_container"><a id="di.shadows.variance.types"/><div class="st300_subsection_title_number"><a id="st300_p2s17ss5" href="#st300_p2s17ss5" title="Subsection 2.17.5: Types">2.17.5</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss5c1" href="#st300_p2s17ss5c1" title="Paragraph 2.17.5.1">1</a></div><div class="st300_paragraph">Variance mapped shadows are represented by the <a class="st300_link_external" href="apidocs/com/io7m/r1/core/R2ShadowDepthVarianceType.html">R2ShadowDepthVarianceType</a> type, and can be associated with <a class="st300_link" href="#di.lighting.projective">projective lights</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s17ss5c2" href="#st300_p2s17ss5c2" title="Paragraph 2.17.5.2">2</a></div><div class="st300_paragraph">Rendering of depth-variance images is handled by implementations of the <a class="st300_link_external" href="apidocs/com/io7m/r1/core/R2ShadowMapRendererType.html">R2ShadowMapRendererType</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.deferred"/><div class="st300_section_title_number"><a id="st300_p2s18" href="#st300_p2s18" title="Section 2.18: Deferred Rendering">2.18</a></div><div class="st300_section_title">Deferred Rendering</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s18ss1" title="Link to subsection 2.18.1: Overview">2.18.1. Overview</a></li></ul><div class="st300_subsection_container"><a id="di.deferred.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s18ss1" href="#st300_p2s18ss1" title="Subsection 2.18.1: Overview">2.18.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s18ss1c1" href="#st300_p2s18ss1c1" title="Paragraph 2.18.1.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Deferred rendering</span> is a rendering technique where all of the opaque objects in a given scene are rendered into a series of buffers, and then lighting is applied to those buffers in <a class="st300_link" href="#di.coords.screen">screen space</a>. This is in contrast to <span class="st300_term term">forward rendering</span>, where all lighting is applied to objects as they are rendered.</div></div><div class="st300_paragraph_container"><a id="di.deferred.overview.shaders"/><div class="st300_paragraph_number"><a id="st300_p2s18ss1c2" href="#st300_p2s18ss1c2" title="Paragraph 2.18.1.2">2</a></div><div class="st300_paragraph">One major advantage of deferred rendering is a massive reduction in the number of shaders required (traditional forward rendering requires <span class="st300_term expression">s * l</span> shaders, where <span class="st300_term expression">s</span> is the number of different object surface types in the scene, and <span class="st300_term expression">l</span> is the number of different light types). In contrast, deferred rendering requires <span class="st300_term expression">s + l</span> shaders, because surface and lighting shaders are applied separately.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s18ss1c3" href="#st300_p2s18ss1c3" title="Paragraph 2.18.1.3">3</a></div><div class="st300_paragraph">Traditional forward rendering also suffers severe performance problems as the number of lights in the scene increases, because it is necessary to recompute all of the surface attributes of an object each time a light is applied. In contrast, deferred rendering calculates all surface attributes of all objects once, and then reuses them when lighting is applied.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s18ss1c4" href="#st300_p2s18ss1c4" title="Paragraph 2.18.1.4">4</a></div><div class="st300_paragraph">However, deferred renderers are usually incapable of rendering translucent objects. The deferred renderer in the <span class="st300_term package">r2</span> package is no exception, and a separate set of renderers are provided to render translucent objects.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s18ss1c5" href="#st300_p2s18ss1c5" title="Paragraph 2.18.1.5">5</a></div><div class="st300_paragraph">Due to the size of the subject, the deferred rendering infrastructure in the <span class="st300_term package">r2</span> package is described in several sections. The rendering of opaque geometry is described in the <a class="st300_link" href="#di.deferred.geom">Geometry</a> section, the subsequent lighting of that geometry is described in the <a class="st300_link" href="#di.deferred.light">Lighting</a> section. The details of the position reconstruction algorithm, an algorithm utterly fundamental to deferred rendering, is described in <a class="st300_link" href="#di.deferred-position-recon">Position Reconstruction</a>.</div></div></div></div><div class="st300_section_container"><a id="di.deferred.geom"/><div class="st300_section_title_number"><a id="st300_p2s19" href="#st300_p2s19" title="Section 2.19: Deferred Rendering: Geometry">2.19</a></div><div class="st300_section_title">Deferred Rendering: Geometry</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s19ss1" title="Link to subsection 2.19.1: Overview">2.19.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s19ss2" title="Link to subsection 2.19.2: Groups">2.19.2. Groups</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s19ss3" title="Link to subsection 2.19.3: Geometry Buffer">2.19.3. Geometry Buffer</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s19ss4" title="Link to subsection 2.19.4: Algorithm">2.19.4. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s19ss5" title="Link to subsection 2.19.5: Ordering/Batching">2.19.5. Ordering/Batching</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s19ss6" title="Link to subsection 2.19.6: Normal Compression">2.19.6. Normal Compression</a></li></ul><div class="st300_subsection_container"><a id="di.deferred.geom.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s19ss1" href="#st300_p2s19ss1" title="Subsection 2.19.1: Overview">2.19.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss1c1" href="#st300_p2s19ss1c1" title="Paragraph 2.19.1.1">1</a></div><div class="st300_paragraph">The first step in <span class="st300_term term">deferred rendering</span> involves rendering all opaque instances in the current scene to a <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a>. This populated geometry buffer is then primarily used in later stages to calculate <a class="st300_link" href="#di.deferred.light">lighting</a>, but can also be used to implement effects such as <a class="st300_link" href="#di.ssao">screen-space ambient occlusion</a> and <a class="st300_link" href="#di.emission">emission</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss1c2" href="#st300_p2s19ss1c2" title="Paragraph 2.19.1.2">2</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the primary implementation of the deferred geometry rendering algorithm is the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2GeometryRenderer.html">R2GeometryRenderer</a> type.</div></div></div><div class="st300_subsection_container"><a id="di.deferred.geom.group"/><div class="st300_subsection_title_number"><a id="st300_p2s19ss2" href="#st300_p2s19ss2" title="Subsection 2.19.2: Groups">2.19.2</a></div><div class="st300_subsection_title">Groups</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss2c1" href="#st300_p2s19ss2c1" title="Paragraph 2.19.2.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Groups</span> are a simple means to constrain the contributions of sets of specific light sources to sets of specific rendered instances. Instances and lights are assigned a <span class="st300_term term">group number</span> in the range <span class="st300_term expression">[1, 15]</span>. If the programmer does not explicitly assign a number, the number <span class="st300_term constant">1</span> is assigned automatically. During rendering, the group number of each rendered instance is written to the <a class="st300_link" href="#di.stencil">stencil buffer</a>. Then, when the light contribution is calculated for a light with group number <span class="st300_term expression">n</span>, only those pixels that have a corresponding value of <span class="st300_term expression">n</span> in the stencil buffer are allowed to be modified.</div></div></div><div class="st300_subsection_container"><a id="di.deferred.geom.gbuffer"/><div class="st300_subsection_title_number"><a id="st300_p2s19ss3" href="#st300_p2s19ss3" title="Subsection 2.19.3: Geometry Buffer">2.19.3</a></div><div class="st300_subsection_title">Geometry Buffer</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss3c1" href="#st300_p2s19ss3c1" title="Paragraph 2.19.3.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">geometry buffer</span> is a <a class="st300_link" href="#di.render-target">render target</a> in which the surface attributes of objects are stored prior to being combined with the contents of a <a class="st300_link" href="#di.deferred.light.lbuffer">light buffer</a> to produce a lit image.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss3c2" href="#st300_p2s19ss3c2" title="Paragraph 2.19.3.2">2</a></div><div class="st300_paragraph">One of the main implementation issues in any deferred renderer is deciding which surface attributes (such as position, albedo, normals, etc) to store and which to reconstruct. The more attributes that are stored, the less work is required during rendering to reconstruct those values. However, storing more attributes requires a larger geometry buffer and more memory bandwidth to actually populate that geometry buffer during rendering. The <span class="st300_term package">r2</span> package leans towards having a more compact geometry buffer and doing slightly more reconstruction work during rendering.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s19ss3c3" href="#st300_p2s19ss3c3" title="Formal item 2.19.3.3: Geometry Buffer">2.19.3.3 Geometry Buffer</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Geometry Buffer" src="images/gbuffer.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss3c4" href="#st300_p2s19ss3c4" title="Paragraph 2.19.3.4">4</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package explicitly stores the albedo, normals, emission level, and specular color of surfaces. Additionally, the depth buffer is sampled to recover the depth of surfaces. The eye-space positions of surfaces are recovered via an efficient <a class="st300_link" href="#di.deferred-position-recon">position reconstruction</a> algorithm which uses the current viewing projection and <a class="st300_link" href="#di.log_depth">logarithmic depth</a> value as input. In order to reduce the amount of storage required, three-dimensional eye-space normal vectors are stored compressed as two <span class="st300_term expression">16</span> half-precision floating point components via a simple <a class="st300_link" href="#di.deferred.geom.normal-compression">mapping</a>. This means that only <span class="st300_term expression">32</span> bits are required to store the vectors, and very little precision is lost. The precise format of the geometry buffer is as follows:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s19ss3c5" href="#st300_p2s19ss3c5" title="Formal item 2.19.3.5: Geometry Buffer Format">2.19.3.5 Geometry Buffer Format</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Geometry Buffer Format" src="images/gbuffer_format_0.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss3c6" href="#st300_p2s19ss3c6" title="Paragraph 2.19.3.6">6</a></div><div class="st300_paragraph">The <span class="st300_term variable">albedo_r</span>, <span class="st300_term variable">albedo_g</span>, and <span class="st300_term variable">albedo_b</span> components correspond to the red, green, and blue components of the surface, respectively. The <span class="st300_term variable">emission</span> component refers to the surface emission level. The <span class="st300_term variable">normal_x</span> and <span class="st300_term variable">normal_y</span> components correspond to the two components of the <a class="st300_link" href="#di.deferred.geom.normal-compression">compressed surface normal</a> vector. The <span class="st300_term variable">specular_r</span>, <span class="st300_term variable">specular_g</span>, and <span class="st300_term variable">specular_b</span> components correspond to the red, green, and blue components of the surface specularity. Surfaces that will not receive specular highlights simply have <span class="st300_term expression">0</span> for each component. The <span class="st300_term variable">specular_e</span> component holds the surface <span class="st300_term term">specular exponent</span> divided by <span class="st300_term expression">256</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss3c7" href="#st300_p2s19ss3c7" title="Paragraph 2.19.3.7">7</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, geometry buffers are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2GeometryBufferType.html">R2GeometryBufferType</a>.</div></div></div><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p2s19ss4" href="#st300_p2s19ss4" title="Subsection 2.19.4: Algorithm">2.19.4</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss4c1" href="#st300_p2s19ss4c1" title="Paragraph 2.19.4.1">1</a></div><div class="st300_paragraph">An informal description of the geometry rendering algorithm as implemented in the <span class="st300_term package">r2</span> package is as follows:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s19ss4c2" href="#st300_p2s19ss4c2" title="Formal item 2.19.4.2: Geometry Rendering Overview">2.19.4.2 Geometry Rendering Overview</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Set the current <a class="st300_link" href="#di.render-target">render target</a> to a geometry buffer <span class="st300_term expression">b</span>.</li><li class="st300_list_item">Enable writing to the depth and stencil buffers, and enable stencil testing. Enable depth testing such that only pixels with a depth less than or equal to the current depth are touched.</li><li class="st300_list_item">For each <a class="st300_link" href="#di.deferred.geom.group">group</a> <span class="st300_term expression">g</span>: <ol class="st300_list_ordered"><li class="st300_list_item">Configure stencil testing such that only pixels with the <a class="st300_link" href="#di.stencil.allow_bit">allow bit</a> enabled are touched, and configure stencil writing such that the index of <span class="st300_term expression">g</span> is recorded in the stencil buffer.</li><li class="st300_list_item">For each instance <span class="st300_term expression">o</span> in <span class="st300_term expression">g</span>: <ol class="st300_list_ordered"><li class="st300_list_item">Render the surface albedo, eye space normals, specular color, and emission level of <span class="st300_term expression">o</span> into <span class="st300_term expression">b</span>. <a class="st300_link" href="#di.normal-mapping">Normal mapping</a> is performed during rendering, and if <span class="st300_term expression">o</span> does not have specular highlights, then a pure black (zero intensity) specular color is written. Effects such as <a class="st300_link" href="#di.environment-mapping">environment mapping</a> are considered to be part of the surface albedo and so are performed in this step.</li></ol></li></ol></li></ol></div></div></div><div class="st300_subsection_container"><a id="di.deferred.geom.ordering"/><div class="st300_subsection_title_number"><a id="st300_p2s19ss5" href="#st300_p2s19ss5" title="Subsection 2.19.5: Ordering/Batching">2.19.5</a></div><div class="st300_subsection_title">Ordering/Batching</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss5c1" href="#st300_p2s19ss5c1" title="Paragraph 2.19.5.1">1</a></div><div class="st300_paragraph">Due to the use of depth testing, the geometry rendering algorithm is effectively order independent: Instances can be rendered in any order and the final image will always be the same. However, there are efficiency advantages in rendering instances in a particular order. The most efficient order of rendering is the one that minimizes internal OpenGL <span class="st300_term term">state changes</span>. NVIDIA's <a class="st300_link_external" href="http://media.steampowered.com/apps/steamdevdays/slides/beyondporting.pdf">Beyond Porting</a> presentation gives the relative cost of OpenGL state changes, from most expensive to least expensive, as <span class="st300_footnote_reference">[<a href="#st300_f_13206_0" id="st300_fr_13046" title="Jump to footnote di.deferred.geom.ordering.perf (reference 0)">18</a>]</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s19ss5c2" href="#st300_p2s19ss5c2" title="Formal item 2.19.5.2: State changes">2.19.5.2 State changes</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Render target changes: 60,000/second</li><li class="st300_list_item">Program bindings: 300,000/second</li><li class="st300_list_item">Texture bindings: 1,500,000/second</li><li class="st300_list_item">Vertex format (exact cost unspecified)</li><li class="st300_list_item">UBO bindings (exact cost unspecified)</li><li class="st300_list_item">Vertex Bindings (exact cost unspecified)</li><li class="st300_list_item">Uniform Updates: 10,000,000/second</li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss5c3" href="#st300_p2s19ss5c3" title="Paragraph 2.19.5.3">3</a></div><div class="st300_paragraph">Therefore, it is beneficial to order rendering operations such that the most expensive state changes happen the least frequently.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss5c4" href="#st300_p2s19ss5c4" title="Paragraph 2.19.5.4">4</a></div><div class="st300_paragraph">The <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2SceneOpaquesType.html">R2SceneOpaquesType</a> type provides a simple interface that allows the programmer to specify instances without worrying about ordering concerns. When all instances have been submitted, they will be delivered to a given consumer (typically a geometry renderer) via the <span class="st300_term function">opaquesExecute</span> method in the order that would be most efficient for rendering. Typically, this means that instances are first batched by <a class="st300_link" href="#di.shaders.instance">shader</a>, because switching programs is the second most expensive type of render state change. The shader-batched instances are then batched by <a class="st300_link" href="#di.shaders.instance.material">material</a>, in order to reduce the number of uniform updates that need to occur per shader.</div></div></div><div class="st300_subsection_container"><a id="di.deferred.geom.normal-compression"/><div class="st300_subsection_title_number"><a id="st300_p2s19ss6" href="#st300_p2s19ss6" title="Subsection 2.19.6: Normal Compression">2.19.6</a></div><div class="st300_subsection_title">Normal Compression</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss6c1" href="#st300_p2s19ss6c1" title="Paragraph 2.19.6.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package uses a <a class="st300_link_external" href="http://en.wikipedia.org/wiki/Lambert_azimuthal_equal-area_projection">Lambert azimuthal equal-area projection</a> to store surface normal vectors in two components instead of three. This makes use of the fact that normalized vectors represent points on the unit sphere. The mapping from normal vectors to two-dimensional spheremap coordinates is given by <span class="st300_term function">compress</span> <a class="st300_link_external" href="haskell/NormalCompress.hs">NormalCompress.hs</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s19ss6c2" href="#st300_p2s19ss6c2" title="Formal item 2.19.6.2: Normal Compression">2.19.6.2 Normal Compression</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module NormalCompress where

import qualified Vector3f
import qualified Vector2f
import qualified Normal

compress :: Normal.T -&gt; Vector2f.T
compress n =
  let p = sqrt ((Vector3f.z n * 8.0) + 8.0)
      x = (Vector3f.x n / p) + 0.5
      y = (Vector3f.y n / p) + 0.5
  in Vector2f.V2 x y</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s19ss6c3" href="#st300_p2s19ss6c3" title="Paragraph 2.19.6.3">3</a></div><div class="st300_paragraph">The mapping from two-dimensional spheremap coordinates to normal vectors is given by <span class="st300_term function">decompress</span> <a class="st300_link_external" href="haskell/NormalDecompress.hs">NormalDecompress.hs</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s19ss6c4" href="#st300_p2s19ss6c4" title="Formal item 2.19.6.4: Normal Decompression">2.19.6.4 Normal Decompression</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module NormalDecompress where

import qualified Vector3f
import qualified Vector2f
import qualified Normal

decompress :: Vector2f.T -&gt; Normal.T
decompress v =
  let fn = Vector2f.V2 ((Vector2f.x v * 4.0) - 2.0) ((Vector2f.y v * 4.0) - 2.0)
      f  = Vector2f.dot2 fn fn
      g  = sqrt (1.0 - (f / 4.0))
      x  = (Vector2f.x fn) * g
      y  = (Vector2f.y fn) * g
      z  = 1.0 - (f / 2.0)
  in Vector3f.V3 x y z</pre></div></div></div></div><div class="st300_section_container"><a id="di.deferred.light"/><div class="st300_section_title_number"><a id="st300_p2s20" href="#st300_p2s20" title="Section 2.20: Deferred Rendering: Lighting">2.20</a></div><div class="st300_section_title">Deferred Rendering: Lighting</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s20ss1" title="Link to subsection 2.20.1: Overview">2.20.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s20ss2" title="Link to subsection 2.20.2: Light Buffer">2.20.2. Light Buffer</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s20ss3" title="Link to subsection 2.20.3: Light Clip Volumes">2.20.3. Light Clip Volumes</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s20ss4" title="Link to subsection 2.20.4: Types">2.20.4. Types</a></li></ul><div class="st300_subsection_container"><a id="di.deferred.light.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s20ss1" href="#st300_p2s20ss1" title="Subsection 2.20.1: Overview">2.20.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss1c1" href="#st300_p2s20ss1c1" title="Paragraph 2.20.1.1">1</a></div><div class="st300_paragraph">The second step in <span class="st300_term term">deferred rendering</span> involves rendering the light contributions of all light sources within a scene to a <a class="st300_link" href="#di.deferred.light.lbuffer">light buffer</a>. The rendering algorithm requires sampling from a populated <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a>.</div></div></div><div class="st300_subsection_container"><a id="di.deferred.light.lbuffer"/><div class="st300_subsection_title_number"><a id="st300_p2s20ss2" href="#st300_p2s20ss2" title="Subsection 2.20.2: Light Buffer">2.20.2</a></div><div class="st300_subsection_title">Light Buffer</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss2c1" href="#st300_p2s20ss2c1" title="Paragraph 2.20.2.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">light buffer</span> is a <a class="st300_link" href="#di.render-target">render target</a> in which the light contributions of all light sources are summed in preparation for being combined with the surface albedo of a <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a> to produce a lit image.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss2c2" href="#st300_p2s20ss2c2" title="Paragraph 2.20.2.2">2</a></div><div class="st300_paragraph">A light buffer consists of a 32-bit RGBA <span class="st300_term term">diffuse</span> image and a 32-bit RGBA <span class="st300_term term">specular</span> image. Currently, the alpha channels of both images are unused and exist solely because OpenGL 3.3 does not provide a color-renderable 24-bit RGB format.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss2c3" href="#st300_p2s20ss2c3" title="Paragraph 2.20.2.3">3</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package offers the ability to disable <a class="st300_link" href="#di.lighting.specular">specular lighting</a> entirely if it is not needed, and so light buffer implementations provide the ability to avoid allocating an image for specular contributions if they will not be calculated.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss2c4" href="#st300_p2s20ss2c4" title="Paragraph 2.20.2.4">4</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, light buffers are instances of <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2LightBufferType.html">R2LightBufferType</a>.</div></div></div><div class="st300_subsection_container"><a id="di.deferred.light.clip_volumes"/><div class="st300_subsection_title_number"><a id="st300_p2s20ss3" href="#st300_p2s20ss3" title="Subsection 2.20.3: Light Clip Volumes">2.20.3</a></div><div class="st300_subsection_title">Light Clip Volumes</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c1" href="#st300_p2s20ss3c1" title="Paragraph 2.20.3.1">1</a></div><div class="st300_paragraph">A <span class="st300_term light">light clip volume</span> is a means of constraining the contributions of groups of light sources to a provided <span class="st300_term term">volume</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c2" href="#st300_p2s20ss3c2" title="Paragraph 2.20.3.2">2</a></div><div class="st300_paragraph">Because, like most renderers, the <span class="st300_term package">r2</span> package implements so-called <span class="st300_term term">local illumination</span>, lights that do not have explicit <span class="st300_term term">shadow mapping</span> enabled are able to bleed through solid objects:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c3" href="#st300_p2s20ss3c3" title="Formal item 2.20.3.3: Local Light Bleed">2.20.3.3 Local Light Bleed</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Local light bleeding." src="images/lightbleed_noclip.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c4" href="#st300_p2s20ss3c4" title="Paragraph 2.20.3.4">4</a></div><div class="st300_paragraph">Enabling shadow mapping for every single light source would be prohibitively expensive <span class="st300_footnote_reference">[<a href="#st300_f_2627_1" id="st300_fr_13636" title="Jump to footnote di.concepts.shadow_expensive (reference 1)">3</a>]</span>, but for some scenes, acceptable results can be achieved by simply preventing the light source from affecting pixels outside of a given <span class="st300_term term">clip volume</span>.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c5" href="#st300_p2s20ss3c5" title="Formal item 2.20.3.5: Local Light Clipped">2.20.3.5 Local Light Clipped</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Local light clipped to a volume." src="images/lightbleed_clip.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c6" href="#st300_p2s20ss3c6" title="Paragraph 2.20.3.6">6</a></div><div class="st300_paragraph">The technique is implemented using the <a class="st300_link" href="#di.stencil">stencil buffer</a>, using a single <span class="st300_term term">light clip volume bit</span>.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c7" href="#st300_p2s20ss3c7" title="Formal item 2.20.3.7: Algorithm">2.20.3.7 Algorithm</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Disable depth writing, and enable depth testing using the standard less-than-or-equal-to depth function is used.</li><li class="st300_list_item">For each light clip volume <span class="st300_term expression">v</span>: <ol class="st300_list_ordered"><li class="st300_list_item">Clear the <span class="st300_term term">light clip volume</span> bit in the stencil buffer.</li><li class="st300_list_item">Configure stencil testing such that the stencil test always passes.</li><li class="st300_list_item">Configure stencil writing such that: <ul class="st300_list_unordered"><li class="st300_list_item">Only the light clip volume bit can be written.</li><li class="st300_list_item">Pixels that fail the depth test will invert the value of the light clip volume bit <span class="st300_term expression">(GL_INVERT)</span>.</li><li class="st300_list_item">Pixels that pass the depth test leave the value of the light clip volume bit untouched.</li><li class="st300_list_item">Pixels that pass the stencil test leave the value of the light clip volume bit untouched.</li></ul></li><li class="st300_list_item">Render both the front and back faces of <span class="st300_term expression">v</span>.</li><li class="st300_list_item">Configure stencil testing such that only those pixels with both the <a class="st300_link" href="#di.stencil.allow_bit">allow bit</a> and light clip volume bit set will be touched.</li><li class="st300_list_item">Render all of the light sources associated with <span class="st300_term expression">v</span>.</li></ol></li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c8" href="#st300_p2s20ss3c8" title="Paragraph 2.20.3.8">8</a></div><div class="st300_paragraph">The reason the algorithm works can be inferred from the following diagram:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c9" href="#st300_p2s20ss3c9" title="Formal item 2.20.3.9: Stencil Test Diagram">2.20.3.9 Stencil Test Diagram</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Stencil test diagram" src="images/light_clip_volume_diagram.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c10" href="#st300_p2s20ss3c10" title="Paragraph 2.20.3.10">10</a></div><div class="st300_paragraph">In the diagram, the grey polygons represent the already-rendered depths of the scene geometry <span class="st300_footnote_reference">[<a href="#st300_f_13950_0" id="st300_fr_13914" title="Jump to footnote di.deferred.light.depth (reference 0)">19</a>]</span>. If a point is inside or behind (from  the perspective of the observer) one of the polygons, then the depth of the point is considered to be <span class="st300_term term">greater</span> than the scene geometry.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c11" href="#st300_p2s20ss3c11" title="Paragraph 2.20.3.11">11</a></div><div class="st300_paragraph">In the diagram, when rendering the front face of the light volume at point <span class="st300_term expression">P0</span>, the depth of the light volume face at <span class="st300_term expression">P0</span> is less than the current scene depth, and so the depth test succeeds and the light clip volume bit is not touched. When rendering the back face of the light volume at point <span class="st300_term expression">P1</span>, the depth of the light volume face at <span class="st300_term expression">P1</span> is greater than the current scene depth so the depth test fails, and the light clip volume bit is inverted, setting it to <span class="st300_term constant">true</span>. This means that the scene geometry along that view ray is <span class="st300_term term">inside</span> the light clip volume.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c12" href="#st300_p2s20ss3c12" title="Paragraph 2.20.3.12">12</a></div><div class="st300_paragraph">In the diagram, when rendering the front face of the light volume at point <span class="st300_term expression">P2</span>, the depth of the light volume face at <span class="st300_term expression">P2</span> is greater than the current scene depth, and so the depth test fails and the light clip volume bit is inverted, setting it to <span class="st300_term constant">true</span>. When rendering the back face of the light volume at point <span class="st300_term expression">P3</span>, the depth of the light volume face at <span class="st300_term expression">P3</span> is greater than the current scene depth, so the depth test fails and the light clip volume bit is inverted again, setting it to <span class="st300_term constant">false</span>. This means that the scene geometry along that view ray is <span class="st300_term term">outside</span> the light clip volume.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c13" href="#st300_p2s20ss3c13" title="Paragraph 2.20.3.13">13</a></div><div class="st300_paragraph">In the diagram, when rendering the front face of the light volume at point <span class="st300_term expression">P4</span>, the depth of the light volume face at <span class="st300_term expression">P4</span> is less than the current scene depth, and so the depth test succeeds and the light clip volume bit is not touched. When rendering the back face of the light volume at point <span class="st300_term expression">P5</span>, the depth of the light volume face at <span class="st300_term expression">P5</span> is less than the current scene depth, and so the depth test succeeds and the light clip volume bit is not touched. Because the light clip volume bit is <span class="st300_term constant">false</span> by default and is not modified, this results in the scene geometry along that view ray being considered to be <span class="st300_term term">outside</span> the light clip volume.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c14" href="#st300_p2s20ss3c14" title="Paragraph 2.20.3.14">14</a></div><div class="st300_paragraph">Given the initial depth buffer from an example scene:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c15" href="#st300_p2s20ss3c15" title="Formal item 2.20.3.15: Depth Buffer">2.20.3.15 Depth Buffer</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Scene depth buffer." src="images/light_clip_volume_depth.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c16" href="#st300_p2s20ss3c16" title="Paragraph 2.20.3.16">16</a></div><div class="st300_paragraph">The stencil buffer for the initial scene has all of the geometry with the <a class="st300_link" href="#di.stencil.allow_bit">allow bit</a> set:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c17" href="#st300_p2s20ss3c17" title="Formal item 2.20.3.17: Stencil Buffer (Initial)">2.20.3.17 Stencil Buffer (Initial)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Scene stencil buffer (initial) ." src="images/light_clip_volume_stencil_before.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c18" href="#st300_p2s20ss3c18" title="Paragraph 2.20.3.18">18</a></div><div class="st300_paragraph">After rendering a cuboid-shaped light volume that is intended to constrain the contributions of a light source to a single area, all pixels that fell within the clip volume have the light clip volume bit set:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c19" href="#st300_p2s20ss3c19" title="Formal item 2.20.3.19: Stencil Buffer (Result)">2.20.3.19 Stencil Buffer (Result)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Scene stencil buffer (result) ." src="images/light_clip_volume_stencil_after.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss3c20" href="#st300_p2s20ss3c20" title="Paragraph 2.20.3.20">20</a></div><div class="st300_paragraph">Then, after rendering the light contribution of the constrainted light, the light contribution becomes:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s20ss3c21" href="#st300_p2s20ss3c21" title="Formal item 2.20.3.21: Light Buffer (Result)">2.20.3.21 Light Buffer (Result)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Scene light buffer (result) ." src="images/light_clip_volume_diffuse.png"/></div></div></div><div class="st300_subsection_container"><a id="di.deferred.light.types"/><div class="st300_subsection_title_number"><a id="st300_p2s20ss4" href="#st300_p2s20ss4" title="Subsection 2.20.4: Types">2.20.4</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s20ss4c1" href="#st300_p2s20ss4c1" title="Paragraph 2.20.4.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the primary implementation of the deferred light rendering algorithm is the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2LightRenderer.html">R2LightRenderer</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.deferred-position-recon"/><div class="st300_section_title_number"><a id="st300_p2s21" href="#st300_p2s21" title="Section 2.21: Deferred Rendering: Position Reconstruction">2.21</a></div><div class="st300_section_title">Deferred Rendering: Position Reconstruction</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s21ss1" title="Link to subsection 2.21.1: Overview">2.21.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s21ss2" title="Link to subsection 2.21.2: Recovering Eye space Z">2.21.2. Recovering Eye space Z</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s21ss3" title="Link to subsection 2.21.3: Recovering Eye space Z (Logarithmic depth encoding)">2.21.3. Recovering Eye space Z (Logarithmic depth encoding)</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s21ss4" title="Link to subsection 2.21.4: Recovering Eye space Z (Screen space depth encoding)">2.21.4. Recovering Eye space Z (Screen space depth encoding)</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s21ss5" title="Link to subsection 2.21.5: Recovering Eye space Position">2.21.5. Recovering Eye space Position</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s21ss6" title="Link to subsection 2.21.6: Implementation">2.21.6. Implementation</a></li></ul><div class="st300_subsection_container"><a id="di.deferred-position-recon.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s21ss1" href="#st300_p2s21ss1" title="Subsection 2.21.1: Overview">2.21.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss1c1" href="#st300_p2s21ss1c1" title="Paragraph 2.21.1.1">1</a></div><div class="st300_paragraph">Applying lighting during <span class="st300_term term">deferred rendering</span> is primarily a <a class="st300_link" href="#di.coords.screen">screen space</a> technique. When the visible opaque objects have been rendered into the <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a>, the original <a class="st300_link" href="#di.coords.eye">eye space</a> positions of all of the surfaces that resulted in visible fragments in the scene are lost (unless explicitly saved into the geometry buffer). However, given the knowledge of the <span class="st300_term term">projection</span> that was used to render the scene (such as perspective or orthographic), it's possible to reconstruct the original eye space position of the surfaces that produced each of the fragments in the geometry buffer.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss1c2" href="#st300_p2s21ss1c2" title="Paragraph 2.21.1.2">2</a></div><div class="st300_paragraph">Specifically then, for each fragment <span class="st300_term variable">f</span> in the geometry buffer for which lighting is being applied, a position reconstruction algorithm attempts to reconstruct <span class="st300_term expression">surface_eye</span>  - the eye space position of the surface that produced <span class="st300_term variable">f</span>  - using the screen space position of the current light volume fragment <span class="st300_term expression">position = (screen_x, screen_y)</span> and some form of <span class="st300_term term">depth</span> value (such as the screen space depth of <span class="st300_term variable">f</span> ).</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss1c3" href="#st300_p2s21ss1c3" title="Paragraph 2.21.1.3">3</a></div><div class="st300_paragraph">Position reconstruction is a fundamental technique in deferred rendering, and there are a practically unlimited number of ways to reconstruct eye space positions for fragments, each with various advantages and disadvantages. Some rendering systems actually store the eye space position of each fragment in the geometry buffer, meaning that reconstructing positions means simply reading a value directly from a texture. Some systems store only a normalized eye space depth value in a separate texture: The first step of most position reconstruction algorithms is to compute the original eye space Z value of a fragment, so having this value computed during the population of the geometry buffer reduces the work performed later. Storing an entire eye space position into the geometry buffer is obviously the simplest and requires the least reconstruction work later on, but is costly in terms of memory bandwidth: Storing a full eye space position requires an extra <span class="st300_term expression">4 * 4 = 16</span> bytes of storage per fragment (four 32-bit floating point values). As screen resolutions increase, the costs can be prohibitive. Storing a normalized depth value requires only a single 32-bit floating point value per fragment but even this can be too much on less capable hardware. Some algorithms take advantage of the fact that most projections used to render scenes are perspective projections. Some naive algorithms use the full inverse of the current projection matrix to reconstruct eye space positions having already calculated <a class="st300_link" href="#di.coords.clip">clip space</a> positions.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss1c4" href="#st300_p2s21ss1c4" title="Paragraph 2.21.1.4">4</a></div><div class="st300_paragraph">The algorithm that the <span class="st300_term package">r2</span> package uses for position reconstruction is generalized to handle both orthographic and perspective projections, and uses only the existing <a class="st300_link" href="#di.log_depth">logarithmic depth values</a> that were written to the depth buffer during scene rendering. This keeps the geometry buffer compact, and memory bandwidth requirements comparatively low. The algorithm works with symmetric and asymmetric viewing frustums, but will only work with near and far planes that are parallel to the screen.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss1c5" href="#st300_p2s21ss1c5" title="Paragraph 2.21.1.5">5</a></div><div class="st300_paragraph">The algorithm works in two steps: Firstly, the original <a class="st300_link" href="#di.deferred-position-recon.eye-space-z">eye space Z</a> value of the fragment in question is recovered, and then this Z value is used to recover the full <a class="st300_link" href="#di.deferred-position-recon.eye-space">eye space position</a>.</div></div></div><div class="st300_subsection_container"><a id="di.deferred-position-recon.eye-space-z"/><div class="st300_subsection_title_number"><a id="st300_p2s21ss2" href="#st300_p2s21ss2" title="Subsection 2.21.2: Recovering Eye space Z">2.21.2</a></div><div class="st300_subsection_title">Recovering Eye space Z</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss2c1" href="#st300_p2s21ss2c1" title="Paragraph 2.21.2.1">1</a></div><div class="st300_paragraph">During rendering of arbitrary scenes, vertices specified in <a class="st300_link" href="#di.coords.object">object space</a> are transformed to eye space, and the eye space coordinates are transformed to <a class="st300_link" href="#di.coords.clip">clip space</a> with a <span class="st300_term term">projection matrix</span>. The resulting 4D clip space coordinates are divided by their own <span class="st300_term variable">w</span> components, resulting in <a class="st300_link" href="#di.coords.ndevice">normalized-device space</a> coordinates. These normalized-device space coordinates are then transformed to <a class="st300_link" href="#di.coords.screen">screen space</a> by multiplying by the current <span class="st300_term term">viewport transform</span>. The transitions from clip space to screen space are handled automatically by the graphics hardware.</div></div><div class="st300_paragraph_container"><a id="di.deferred-position-recon.eye-space-z.initial"/><div class="st300_paragraph_number"><a id="st300_p2s21ss2c2" href="#st300_p2s21ss2c2" title="Paragraph 2.21.2.2">2</a></div><div class="st300_paragraph">The first step required is to recover the original eye space Z value of <span class="st300_term variable">f</span>. This involves sampling a depth value from the current depth buffer. Sampling from the depth buffer is achieved as with any other texture: A particular texel is addressed by using coordinates in the range <span class="st300_term expression">[(0, 0), (1, 1)]</span>. The <span class="st300_term package">r2</span> package currently assumes that the size of the <span class="st300_term term">viewport</span> is the same as that of the framebuffer <span class="st300_term expression">(width, height)</span> and that the bottom left corner of the viewport is positioned at <span class="st300_term expression">(0, 0)</span> in screen space. Given the assumption on the position and size of the viewport, and assuming that the screen space position of the current light volume fragment being shaded is <span class="st300_term expression">position = (screen_x, screen_y)</span>, the texture coordinates <span class="st300_term expression">(screen_uv_x, screen_uv_y)</span> used to access the current depth value are given by:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss2c3" href="#st300_p2s21ss2c3" title="Formal item 2.21.2.3: Screen to texture">2.21.2.3 Screen to texture</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ScreenToTexture where

import qualified Vector2f

screen_to_texture :: Vector2f.T -&gt; Float -&gt; Float -&gt; Vector2f.T
screen_to_texture position width height =
  let u = (Vector2f.x position) / width
      v = (Vector2f.y position) / height
  in Vector2f.V2 u v
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss2c4" href="#st300_p2s21ss2c4" title="Paragraph 2.21.2.4">4</a></div><div class="st300_paragraph">Intuitively, <span class="st300_term expression">(screen_uv_x, screen_uv_y) = (0, 0)</span> when the current screen space position is the bottom-left corner of the screen, <span class="st300_term expression">(screen_uv_x, screen_uv_y) = (1, 1)</span> when the current screen space position is the top-right corner of the screen, and <span class="st300_term expression">(screen_uv_x, screen_uv_y) = (0.5, 0.5)</span> when the current screen space position is the exact center of the screen.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss2c5" href="#st300_p2s21ss2c5" title="Paragraph 2.21.2.5">5</a></div><div class="st300_paragraph">Originally, the spiritual ancestor of the <span class="st300_term package">r2</span> package, <span class="st300_term package">r1</span>, used a standard depth buffer and so recovering the eye space Z value required a slightly different method compared to the steps required for the <a class="st300_link" href="#di.log_depth">logarithmic depth encoding</a> that the <span class="st300_term package">r2</span> package uses. For historical reasons and for completeness, the method to reconstruct an eye space Z value from a traditional screen space depth value is given in the section on <a class="st300_link" href="#di.deferred-position-recon.eye-space-z.screen-space-encoding">screen space depth encoding</a>.</div></div></div><div class="st300_subsection_container"><a id="di.deferred-position-recon.eye-space-z.log-depth-encoding"/><div class="st300_subsection_title_number"><a id="st300_p2s21ss3" href="#st300_p2s21ss3" title="Subsection 2.21.3: Recovering Eye space Z (Logarithmic depth encoding)">2.21.3</a></div><div class="st300_subsection_title">Recovering Eye space Z (Logarithmic depth encoding)</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss3c1" href="#st300_p2s21ss3c1" title="Paragraph 2.21.3.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package uses a <a class="st300_link" href="#di.log_depth">logarithmic depth buffer</a>. Depth values sampled from any depth buffer produced by the package can be transformed to a negated eye space Z value by with a simple decoding <a class="st300_link" href="#di.log_depth.encoding">equation</a>.</div></div></div><div class="st300_subsection_container"><a id="di.deferred-position-recon.eye-space-z.screen-space-encoding"/><div class="st300_subsection_title_number"><a id="st300_p2s21ss4" href="#st300_p2s21ss4" title="Subsection 2.21.4: Recovering Eye space Z (Screen space depth encoding)">2.21.4</a></div><div class="st300_subsection_title">Recovering Eye space Z (Screen space depth encoding)</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c1" href="#st300_p2s21ss4c1" title="Paragraph 2.21.4.1">1</a></div><div class="st300_paragraph">Note: This section is for completeness and historical interest. Please skip ahead to the section on <a class="st300_link" href="#di.deferred-position-recon.eye-space">eye space position reconstruction</a> if you are not interested.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c2" href="#st300_p2s21ss4c2" title="Paragraph 2.21.4.2">2</a></div><div class="st300_paragraph">Assuming a screen space depth value <span class="st300_term variable">screen_depth</span> sampled from the depth buffer at <span class="st300_term expression">(screen_uv_x, screen_uv_y)</span>, it's now necessary to transform the depth value back into normalized-device space. In OpenGL, screen space depth values are in the range <span class="st300_term expression">[0, 1]</span> by default, with <span class="st300_term expression">0</span> representing the near plane and <span class="st300_term expression">1</span> representing the far plane. However, in OpenGL, normalized-device space coordinates are in the range <span class="st300_term expression">[(-1, -1, -1), (1, 1, 1)]</span>. The transformation from screen space to normalized-device space is given by:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c3" href="#st300_p2s21ss4c3" title="Formal item 2.21.4.3: Screen space depth to NDC Z">2.21.4.3 Screen space depth to NDC Z</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ScreenDepthToNDC where

screen_depth_to_ndc :: Float -&gt; Float
screen_depth_to_ndc screen_depth =
  (screen_depth * 2.0) - 1.0</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c4" href="#st300_p2s21ss4c4" title="Paragraph 2.21.4.4">4</a></div><div class="st300_paragraph">In order to understand how to calculate the eye space depth value from the resulting NDC Z value <span class="st300_term variable">ndc_z = screen_depth_to_ndc screen_depth</span>, it's necessary to understand how the normalized-device coordinates of <span class="st300_term variable">f</span> were derived in the first place. Given a standard 4x4 projection matrix <span class="st300_term variable">m</span> and an eye space position <span class="st300_term variable">eye</span>, clip space coordinates are calculated by <span class="st300_term variable">Matrix4x4f.mult_v m eye</span>. This means that the <span class="st300_term variable">z</span> component of the resulting clip space coordinates is given by:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c5" href="#st300_p2s21ss4c5" title="Formal item 2.21.4.5: Clip space Z Long (Diagram)">2.21.4.5 Clip space Z Long (Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Clip space Z Long (Diagram)" src="images/matrix_clip_z_long.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c6" href="#st300_p2s21ss4c6" title="Formal item 2.21.4.6: Clip space Z Long">2.21.4.6 Clip space Z Long</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ClipSpaceZLong where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_z_long :: M4x4.T -&gt; V4.T -&gt; Float
clip_z_long m eye =
  let
    m20 = M4x4.row_column m (2, 0)
    m21 = M4x4.row_column m (2, 1)
    m22 = M4x4.row_column m (2, 2)
    m23 = M4x4.row_column m (2, 3)

    k0 = (V4.x eye) * m20
    k1 = (V4.y eye) * m21
    k2 = (V4.z eye) * m22
    k3 = (V4.w eye) * m23
  in
    k0 + k1 + k2 + k3
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c7" href="#st300_p2s21ss4c7" title="Paragraph 2.21.4.7">7</a></div><div class="st300_paragraph">Similarly, the <span class="st300_term variable">w</span> component of the resulting clip space coordinates is given by:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c8" href="#st300_p2s21ss4c8" title="Formal item 2.21.4.8: Clip space W Long (Diagram)">2.21.4.8 Clip space W Long (Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Clip space W Long (Diagram)" src="images/matrix_clip_w_long.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c9" href="#st300_p2s21ss4c9" title="Formal item 2.21.4.9: Clip space W Long">2.21.4.9 Clip space W Long</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ClipSpaceWLong where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_w_long :: M4x4.T -&gt; V4.T -&gt; Float
clip_w_long m eye =
  let
    m30 = M4x4.row_column m (3, 0)
    m31 = M4x4.row_column m (3, 1)
    m32 = M4x4.row_column m (3, 2)
    m33 = M4x4.row_column m (3, 3)

    k0 = (V4.x eye) * m30
    k1 = (V4.y eye) * m31
    k2 = (V4.z eye) * m32
    k3 = (V4.w eye) * m33
  in
    k0 + k1 + k2 + k3
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c10" href="#st300_p2s21ss4c10" title="Paragraph 2.21.4.10">10</a></div><div class="st300_paragraph">However, in the perspective and orthographic projections provided by the <span class="st300_term package">r2</span> package, <span class="st300_term expression">Matrix4x4f.row_column m (2, 0) == 0</span>, <span class="st300_term expression">Matrix4x4f.row_column m (2, 1) == 0</span>, <span class="st300_term expression">Matrix4x4f.row_column m (3, 0) == 0</span>, and <span class="st300_term expression">Matrix4x4f.row_column m (3, 1) == 0</span>. Additionally, the <span class="st300_term variable">w</span> component of all eye space coordinates is <span class="st300_term expression">1</span>. With these assumptions, the previous definitions simplify to:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c11" href="#st300_p2s21ss4c11" title="Formal item 2.21.4.11: Clip space Z Simple (Diagram)">2.21.4.11 Clip space Z Simple (Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Clip space Z Simple (Diagram)" src="images/matrix_clip_z_simple.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c12" href="#st300_p2s21ss4c12" title="Formal item 2.21.4.12: Clip space Z Simple">2.21.4.12 Clip space Z Simple</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ClipSpaceZSimple where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_z_simple :: M4x4.T -&gt; V4.T -&gt; Float
clip_z_simple m eye =
  let
    m22 = M4x4.row_column m (2, 2)
    m23 = M4x4.row_column m (2, 3)
  in
    ((V4.z eye) * m22) + m23
</pre></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c13" href="#st300_p2s21ss4c13" title="Formal item 2.21.4.13: Clip space W Simple (Diagram)">2.21.4.13 Clip space W Simple (Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Clip space W Simple (Diagram)" src="images/matrix_clip_w_simple.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c14" href="#st300_p2s21ss4c14" title="Formal item 2.21.4.14: Clip space W Simple">2.21.4.14 Clip space W Simple</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module ClipSpaceWSimple where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_w_simple :: M4x4.T -&gt; V4.T -&gt; Float
clip_w_simple m eye =
  let
    m32 = M4x4.row_column m (3, 2)
    m33 = M4x4.row_column m (3, 3)
  in
    ((V4.z eye) * m32) + m33
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c15" href="#st300_p2s21ss4c15" title="Paragraph 2.21.4.15">15</a></div><div class="st300_paragraph">It should be noted that for perspective matrices in the <span class="st300_term package">r2</span> package, <span class="st300_term expression">Matrix4x4f.row_column m (3, 2) == -1</span> and <span class="st300_term expression">Matrix4x4f.row_column m (3, 3) == 0</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c16" href="#st300_p2s21ss4c16" title="Formal item 2.21.4.16: Clip space W Simple (Perspective, Diagram)">2.21.4.16 Clip space W Simple (Perspective, Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Clip space W Simple (Perspective, Diagram)" src="images/matrix_clip_w_simple_perspective.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c17" href="#st300_p2s21ss4c17" title="Paragraph 2.21.4.17">17</a></div><div class="st300_paragraph">This means that the <span class="st300_term variable">w</span> component of the resulting clip space coordinates is equal to the negated (and therefore positive) eye space <span class="st300_term variable">z</span> of the original coordinates.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c18" href="#st300_p2s21ss4c18" title="Paragraph 2.21.4.18">18</a></div><div class="st300_paragraph">For orthographic projections in the <span class="st300_term package">r2</span> package, <span class="st300_term expression">Matrix4x4f.row_column m (3, 2) == 0</span> and <span class="st300_term expression">Matrix4x4f.row_column m (3, 3) == 1</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c19" href="#st300_p2s21ss4c19" title="Formal item 2.21.4.19: Clip space W Simple (Orthographic, Diagram)">2.21.4.19 Clip space W Simple (Orthographic, Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Clip space W Simple (Orthographic, Diagram)" src="images/matrix_clip_w_simple_orthographic.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c20" href="#st300_p2s21ss4c20" title="Paragraph 2.21.4.20">20</a></div><div class="st300_paragraph">This means that the <span class="st300_term variable">w</span> component of the resulting clip space coordinates is always equal to <span class="st300_term constant">1</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss4c21" href="#st300_p2s21ss4c21" title="Paragraph 2.21.4.21">21</a></div><div class="st300_paragraph">As stated previously, normalized-device space coordinates are calculated by dividing a set of clip space coordinates by their own <span class="st300_term variable">w</span> component. So, given <span class="st300_term expression">clip_z = ClipSpaceZSimple.clip_z_simple m eye</span> and <span class="st300_term expression">clip_w = ClipSpaceWSimple.clip_w_simple m eye</span> for some arbitrary projection matrix <span class="st300_term variable">m</span> and eye space position <span class="st300_term variable">eye</span>, the normalized-device space Z coordinate is given by <span class="st300_term expression">ndc_z = clip_z / clip_w</span>. Rearranging the definitions of <span class="st300_term expression">clip_z</span> and <span class="st300_term expression">clip_w</span> algebraically yields an equation that takes an arbitrary projection matrix <span class="st300_term variable">m</span> and a normalized-device space Z value <span class="st300_term expression">ndc_z</span> and returns an eye space Z value:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss4c22" href="#st300_p2s21ss4c22" title="Formal item 2.21.4.22: Eye space Z">2.21.4.22 Eye space Z</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module EyeSpaceZ where

import qualified Matrix4f as M4x4;

eye_z :: M4x4.T -&gt; Float -&gt; Float
eye_z m ndc_z =
  let
    m22 = M4x4.row_column m (2, 2)
    m23 = M4x4.row_column m (2, 3)
    m32 = M4x4.row_column m (3, 2)
    m33 = M4x4.row_column m (3, 3)
    
    a = (ndc_z * m33) - m32
    b = (ndc_z * m23) - m22
  in
    - (a / b)
</pre></div></div></div><div class="st300_subsection_container"><a id="di.deferred-position-recon.eye-space"/><div class="st300_subsection_title_number"><a id="st300_p2s21ss5" href="#st300_p2s21ss5" title="Subsection 2.21.5: Recovering Eye space Position">2.21.5</a></div><div class="st300_subsection_title">Recovering Eye space Position</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c1" href="#st300_p2s21ss5c1" title="Paragraph 2.21.5.1">1</a></div><div class="st300_paragraph">Given that the eye space Z value is known, it's now necessary to reconstruct the full eye space position <span class="st300_term expression">surface_eye</span> of the surface that resulted in <span class="st300_term variable">f</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c2" href="#st300_p2s21ss5c2" title="Paragraph 2.21.5.2">2</a></div><div class="st300_paragraph">When the current projection is a perspective projection, there is conceptually a ray passing through the near clipping plane ( <span class="st300_term variable">near</span>) from the origin, oriented towards the eye space position ( <span class="st300_term variable">eye</span>) of <span class="st300_term variable">f</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss5c3" href="#st300_p2s21ss5c3" title="Formal item 2.21.5.3: Perspective projection (Diagram)">2.21.5.3 Perspective projection (Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Perspective projection (Diagram)" src="images/reconstruction_view_perspective.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c4" href="#st300_p2s21ss5c4" title="Paragraph 2.21.5.4">4</a></div><div class="st300_paragraph">When the current projection is an orthographic projection, the ray is always perpendicular to the clipping planes and is offset by a certain amount ( <span class="st300_term variable">q</span>) on the X and Y axes:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss5c5" href="#st300_p2s21ss5c5" title="Formal item 2.21.5.5: Orthographic projection (Diagram)">2.21.5.5 Orthographic projection (Diagram)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Orthographic projection (Diagram)" src="images/reconstruction_view_ortho.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c6" href="#st300_p2s21ss5c6" title="Paragraph 2.21.5.6">6</a></div><div class="st300_paragraph">Assuming <span class="st300_term expression">ray = Vector3f.V3 ray_x ray_y 1.0</span>, the eye space position of <span class="st300_term variable">f</span> is given by <span class="st300_term expression">surface_eye = Vector3f.add3 q (Vector3f.scale ray eye_z)</span>. In the case of perspective projections, <span class="st300_term expression">q = Vector3f.V3 0.0 0.0 0.0</span>. The <span class="st300_term variable">q</span> term is sometimes referred to as the origin (because <span class="st300_term variable">q</span> is the origin of the view ray), but that terminology is not used here in order to avoid confusion between the <span class="st300_term variable">ray</span> origin and the eye space coordinate system origin. It's therefore necessary to calculate <span class="st300_term variable">q</span> and <span class="st300_term variable">ray</span> in order to reconstruct the full eye space position of the fragment. The way this is achieved in the <span class="st300_term package">r2</span> package is to calculate <span class="st300_term variable">q</span> and <span class="st300_term variable">ray</span> for each of the viewing frustum corners <span class="st300_footnote_reference">[<a href="#st300_f_16796_0" id="st300_fr_16386" title="Jump to footnote di.deferred-position-recon.matrix-once (reference 0)">20</a>]</span> and then bilinearly interpolate between the calculated values during rendering based on <span class="st300_term expression">screen_uv_x</span> and <span class="st300_term expression">screen_uv_y</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c7" href="#st300_p2s21ss5c7" title="Paragraph 2.21.5.7">7</a></div><div class="st300_paragraph">As stated previously, normalized-device space coordinates are in the range <span class="st300_term expression">[(-1, -1, -1), (1, 1, 1)]</span>. Stating each of the eight corners of the cube that defines normalized-device space as 4D homogeneous coordinates <span class="st300_footnote_reference">[<a href="#st300_f_16834_0" id="st300_fr_16440" title="Jump to footnote di.deferred-position-recon.w (reference 0)">22</a>]</span> yields the following values:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss5c8" href="#st300_p2s21ss5c8" title="Formal item 2.21.5.8: Normalized-device space corners">2.21.5.8 Normalized-device space corners</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module NDCCorners where

import qualified Vector4f as V4

near_x0y0 :: V4.T
near_x0y0 = V4.V4 (-1.0) (-1.0) (-1.0) 1.0

near_x1y0 :: V4.T
near_x1y0 = V4.V4 1.0 (-1.0) (-1.0) 1.0

near_x0y1 :: V4.T
near_x0y1 = V4.V4 (-1.0) 1.0 (-1.0) 1.0

near_x1y1 :: V4.T
near_x1y1 = V4.V4 1.0 1.0 (-1.0) 1.0

far_x0y0 :: V4.T
far_x0y0 = V4.V4 (-1.0) (-1.0) 1.0 1.0

far_x1y0 :: V4.T
far_x1y0 = V4.V4 1.0 (-1.0) 1.0 1.0

far_x0y1 :: V4.T
far_x0y1 = V4.V4 (-1.0) 1.0 1.0 1.0

far_x1y1 :: V4.T
far_x1y1 = V4.V4 1.0 1.0 1.0 1.0

</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c9" href="#st300_p2s21ss5c9" title="Paragraph 2.21.5.9">9</a></div><div class="st300_paragraph">Then, for the four pairs of near/far corners <span class="st300_term expression">((near_x0y0, far_x0y0)</span>, <span class="st300_term expression">(near_x1y0, far_x1y0)</span>, <span class="st300_term expression">(near_x0y1, far_x0y1)</span>, <span class="st300_term expression">(near_x1y1, far_x1y1))</span>, a <span class="st300_term variable">q</span> and <span class="st300_term variable">ray</span> value is calculated. The <span class="st300_term expression">ray_and_q</span> function describes the calculation for a given pair of near/far corners:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss5c10" href="#st300_p2s21ss5c10" title="Formal item 2.21.5.10: Ray and Q calculation (Single)">2.21.5.10 Ray and Q calculation (Single)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module RayAndQ where

import qualified Matrix4f as M4x4
import qualified Vector4f as V4

-- | Calculate @(ray, q)@ for the given inverse projection matrix and frustum corners
ray_and_q :: M4x4.T -&gt; (V4.T, V4.T) -&gt; (V4.T, V4.T)
ray_and_q inverse_m (near, far) =
  let
    -- Unproject the NDC coordinates to eye-space
    near_hom    = M4x4.mult_v inverse_m near
    near_eye    = V4.div_s near_hom (V4.w near_hom)
    far_hom     = M4x4.mult_v inverse_m far
    far_eye     = V4.div_s far_hom (V4.w far_hom)
    
    -- Calculate a ray with ray.z == 1.0
    ray_initial = V4.sub4 far_eye near_eye
    ray = V4.div_s ray_initial (V4.z ray_initial)
    
    -- Subtract the scaled ray from the near corner to calculate q
    q = V4.sub4 near_eye (V4.scale ray (V4.z near_eye))
  in
    (ray, q)
</pre></div></div><div class="st300_paragraph_container"><a id="di.deferred-position-recon.eye-space.rays_and_qs"/><div class="st300_paragraph_number"><a id="st300_p2s21ss5c11" href="#st300_p2s21ss5c11" title="Paragraph 2.21.5.11">11</a></div><div class="st300_paragraph">The function takes a matrix representing the <span class="st300_term term">inverse</span> of the current projection matrix, and "unprojects" the given near and far frustum corners from normalized-device space to eye space. The desired <span class="st300_term variable">ray</span> value for the pair of corners is simply the vector that results from subtracting the near corner from the far corner, divided by its own <span class="st300_term variable">z</span> component. The desired <span class="st300_term variable">q</span> value is the vector that results from subtracting <span class="st300_term variable">ray</span> scaled by the <span class="st300_term variable">z</span> component of the near corner, from the near corner.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c12" href="#st300_p2s21ss5c12" title="Paragraph 2.21.5.12">12</a></div><div class="st300_paragraph">Note: The function calculates <span class="st300_term variable">ray</span> in eye space, but the resulting value will have a non-negative <span class="st300_term variable">z</span> component. The reason for this is that the resulting ray will be multiplied by the calculated <a class="st300_link" href="#di.deferred-position-recon.eye-space-z">eye space Z value</a> <span class="st300_footnote_reference">[<a href="#st300_f_16849_0" id="st300_fr_16655" title="Jump to footnote di.deferred-position-recon.eye_negative (reference 0)">23</a>]</span> to produce an eye space position. If the <span class="st300_term variable">z</span> component of <span class="st300_term variable">ray</span> was negative, the resulting position would have a positive <span class="st300_term variable">z</span> component.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c13" href="#st300_p2s21ss5c13" title="Paragraph 2.21.5.13">13</a></div><div class="st300_paragraph">Calculating the <span class="st300_term variable">ray</span> and <span class="st300_term variable">q</span> value for each of the pairs of corners is straightforward:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss5c14" href="#st300_p2s21ss5c14" title="Formal item 2.21.5.14: Ray and Q calculation (All)">2.21.5.14 Ray and Q calculation (All)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module RayAndQAll where

import qualified NDCCorners
import qualified RayAndQ
import qualified Matrix4f as M4x4
import qualified Vector4f as V4

data T = T {
  q_x0y0 :: V4.T,
  q_x1y0 :: V4.T,
  q_x0y1 :: V4.T,
  q_x1y1 :: V4.T,
  ray_x0y0 :: V4.T,
  ray_x1y0 :: V4.T,
  ray_x0y1 :: V4.T,
  ray_x1y1 :: V4.T
} deriving (Eq, Ord, Show)

-- | Calculate all rays and qs for the four pairs of near/far frustum corners
calculate :: M4x4.T -&gt; T
calculate inverse_m =
  let
    (x0y0_ray, x0y0_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x0y0, NDCCorners.far_x0y0)
    (x1y0_ray, x1y0_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x1y0, NDCCorners.far_x1y0)
    (x0y1_ray, x0y1_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x0y1, NDCCorners.far_x0y1)
    (x1y1_ray, x1y1_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x1y1, NDCCorners.far_x1y1)
  in
    T {
      q_x0y0 = x0y0_q,
      q_x1y0 = x1y0_q,
      q_x0y1 = x0y1_q,
      q_x1y1 = x1y1_q,
      ray_x0y0 = x0y0_ray,
      ray_x1y0 = x1y0_ray,
      ray_x0y1 = x0y1_ray,
      ray_x1y1 = x1y1_ray
    }
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c15" href="#st300_p2s21ss5c15" title="Paragraph 2.21.5.15">15</a></div><div class="st300_paragraph">Then, by reusing the <span class="st300_term expression">position = (screen_uv_x, screen_uv_y)</span> values calculated during the initial <a class="st300_link" href="#di.deferred-position-recon.eye-space-z.initial">eye space Z</a> calculation, determining <span class="st300_term variable">ray</span> and <span class="st300_term variable">q</span> for the current fragment involves simply bilinearly interpolating between the precalculated values above. Bilinear interpolation between four vectors is defined as:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss5c16" href="#st300_p2s21ss5c16" title="Formal item 2.21.5.16: Bilinear interpolation (Vector4f)">2.21.5.16 Bilinear interpolation (Vector4f)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module Bilinear4 where

import qualified Vector2f as V2
import qualified Vector4f as V4

interpolate :: (V4.T, V4.T, V4.T, V4.T) -&gt; V2.T -&gt; V4.T
interpolate (x0y0, x1y0, x0y1, x1y1) position =
  let u0 = V4.interpolate x0y0 (V2.x position) x1y0
      u1 = V4.interpolate x0y1 (V2.x position) x1y1
  in V4.interpolate u0 (V2.y position) u1
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss5c17" href="#st300_p2s21ss5c17" title="Paragraph 2.21.5.17">17</a></div><div class="st300_paragraph">Finally, now that all of the required components are known, the eye space position <span class="st300_term variable">surface_eye</span> of <span class="st300_term variable">f</span> is calculated as <span class="st300_term expression">surface_eye = Vector3f.add3 q (Vector3f.scale ray eye_z)</span>.</div></div></div><div class="st300_subsection_container"><a id="di.deferred-position-recon.implementation"/><div class="st300_subsection_title_number"><a id="st300_p2s21ss6" href="#st300_p2s21ss6" title="Subsection 2.21.6: Implementation">2.21.6</a></div><div class="st300_subsection_title">Implementation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss6c1" href="#st300_p2s21ss6c1" title="Paragraph 2.21.6.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2ViewRays.html">R2ViewRays</a> class precalculates the <a class="st300_link" href="#di.deferred-position-recon.eye-space.rays_and_qs">rays and q values</a> for each of the current frustum corners, and the results of which are cached and re-used based on the current projection each time the scene is rendered.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss6c2" href="#st300_p2s21ss6c2" title="Paragraph 2.21.6.2">2</a></div><div class="st300_paragraph">The actual position reconstruction is performed in a <span class="st300_term term">fragment shader</span>, producing an eye space Z value using the <span class="st300_term package">GLSL</span> functions in <a class="st300_link_external" href="glsl/com/io7m/r2/shaders/core/R2LogDepth.h">R2LogDepth.h</a> and the final position in <a class="st300_link_external" href="glsl/com/io7m/r2/shaders/core/R2PositionReconstruction.h">R2PositionReconstruction.h</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss6c3" href="#st300_p2s21ss6c3" title="Formal item 2.21.6.3: Position reconstruction (LogDepth)">2.21.6.3 Position reconstruction (LogDepth)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">#ifndef R2_LOG_DEPTH_H
#define R2_LOG_DEPTH_H

/// \file R2LogDepth.h
/// \brief Logarithmic depth functions.

///
/// Prepare an eye-space Z value for encoding. See R2_logDepthEncodePartial.
///
/// @param z An eye-space Z value
/// @return The prepared value
///

float
R2_logDepthPrepareEyeZ(
  const float z)
{
  return 1.0 + (-z);
}

///
/// Partially encode the given _positive_ eye-space Z value. This partial encoding
/// can be used when performing part of the encoding in a vertex shader
/// and the rest in a fragment shader (for efficiency reasons) - See R2_logDepthPrepareEyeZ.
///
/// @param z                 An eye-space Z value
/// @param depth_coefficient The depth coefficient used to encode \a z
///
/// @return The encoded depth
///

float
R2_logDepthEncodePartial(
  const float z,
  const float depth_coefficient)
{
  float half_co = depth_coefficient * 0.5;
  float clamp_z = max (0.000001, z);
  return log2 (clamp_z) * half_co;
}

///
/// Fully encode the given eye-space Z value.
///
/// @param z                 An eye-space Z value
/// @param depth_coefficient The depth coefficient used to encode \a z
/// @return The fully encoded depth
///

float
R2_logDepthEncodeFull(
  const float z,
  const float depth_coefficient)
{
  float half_co = depth_coefficient * 0.5;
  float clamp_z = max (0.000001, z + 1.0);
  return log2 (clamp_z) * half_co;
}

///
/// Decode a depth value that was encoded with the given depth coefficient.
/// Note that in most cases, this will yield a _positive_ eye-space Z value,
/// and must be negated to yield a conventional negative eye-space Z value.
///
/// @param z                 The depth value
/// @param depth_coefficient The coefficient used during encoding
///
/// @return The original (positive) eye-space Z value
///

float
R2_logDepthDecode(
  const float z,
  const float depth_coefficient)
{
  float half_co  = depth_coefficient * 0.5;
  float exponent = z / half_co;
  return pow (2.0, exponent) - 1.0;
}

#endif // R2_LOG_DEPTH_H
</pre></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss6c4" href="#st300_p2s21ss6c4" title="Formal item 2.21.6.4: Position reconstruction (GLSL)">2.21.6.4 Position reconstruction (GLSL)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">#ifndef R2_POSITION_RECONSTRUCTION_H
#define R2_POSITION_RECONSTRUCTION_H

/// \file R2PositionReconstruction.h
/// \brief Functions for performing position reconstruction during deferred rendering.

#include "R2Bilinear.h"
#include "R2ViewRays.h"

///
/// Reconstruct an eye-space position from the given parameters.
///
/// @param eye_z     The eye-space Z value of the position
/// @param uv        The current position on the screen in UV coordinates
/// @param view_rays The current set of view rays
///

vec4
R2_positionReconstructFromEyeZ(
  const float eye_z,
  const vec2 uv,
  const R2_view_rays_t view_rays)
{
  vec3 origin =
    R2_bilinearInterpolate3(
      view_rays.origin_x0y0,
      view_rays.origin_x1y0,
      view_rays.origin_x0y1,
      view_rays.origin_x1y1,
      uv
    );

  vec3 ray_normal =
    R2_bilinearInterpolate3(
      view_rays.ray_x0y0,
      view_rays.ray_x1y0,
      view_rays.ray_x0y1,
      view_rays.ray_x1y1,
      uv
    );

  vec3 ray =
    (ray_normal * eye_z) + origin;

  return vec4 (ray, 1.0);
}

#endif // R2_POSITION_RECONSTRUCTION_H
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s21ss6c5" href="#st300_p2s21ss6c5" title="Paragraph 2.21.6.5">5</a></div><div class="st300_paragraph">The precalculated view ray vectors are passed to the fragment shader in a value of type <span class="st300_term type">R2_view_rays_t</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s21ss6c6" href="#st300_p2s21ss6c6" title="Formal item 2.21.6.6: View Rays (GLSL)">2.21.6.6 View Rays (GLSL)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">#ifndef R2_VIEW_RAYS_H
#define R2_VIEW_RAYS_H

/// \file R2ViewRays.h
/// \brief View ray types

/// The type of view rays used to reconstruct positions during deferred rendering.

struct R2_view_rays_t {
  /// The bottom left origin
  vec3 origin_x0y0;
  /// The bottom right origin
  vec3 origin_x1y0;
  /// The top left origin
  vec3 origin_x0y1;
  /// The top right origin
  vec3 origin_x1y1;
  /// The view ray pointing out of the bottom left origin
  vec3 ray_x0y0;
  /// The view ray pointing out of the bottom right origin
  vec3 ray_x1y0;
  /// The view ray pointing out of the top left origin
  vec3 ray_x0y1;
  /// The view ray pointing out of the top right origin
  vec3 ray_x1y1;
};

#endif // R2_VIEW_RAYS_H
</pre></div></div></div></div><div class="st300_section_container"><a id="di.forward"/><div class="st300_section_title_number"><a id="st300_p2s22" href="#st300_p2s22" title="Section 2.22: Forward rendering (Translucency)">2.22</a></div><div class="st300_section_title">Forward rendering (Translucency)</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss1" title="Link to subsection 2.22.1: Overview">2.22.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss2" title="Link to subsection 2.22.2: Instances">2.22.2. Instances</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss3" title="Link to subsection 2.22.3: Blending">2.22.3. Blending</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss4" title="Link to subsection 2.22.4: Culling">2.22.4. Culling</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss5" title="Link to subsection 2.22.5: Ordering">2.22.5. Ordering</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss6" title="Link to subsection 2.22.6: Types">2.22.6. Types</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s22ss7" title="Link to subsection 2.22.7: Provided Shaders">2.22.7. Provided Shaders</a></li></ul><div class="st300_subsection_container"><a id="di.forward.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss1" href="#st300_p2s22ss1" title="Subsection 2.22.1: Overview">2.22.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss1c1" href="#st300_p2s22ss1c1" title="Paragraph 2.22.1.1">1</a></div><div class="st300_paragraph">Because the <a class="st300_link" href="#di.deferred">deferred renderer</a> in the <span class="st300_term package">r2</span> package is incapable of rendering <span class="st300_term term">translucent</span> instances, a separate <span class="st300_term term">forward renderer</span> is provided. A <span class="st300_term translucent">translucent</span> instance is an instance that, when rendered, is simply blended with the current image. This is used to implement visual effects such as glass, water, smoke, fire, etc.</div></div></div><div class="st300_subsection_container"><a id="di.forward.instances"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss2" href="#st300_p2s22ss2" title="Subsection 2.22.2: Instances">2.22.2</a></div><div class="st300_subsection_title">Instances</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss2c1" href="#st300_p2s22ss2c1" title="Paragraph 2.22.2.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package provides a slightly different abstraction for translucent instances. Because of the strict <a class="st300_link" href="#di.forward.ordering">ordering</a> requirements when rendering translucent instances, it is simply not possible to batch translucent instances by material and shaders for performance reasons as is done with <a class="st300_link" href="#di.deferred.geom.ordering">opaque instances</a>. The <span class="st300_term package">r2</span> package therefore simply has users submit a list of values of type <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2TranslucentType.html">R2TranslucentType</a> in draw order. Each translucent value contains a <a class="st300_link" href="#di.forward.blending">blending</a> and <a class="st300_link" href="#di.forward.culling">culling</a> configuration, along with an <a class="st300_link" href="#di.instances.overview">instance</a>, and a <a class="st300_link" href="#di.shaders.overview">shader</a> for rendering the instance.</div></div></div><div class="st300_subsection_container"><a id="di.forward.blending"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss3" href="#st300_p2s22ss3" title="Subsection 2.22.3: Blending">2.22.3</a></div><div class="st300_subsection_title">Blending</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss3c1" href="#st300_p2s22ss3c1" title="Paragraph 2.22.3.1">1</a></div><div class="st300_paragraph">Each translucent instance provides a blending configuration that states how the rendered instance is blended with the contents of the current framebuffer.</div></div></div><div class="st300_subsection_container"><a id="di.forward.culling"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss4" href="#st300_p2s22ss4" title="Subsection 2.22.4: Culling">2.22.4</a></div><div class="st300_subsection_title">Culling</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss4c1" href="#st300_p2s22ss4c1" title="Paragraph 2.22.4.1">1</a></div><div class="st300_paragraph">Typically, it is not desirable to render the <span class="st300_term term">back faces</span> of opaque instances as they are by definition invisible. However, translucent instances are by definition translucent and therefore the back faces of the instances may be visible. A translucent instance therefore contains a value that specifies whether front faces, back faces, or both should be rendered.</div></div></div><div class="st300_subsection_container"><a id="di.forward.ordering"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss5" href="#st300_p2s22ss5" title="Subsection 2.22.5: Ordering">2.22.5</a></div><div class="st300_subsection_title">Ordering</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss5c1" href="#st300_p2s22ss5c1" title="Paragraph 2.22.5.1">1</a></div><div class="st300_paragraph">Unlike <span class="st300_term term">opaque</span> instances which can be rendered in any order due to depth testing, translucent instances must be rendered in strict <span class="st300_term term">furthest-to-nearest</span> order. The <span class="st300_term package">r2</span> package simply delegates the responsibility of submitting instances in the correct order to the user. This frees the package from having to know anything about the spatial properties of the scene being rendered.</div></div></div><div class="st300_subsection_container"><a id="di.forward.types"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss6" href="#st300_p2s22ss6" title="Subsection 2.22.6: Types">2.22.6</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss6c1" href="#st300_p2s22ss6c1" title="Paragraph 2.22.6.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, translucent instances are rendered via implementations of the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2TranslucentRendererType.html">R2TranslucentRendererType</a> interface.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss6c2" href="#st300_p2s22ss6c2" title="Paragraph 2.22.6.2">2</a></div><div class="st300_paragraph">Shaders for rendering translucent instances are of type <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/types/R2ShaderTranslucentType.html">R2ShaderTranslucentType</a>.</div></div></div><div class="st300_subsection_container"><a id="di.forward.provided"/><div class="st300_subsection_title_number"><a id="st300_p2s22ss7" href="#st300_p2s22ss7" title="Subsection 2.22.7: Provided Shaders">2.22.7</a></div><div class="st300_subsection_title">Provided Shaders</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s22ss7c1" href="#st300_p2s22ss7c1" title="Paragraph 2.22.7.1">1</a></div><div class="st300_paragraph">Because translucent surface can have a massive range of appearances, the <span class="st300_term package">r2</span> package makes no attempt to provide a wide range of shaders for translucent surfaces.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s22ss7c2" href="#st300_p2s22ss7c2" title="Formal item 2.22.7.2: Provided instance shaders">2.22.7.2 Provided instance shaders</a></div><div class="st300_formal_item_content"><table class="st300_table shaders" summary="Provided instance shaders"><thead class="st300_table_head"><tr><th class="st300_table_column_name">Shader</th><th class="st300_table_column_name">Description</th></tr></thead><tbody class="st300_table_body"><tr><td class="st300_table_cell"><a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/provided/R2TranslucentShaderBasicPremultipliedSingle.html">R2TranslucentShaderBasicPremultipliedSingle</a></td><td class="st300_table_cell">Basic textured surface without lighting, with distance fading, producing premultiplied alpha output.</td></tr></tbody></table></div></div></div></div><div class="st300_section_container"><a id="di.normal-mapping"/><div class="st300_section_title_number"><a id="st300_p2s23" href="#st300_p2s23" title="Section 2.23: Normal Mapping">2.23</a></div><div class="st300_section_title">Normal Mapping</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s23ss1" title="Link to subsection 2.23.1: Overview">2.23.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s23ss2" title="Link to subsection 2.23.2: Tangent Space">2.23.2. Tangent Space</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s23ss3" title="Link to subsection 2.23.3: Tangent/Bitangent Generation">2.23.3. Tangent/Bitangent Generation</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s23ss4" title="Link to subsection 2.23.4: Normal Maps">2.23.4. Normal Maps</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s23ss5" title="Link to subsection 2.23.5: Rendering With Normal Maps">2.23.5. Rendering With Normal Maps</a></li></ul><div class="st300_subsection_container"><a id="di.normal-mapping.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s23ss1" href="#st300_p2s23ss1" title="Subsection 2.23.1: Overview">2.23.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss1c1" href="#st300_p2s23ss1c1" title="Paragraph 2.23.1.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package supports the use of <span class="st300_term term">tangent-space normal mapping</span> to allow for per-pixel control over the surface normal of rendered triangles. This allows for meshes to appear to have very complex surface details without requiring those details to actually be rendered as triangles within the scene.</div></div></div><div class="st300_subsection_container"><a id="di.normal-mapping.tangent-space"/><div class="st300_subsection_title_number"><a id="st300_p2s23ss2" href="#st300_p2s23ss2" title="Subsection 2.23.2: Tangent Space">2.23.2</a></div><div class="st300_subsection_title">Tangent Space</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss2c1" href="#st300_p2s23ss2c1" title="Paragraph 2.23.2.1">1</a></div><div class="st300_paragraph">Conceptually, there is a three-dimensional coordinate system based at each vertex, formed by three orthonormal basis vectors: The vertex <span class="st300_term term">normal</span>, <span class="st300_term term">tangent</span> and <span class="st300_term term">bitangent</span> vectors. The <span class="st300_term term">normal</span> vector is a the vector perpendicular to the surface at that vertex. The <span class="st300_term term">tangent</span> and <span class="st300_term term">bitangent</span> vectors are parallel to the surface, and each vector is obviously perpendicular to the other two vectors. This coordinate space is often referred to as <span class="st300_term term">tangent space</span>. The <span class="st300_term term">normal</span> vector actually forms the <span class="st300_term constant">Z</span> axis of the coordinate space, and this fact is central to the process of normal mapping. The coordinate system at each vertex may be left or right-handed depending on the arrangement of UV coordinates at that vertex.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss2c2" href="#st300_p2s23ss2c2" title="Formal item 2.23.2.2: Vertex coordinate system">2.23.2.2 Vertex coordinate system</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Vertex coordinate system" src="images/normal.png"/></div></div></div><div class="st300_subsection_container"><a id="di.normal-mapping.tangent-bitangent-generation"/><div class="st300_subsection_title_number"><a id="st300_p2s23ss3" href="#st300_p2s23ss3" title="Subsection 2.23.3: Tangent/Bitangent Generation">2.23.3</a></div><div class="st300_subsection_title">Tangent/Bitangent Generation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c1" href="#st300_p2s23ss3c1" title="Paragraph 2.23.3.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Tangent</span> and <span class="st300_term term">bitangent</span> vectors can be generated by the modelling programs that artists use to create polygon meshes, but, additionally, the <a class="st300_link_external" href="apidocs/com/io7m/r2/meshes/R2MeshTangents.html">R2MeshTangents</a> class can take an arbitrary mesh with only normal vectors and UV coordinates and produce tangent and bitangent vectors. The full description of the algorithm used is given in <a class="st300_link_external" href="http://www.mathfor3dgameprogramming.com/">Mathematics for 3D Game Programming and Computer Graphics, Third Edition</a> <span class="st300_footnote_reference">[<a href="#st300_f_18280_0" id="st300_fr_17736" title="Jump to footnote di.normal-mapping.tangent-book (reference 0)">24</a>]</span>, and also in an <a class="st300_link_external" href="http://www.terathon.com/code/tangent.html">article</a> by the same author. The actual aim of tangent/bitangent generation is to produce a pair of orthogonal vectors that are oriented to the <span class="st300_term variable">x</span> and <span class="st300_term variable">y</span> axes of an arbitrary texture. In order to do achieve this, the generated vectors are oriented according to the UV coordinates in the mesh.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c2" href="#st300_p2s23ss3c2" title="Paragraph 2.23.3.2">2</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the bitangent vector is not actually stored in the mesh data, and the tangent vector for any given vertex is instead stored as a four-component vector. The reasons for this are as follows: Because the normal, tangent, and bitangent vectors are known to be orthonormal, it should be possible to reconstruct any one of the three vectors given the other two at run-time. This would eliminate the need to store one of the vectors and would reduce the size of mesh data (including the on-disk size, and the size of mesh data allocated on the GPU) by a significant amount. Given any two orthogonal vectors <span class="st300_term constant">V0</span> and <span class="st300_term constant">V1</span>, a vector orthogonal to both can be calculated by taking the <span class="st300_term term">cross product</span> of both, denoted <span class="st300_term expression">(cross V0 V1)</span>. The problem here is that if <span class="st300_term constant">V0</span> is assumed to be the original normal vector <span class="st300_term constant">N</span>, and <span class="st300_term constant">V1</span> is assumed to be the original tangent vector <span class="st300_term constant">T</span>, there is no guarantee that <span class="st300_term expression">(cross N T)</span> will produce a vector equal to the original bitangent vector <span class="st300_term constant">B</span>: There are two possible choices of value for <span class="st300_term constant">B</span> that differ only in the sign of their coordinate values.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c3" href="#st300_p2s23ss3c3" title="Paragraph 2.23.3.3">3</a></div><div class="st300_paragraph">As an example, a triangle that will produce <span class="st300_term constant">T</span> and <span class="st300_term constant">B</span> vectors that form a right-handed coordinate system with the normal vector <span class="st300_term constant">N</span> (with UV coordinates indicated at each vertex):</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss3c4" href="#st300_p2s23ss3c4" title="Formal item 2.23.3.4: Tangent generation (RHC)">2.23.3.4 Tangent generation (RHC)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Tangent generation (Resulting in a right-handed coordinate system)" src="images/tangent_gen_RHC.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c5" href="#st300_p2s23ss3c5" title="Paragraph 2.23.3.5">5</a></div><div class="st300_paragraph">The same triangle will produce vectors that form a left-handed system when generating vectors for another vertex (note that the result of <span class="st300_term expression">(Vector3f.cross N T) = (Vector3f.negation B)</span> ):</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss3c6" href="#st300_p2s23ss3c6" title="Formal item 2.23.3.6: Tangent generation (LHC)">2.23.3.6 Tangent generation (LHC)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Tangent generation (Resulting in a left-handed coordinate system)" src="images/tangent_gen_LHC.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c7" href="#st300_p2s23ss3c7" title="Paragraph 2.23.3.7">7</a></div><div class="st300_paragraph">However, if the original tangent vector <span class="st300_term constant">T</span> was augmented with a piece of extra information that indicated whether or not the result of <span class="st300_term expression">(cross N T)</span> needed to be inverted, then reconstructing <span class="st300_term constant">B</span> would be trivial. Therefore, the fourth component of the tangent vector <span class="st300_term constant">T</span> contains <span class="st300_term constant">1.0</span> if <span class="st300_term expression">(cross N T) = B</span>, and <span class="st300_term constant">-1.0</span> if <span class="st300_term expression">(cross N T) = -B</span>. The bitangent vector can therefore be reconstructed by calculating <span class="st300_term expression">cross (N, T.xyz) * T.w</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c8" href="#st300_p2s23ss3c8" title="Paragraph 2.23.3.8">8</a></div><div class="st300_paragraph">With the three vectors <span class="st300_term expression">(T, B, N)</span>, it's now possible construct a <span class="st300_term expression">3x3</span> matrix that can transform arbitrary vectors in <a class="st300_link" href="#di.normal-mapping.tangent-space">tangent space</a> to <a class="st300_link" href="#di.coords.object">object space</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss3c9" href="#st300_p2s23ss3c9" title="Formal item 2.23.3.9: Tangent → Object matrix">2.23.3.9 Tangent → Object matrix</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Tangent → Object matrix" src="images/tangent_object_matrix.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss3c10" href="#st300_p2s23ss3c10" title="Paragraph 2.23.3.10">10</a></div><div class="st300_paragraph">With this matrix, it's now obviously possible to take an arbitrary vector in tangent space and transform it to object space. Then, with the current <span class="st300_term term">normal matrix</span> (object → eye), transform the object space vector all the way to <a class="st300_link" href="#di.coords.eye">eye space</a> in the same manner as ordinary per-vertex object space normal vectors.</div></div></div><div class="st300_subsection_container"><a id="di.normal-mapping.map"/><div class="st300_subsection_title_number"><a id="st300_p2s23ss4" href="#st300_p2s23ss4" title="Subsection 2.23.4: Normal Maps">2.23.4</a></div><div class="st300_subsection_title">Normal Maps</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss4c1" href="#st300_p2s23ss4c1" title="Paragraph 2.23.4.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">normal map</span> is an ordinary RGB texture where each texel represents a tangent space normal vector. The <span class="st300_term variable">x</span> coordinate is stored in the red channel, the <span class="st300_term variable">y</span> coordinate is stored in the green channel, and the <span class="st300_term variable">z</span> coordinate is stored in the blue channel. The original coordinate values are assumed to fall within the inclusive range <span class="st300_term expression">[-1.0, 1.0]</span>, and these values are mapped to the range <span class="st300_term expression">[0.0, 1.0]</span> before being encoded to a specific pixel format.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss4c2" href="#st300_p2s23ss4c2" title="Paragraph 2.23.4.2">2</a></div><div class="st300_paragraph">As an example, the vector <span class="st300_term constant">(0.0, 0.0, 1.0)</span> is first mapped to <span class="st300_term constant">(0.5, 0.5, 1.0)</span> and then, assuming an image format with 8-bits of precision per color channel, encoded to <span class="st300_term constant">(0x7f, 0x7f, 0xff)</span>. This results in a pale blue color that is characteristic of tangent space normal maps:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss4c3" href="#st300_p2s23ss4c3" title="Formal item 2.23.4.3: (0.0, 0.0, 1.0)">2.23.4.3 (0.0, 0.0, 1.0)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="(0.0, 0.0, 1.0)" src="images/normalmap_zerozeroone.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss4c4" href="#st300_p2s23ss4c4" title="Paragraph 2.23.4.4">4</a></div><div class="st300_paragraph">Typically, tangent space normal maps are generated from a simple height maps: Greyscale images where <span class="st300_term constant">0.0</span> denotes the lowest possible height, and <span class="st300_term constant">1.0</span> indicates the highest possible height. There are multiple algorithms that are capable of generating normal vectors from height maps, but the majority of them work from the same basic principle: For a given pixel with value <span class="st300_term variable">h</span> at location <span class="st300_term expression">(x, y)</span> in an image, the neighbouring pixel values at <span class="st300_term expression">(x - 1, y)</span>, <span class="st300_term expression">(x - 1, y - 1)</span>, <span class="st300_term expression">(x + 1, y)</span>, <span class="st300_term expression">(x + 1, y + 1)</span> are compared with <span class="st300_term variable">h</span> in order to determine the <span class="st300_term term">slope</span> between the height values. As an example, the <a class="st300_link_external" href="https://en.wikipedia.org/wiki/Prewitt_operator">Prewitt (3x3) operator</a> when used from the <a class="st300_link_external" href="https://code.google.com/p/gimp-normalmap/">gimp-normalmap</a> plugin will produce the following map from a given greyscale height map:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss4c5" href="#st300_p2s23ss4c5" title="Formal item 2.23.4.5: Prewitt 3x3 normal map">2.23.4.5 Prewitt 3x3 normal map</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Prewitt 3x3 normal map" src="images/normalmap_fromheight.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss4c6" href="#st300_p2s23ss4c6" title="Paragraph 2.23.4.6">6</a></div><div class="st300_paragraph">It is reasonably easy to infer the general directions of vectors from a visual inspection of a tangent space normal map alone. In the above image, the flat faces of the bricks are mostly pale blue. This is because the tangent space normal for that surface is pointing straight towards the viewer - mostly towards the positive <span class="st300_term variable">z</span> direction. The right edges of the bricks in the image are tinted with a pinkish hue - this indicates that the normal vectors at that pixel point mostly towards the positive <span class="st300_term variable">x</span> direction.</div></div></div><div class="st300_subsection_container"><a id="di.normal-mapping.rendering"/><div class="st300_subsection_title_number"><a id="st300_p2s23ss5" href="#st300_p2s23ss5" title="Subsection 2.23.5: Rendering With Normal Maps">2.23.5</a></div><div class="st300_subsection_title">Rendering With Normal Maps</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss5c1" href="#st300_p2s23ss5c1" title="Paragraph 2.23.5.1">1</a></div><div class="st300_paragraph">As stated, the purpose of a normal map is to give per-pixel control over the surface normal for a given triangle during rendering. The process is as follows:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss5c2" href="#st300_p2s23ss5c2" title="Formal item 2.23.5.2: Rendering process">2.23.5.2 Rendering process</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Calculate the bitangent vector <span class="st300_term constant">B</span> from the <span class="st300_term constant">N</span> and <span class="st300_term constant">T</span> vectors. This step is performed on a per-vertex basis (in the <span class="st300_term term">vertex shader</span> ).</li><li class="st300_list_item">Construct a <span class="st300_term constant">3x3</span> tangent → object matrix <span class="st300_term variable">M</span> from the <span class="st300_term expression">(T, B, N)</span> vectors. This step is performed on a per-fragment basis (in the <span class="st300_term term">fragment shader</span>) using the interpolated vectors calculated in the previous step.</li><li class="st300_list_item">Sample a tangent space normal vector <span class="st300_term variable">P</span> from the current normal map.</li><li class="st300_list_item">Transform the vector <span class="st300_term variable">P</span> with the matrix <span class="st300_term variable">M</span> by calculating <span class="st300_term expression">M * P</span>, resulting in an object space normal vector <span class="st300_term variable">Q</span>.</li><li class="st300_list_item">Transform the vector <span class="st300_term variable">Q</span> to eye space, in the same manner that an ordinary per-vertex normal vector would be (using the <a class="st300_link" href="#di.coords.eye.normal-matrix">3x3 normal matrix</a> ).</li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss5c3" href="#st300_p2s23ss5c3" title="Paragraph 2.23.5.3">3</a></div><div class="st300_paragraph">Effectively, a "replacement" normal vector is sampled from the map, and transformed to object space using the existing <span class="st300_term expression">(T, B, N)</span> vectors. When the replacement normal vector is used when applying lighting, the effect is dramatic. Given a simple two-polygon square textured with the following albedo texture and normal map:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss5c4" href="#st300_p2s23ss5c4" title="Formal item 2.23.5.4: Example albedo and normal maps">2.23.5.4 Example albedo and normal maps</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Example albedo and normal maps" src="images/normalmap_metalpanels.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss5c5" href="#st300_p2s23ss5c5" title="Paragraph 2.23.5.5">5</a></div><div class="st300_paragraph">The square when textured and normal mapped, with three spherical lights:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss5c6" href="#st300_p2s23ss5c6" title="Formal item 2.23.5.6: Lit and normal mapped">2.23.5.6 Lit and normal mapped</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Lit and normal mapped" src="images/normalmap_applied.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s23ss5c7" href="#st300_p2s23ss5c7" title="Paragraph 2.23.5.7">7</a></div><div class="st300_paragraph">The same square with the same lights but missing the normal map:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s23ss5c8" href="#st300_p2s23ss5c8" title="Formal item 2.23.5.8: Lit and not normal mapped">2.23.5.8 Lit and not normal mapped</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Lit and not normal mapped" src="images/normalmap_none.png"/></div></div></div></div><div class="st300_section_container"><a id="di.log_depth"/><div class="st300_section_title_number"><a id="st300_p2s24" href="#st300_p2s24" title="Section 2.24: Logarithmic Depth">2.24</a></div><div class="st300_section_title">Logarithmic Depth</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s24ss1" title="Link to subsection 2.24.1: Overview">2.24.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s24ss2" title="Link to subsection 2.24.2: OpenGL Depth Issues">2.24.2. OpenGL Depth Issues</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s24ss3" title="Link to subsection 2.24.3: Logarithmic Encoding">2.24.3. Logarithmic Encoding</a></li></ul><div class="st300_subsection_container"><a id="di.log_depth.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s24ss1" href="#st300_p2s24ss1" title="Subsection 2.24.1: Overview">2.24.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss1c1" href="#st300_p2s24ss1c1" title="Paragraph 2.24.1.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package exclusively utilizes a so-called <span class="st300_term term">logarithmic depth buffer</span> for all rendering operations.</div></div></div><div class="st300_subsection_container"><a id="di.log_depth.issues_existing"/><div class="st300_subsection_title_number"><a id="st300_p2s24ss2" href="#st300_p2s24ss2" title="Subsection 2.24.2: OpenGL Depth Issues">2.24.2</a></div><div class="st300_subsection_title">OpenGL Depth Issues</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss2c1" href="#st300_p2s24ss2c1" title="Paragraph 2.24.2.1">1</a></div><div class="st300_paragraph">By default, OpenGL (effectively) stores a depth value proportional to the reciprocal of the <span class="st300_term variable">z</span> component of the <a class="st300_link" href="#di.coords.clip">clip space</a> coordinates of each vertex projected onto the screen <span class="st300_footnote_reference">[<a href="#st300_f_19245_0" id="st300_fr_19051" title="Jump to footnote di.log_depth.love_depth (reference 0)">25</a>]</span>. Informally, the <span class="st300_term term">perspective projection</span> matrix used to transform <a class="st300_link" href="#di.coords.eye">eye space</a> coordinates to clip space will place the negated <span class="st300_term variable">z</span> component of the original eye space coordinates into the <span class="st300_term variable">w</span> component of the resulting clip space coordinates. When the hardware performs the <a class="st300_link" href="#di.coords.ndevice">division by w</a> to produce normalized-device space coordinates, the resulting <span class="st300_term variable">z</span> component falls within the range <span class="st300_term expression">[-1.0, 1.0]</span> (although any point with a <span class="st300_term variable">z</span> component less than <span class="st300_term constant">0</span> will be clipped away by the clipping hardware). This final value is linearly mapped to a configurable range (typically <span class="st300_term expression">[0.0, 1.0]</span>) to produce a <a class="st300_link" href="#di.coords.screen">screen space</a> depth value.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss2c2" href="#st300_p2s24ss2c2" title="Paragraph 2.24.2.2">2</a></div><div class="st300_paragraph">Unfortunately, the encoding scheme above means that most of the depth buffer is essentially wasted. The above scheme will give excessive precision for objects close to the viewing plane, and almost none for objects further away. Fortunately, a better encoding scheme known as <span class="st300_term term">logarithmic depth</span> <span class="st300_footnote_reference">[<a href="#st300_f_19262_0" id="st300_fr_19224" title="Jump to footnote di.log_depth.kemen (reference 0)">26</a>]</span> can be implemented that provides vastly greater precision and coexists happily with the standard projection matrices used in OpenGL-based renderers.</div></div></div><div class="st300_subsection_container"><a id="di.log_depth.encoding"/><div class="st300_subsection_title_number"><a id="st300_p2s24ss3" href="#st300_p2s24ss3" title="Subsection 2.24.3: Logarithmic Encoding">2.24.3</a></div><div class="st300_subsection_title">Logarithmic Encoding</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c1" href="#st300_p2s24ss3c1" title="Paragraph 2.24.3.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">logarithmic depth value</span> is produced by encoding a negated (and therefore <span class="st300_term term">positive</span>) eye space <span class="st300_term variable">z</span> value in the manner specified by <span class="st300_term function">encode</span> <a class="st300_link_external" href="haskell/LogDepth.hs">LogDepth.hs</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s24ss3c2" href="#st300_p2s24ss3c2" title="Formal item 2.24.3.2: Logarithmic Depth (Encoding)">2.24.3.2 Logarithmic Depth (Encoding)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module LogDepth where

newtype LogDepth =
  LogDepth Float
    deriving (Eq, Ord, Show)

type Depth = Float

log2 :: Float -&gt; Float
log2 = logBase 2.0

depth_coefficient :: Float -&gt; Float
depth_coefficient far = 2.0 / log2 (far + 1.0)

encode :: Float -&gt; Depth -&gt; LogDepth
encode depth_co depth =
  let hco = depth_co * 0.5 in
    LogDepth $ log2 (depth + 1.0) * hco

decode :: Float -&gt; LogDepth -&gt; Depth
decode depth_co (LogDepth depth) =
  let hco = depth_co * 0.5 in
    (2.0 ** (depth / hco)) - 1
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c3" href="#st300_p2s24ss3c3" title="Paragraph 2.24.3.3">3</a></div><div class="st300_paragraph">The function is parameterized by a so-called <span class="st300_term term">depth coefficient</span> that is derived from the <span class="st300_term term">far plane distance</span> as shown by <span class="st300_term expression">depth_coefficient</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c4" href="#st300_p2s24ss3c4" title="Paragraph 2.24.3.4">4</a></div><div class="st300_paragraph">The inverse of <span class="st300_term function">encode</span> is <span class="st300_term function">decode</span>, such that for a given negated eye space <span class="st300_term variable">z</span>, <span class="st300_term expression">z = decode d (encode d z)</span>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c5" href="#st300_p2s24ss3c5" title="Paragraph 2.24.3.5">5</a></div><div class="st300_paragraph">A graph of the functions is as follows:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s24ss3c6" href="#st300_p2s24ss3c6" title="Formal item 2.24.3.6: Logarithmic Depth (Graph)">2.24.3.6 Logarithmic Depth (Graph)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Logarithmic Depth (Graph)" src="images/log_depth.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c7" href="#st300_p2s24ss3c7" title="Paragraph 2.24.3.7">7</a></div><div class="st300_paragraph">An interactive <a class="st300_link_external" href="http://geogebra.org">GeoGebra</a> construction is provided in <a class="st300_link_external" href="log_depth.ggb">log_depth.ggb</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c8" href="#st300_p2s24ss3c8" title="Paragraph 2.24.3.8">8</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package uses a slightly modified version of the encoding function that clamps the original <span class="st300_term variable">z</span> value to the range <span class="st300_term expression">[0.000001, ∞]</span>. The reason for this is that <span class="st300_term expression">log2 (0)</span> is undefined, and so attempting to derive a depth value in this manner tends to cause issues with triangle clipping. The encoding function is also separated into two parts as a simple optimization: The encoding function contains a term <span class="st300_term expression">z + 1.0</span>, and this term can be calculated by a <span class="st300_term term">vertex shader</span> and interpolated. The actual functions as implemented are given by <a class="st300_link_external" href="glsl/com/io7m/r2/shaders/core/R2LogDepth.h">R2LogDepth.h</a>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s24ss3c9" href="#st300_p2s24ss3c9" title="Formal item 2.24.3.9: Logarithmic Depth (GLSL)">2.24.3.9 Logarithmic Depth (GLSL)</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">#ifndef R2_LOG_DEPTH_H
#define R2_LOG_DEPTH_H

/// \file R2LogDepth.h
/// \brief Logarithmic depth functions.

///
/// Prepare an eye-space Z value for encoding. See R2_logDepthEncodePartial.
///
/// @param z An eye-space Z value
/// @return The prepared value
///

float
R2_logDepthPrepareEyeZ(
  const float z)
{
  return 1.0 + (-z);
}

///
/// Partially encode the given _positive_ eye-space Z value. This partial encoding
/// can be used when performing part of the encoding in a vertex shader
/// and the rest in a fragment shader (for efficiency reasons) - See R2_logDepthPrepareEyeZ.
///
/// @param z                 An eye-space Z value
/// @param depth_coefficient The depth coefficient used to encode \a z
///
/// @return The encoded depth
///

float
R2_logDepthEncodePartial(
  const float z,
  const float depth_coefficient)
{
  float half_co = depth_coefficient * 0.5;
  float clamp_z = max (0.000001, z);
  return log2 (clamp_z) * half_co;
}

///
/// Fully encode the given eye-space Z value.
///
/// @param z                 An eye-space Z value
/// @param depth_coefficient The depth coefficient used to encode \a z
/// @return The fully encoded depth
///

float
R2_logDepthEncodeFull(
  const float z,
  const float depth_coefficient)
{
  float half_co = depth_coefficient * 0.5;
  float clamp_z = max (0.000001, z + 1.0);
  return log2 (clamp_z) * half_co;
}

///
/// Decode a depth value that was encoded with the given depth coefficient.
/// Note that in most cases, this will yield a _positive_ eye-space Z value,
/// and must be negated to yield a conventional negative eye-space Z value.
///
/// @param z                 The depth value
/// @param depth_coefficient The coefficient used during encoding
///
/// @return The original (positive) eye-space Z value
///

float
R2_logDepthDecode(
  const float z,
  const float depth_coefficient)
{
  float half_co  = depth_coefficient * 0.5;
  float exponent = z / half_co;
  return pow (2.0, exponent) - 1.0;
}

#endif // R2_LOG_DEPTH_H
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c10" href="#st300_p2s24ss3c10" title="Paragraph 2.24.3.10">10</a></div><div class="st300_paragraph">A fragment shader can use <span class="st300_term function">encode_full</span> to compute a logarithmic depth value from a given positive eye space <span class="st300_term variable">z</span> value. Alternatively, a vertex shader can compute the <span class="st300_term expression">z + 1.0</span> term <span class="st300_term variable">r</span> from a non-negated eye space <span class="st300_term variable">z</span> value, and pass <span class="st300_term variable">r</span> to a cooperating fragment shader which then finishes the computation by applying <span class="st300_term function">encode_partial</span> to <span class="st300_term variable">r</span>. When performing <a class="st300_link" href="#di.deferred-position-recon">position reconstruction</a> during <span class="st300_term term">deferred rendering</span>, the original eye space <span class="st300_term variable">z</span> value of a fragment is retrieved by negating the result of <span class="st300_term function">decode</span> applied to a given logarithmic depth sample.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s24ss3c11" href="#st300_p2s24ss3c11" title="Paragraph 2.24.3.11">11</a></div><div class="st300_paragraph">The original derivation of the encoding and decoding functions as described by Brano Kemen used the <span class="st300_term variable">w</span> component of the resulting clip space coordinates. Unfortunately, this does not work correctly with orthographic projections, as the typical orthographic projection matrix will produce clip space coordinates with a <span class="st300_term variable">w</span> component always equal to <span class="st300_term constant">1</span>. Aside from the effects that this will have on depth testing (essentially mapping the depth of all fragments to the far plane), it also makes position reconstruction impossible as the original eye space <span class="st300_term variable">z</span> value cannot be recovered. Instead, the <span class="st300_term package">r2</span> package uses the negated eye space <span class="st300_term variable">z</span> value directly in all cases.</div></div></div></div><div class="st300_section_container"><a id="di.environment-mapping"/><div class="st300_section_title_number"><a id="st300_p2s25" href="#st300_p2s25" title="Section 2.25: Environment Mapping">2.25</a></div><div class="st300_section_title">Environment Mapping</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s25ss1" title="Link to subsection 2.25.1: Overview">2.25.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s25ss2" title="Link to subsection 2.25.2: Cube Maps">2.25.2. Cube Maps</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s25ss3" title="Link to subsection 2.25.3: Reflections">2.25.3. Reflections</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s25ss4" title="Link to subsection 2.25.4: Handedness">2.25.4. Handedness</a></li></ul><div class="st300_subsection_container"><a id="di.environment-mapping.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s25ss1" href="#st300_p2s25ss1" title="Subsection 2.25.1: Overview">2.25.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss1c1" href="#st300_p2s25ss1c1" title="Paragraph 2.25.1.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Environment mapping</span> is conceptually the process of constructing an artificial environment around an object in order to provide, for example, effects such as reflective surfaces or refractive objects. In the <span class="st300_term package">r2</span> package, the artificial environment is represented by <a class="st300_link" href="#di.environment-mapping.cube-maps">cube maps</a>, and the only provided effect is a simulation of <span class="st300_term reflection">reflection</span>. Effects such as refraction are instead provided via <a class="st300_link" href="#di.generic-refraction">generic refraction</a>, which doesn't use environment mapping.</div></div></div><div class="st300_subsection_container"><a id="di.environment-mapping.cube-maps"/><div class="st300_subsection_title_number"><a id="st300_p2s25ss2" href="#st300_p2s25ss2" title="Subsection 2.25.2: Cube Maps">2.25.2</a></div><div class="st300_subsection_title">Cube Maps</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss2c1" href="#st300_p2s25ss2c1" title="Paragraph 2.25.2.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">cube map</span> is a <span class="st300_term term">texture</span> with six <span class="st300_term term">faces</span>. When used for environment mapping, each face represents a 90° image of the environment visible in the direction (in <a class="st300_link" href="#di.coords.world">world space</a>) of that face. Cube maps are normally constructed by placing an observer in a scene and then orienting the observer in the direction of each cube face in turn and rendering an image. As an example:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s25ss2c2" href="#st300_p2s25ss2c2" title="Formal item 2.25.2.2: Cube map scene">2.25.2.2 Cube map scene</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Cube map scene" src="images/envmap_cube_scene.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss2c3" href="#st300_p2s25ss2c3" title="Paragraph 2.25.2.3">3</a></div><div class="st300_paragraph">Given the above scene, with the observer placed exactly in the center of the indicated magenta circle and assuming a 90° field of view, the six images visible from that location corresponding to the <span class="st300_term constant">-x</span>, <span class="st300_term constant">+x</span>, <span class="st300_term constant">-y</span>, <span class="st300_term constant">-z</span>, <span class="st300_term constant">-z</span>, <span class="st300_term constant">+z</span> cube faces are:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s25ss2c4" href="#st300_p2s25ss2c4" title="Formal item 2.25.2.4: Cube map example">2.25.2.4 Cube map example</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Cube map example" src="images/envmap_cubemap.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss2c5" href="#st300_p2s25ss2c5" title="Paragraph 2.25.2.5">5</a></div><div class="st300_paragraph">While sampling from ordinary two-dimensional textures involves looking up texels by their two-dimensional coordinates, sampling from cube maps requires three-dimensional coordinates. The three-dimensional coordinates are interpreted as a direction vector or ray emanating from the center of the cube, and the point of intersection between the ray and the corresponding cube face is used to select a texel from that face. Note that in OpenGL there are issues with <a class="st300_link" href="#di.environment-mapping.handedness">coordinate system handedness</a> that the <span class="st300_term package">r2</span> package corrects.</div></div></div><div class="st300_subsection_container"><a id="di.environment-mapping.reflection"/><div class="st300_subsection_title_number"><a id="st300_p2s25ss3" href="#st300_p2s25ss3" title="Subsection 2.25.3: Reflections">2.25.3</a></div><div class="st300_subsection_title">Reflections</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss3c1" href="#st300_p2s25ss3c1" title="Paragraph 2.25.3.1">1</a></div><div class="st300_paragraph">So-called <span class="st300_term term">environment-mapped reflections</span> are trivially provided by cube maps. For a given surface with a normal vector <span class="st300_term variable">n</span>, and given the view direction <span class="st300_term variable">v</span> (from the observer to the surface), a <span class="st300_term term">reflection vector</span> is given by <span class="st300_term expression">r = Reflection.reflection v n</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s25ss3c2" href="#st300_p2s25ss3c2" title="Formal item 2.25.3.2: Reflection vector">2.25.3.2 Reflection vector</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module Reflection where

import qualified Vector3f as V3

reflection :: V3.T -&gt; V3.T -&gt; V3.T
reflection v0 v1 = V3.sub3 v0 (V3.scale v1 (2.0 * (V3.dot3 v1 v0)))
</pre></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss3c3" href="#st300_p2s25ss3c3" title="Paragraph 2.25.3.3">3</a></div><div class="st300_paragraph">The reflection vector <span class="st300_term variable">r</span> is then used to look up a texel in the current cube map directly. This gives a convincing illusion of reflection that will change as the observer moves relative to the surface. Combining normal mapping and environment mapped reflections gives a striking effect:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s25ss3c4" href="#st300_p2s25ss3c4" title="Formal item 2.25.3.4: Normal/Environment mapping">2.25.3.4 Normal/Environment mapping</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Normal/Environment mapping" src="images/envmap_tiles.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s25ss3c5" href="#st300_p2s25ss3c5" title="Formal item 2.25.3.5: Normal/Environment mapping (Cube map)">2.25.3.5 Normal/Environment mapping (Cube map)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Normal/Environment mapping (Cube map)" src="images/envmap_toronto.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss3c6" href="#st300_p2s25ss3c6" title="Paragraph 2.25.3.6">6</a></div><div class="st300_paragraph">Note that in the actual <span class="st300_term package">r2</span> implementation, the vectors <span class="st300_term variable">n</span> and <span class="st300_term variable">v</span> will be in eye-space and therefore so will <span class="st300_term variable">r</span>. The vector <span class="st300_term variable">r</span> is transformed back to <a class="st300_link" href="#di.coords.world">world space</a> by the inverse of the current view matrix for use with the cube map.</div></div></div><div class="st300_subsection_container"><a id="di.environment-mapping.handedness"/><div class="st300_subsection_title_number"><a id="st300_p2s25ss4" href="#st300_p2s25ss4" title="Subsection 2.25.4: Handedness">2.25.4</a></div><div class="st300_subsection_title">Handedness</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s25ss4c1" href="#st300_p2s25ss4c1" title="Paragraph 2.25.4.1">1</a></div><div class="st300_paragraph">For reasons lost to time, cube maps in OpenGL use a left-handed coordinate system in contrast to the usual right-handed coordinate system. Because of this, calculated reflection vectors actually have to be inverted to prevent sampling from the wrong cube face. The <span class="st300_term package">r2</span> package enforces a consistent right-handed coordinate system everywhere. The direction of each cube face corresponds to the same direction in <a class="st300_link" href="#di.coords.world">world space</a>, without exception.</div></div></div></div><div class="st300_section_container"><a id="di.stippling"/><div class="st300_section_title_number"><a id="st300_p2s26" href="#st300_p2s26" title="Section 2.26: Stippling">2.26</a></div><div class="st300_section_title">Stippling</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s26ss1" title="Link to subsection 2.26.1: Overview">2.26.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s26ss2" title="Link to subsection 2.26.2: Algorithm">2.26.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s26ss3" title="Link to subsection 2.26.3: Types">2.26.3. Types</a></li></ul><div class="st300_subsection_container"><a id="di.stippling.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s26ss1" href="#st300_p2s26ss1" title="Subsection 2.26.1: Overview">2.26.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s26ss1c1" href="#st300_p2s26ss1c1" title="Paragraph 2.26.1.1">1</a></div><div class="st300_paragraph">One major issue with <a class="st300_link" href="#di.deferred">deferred rendering</a> is that it does not allow for <span class="st300_term term">translucency</span>; the scene is placed into a single flat image and there is no way to express the fact that an object is to be overlaid on top of another object. This can be a problem when implementing systems such as <span class="st300_term term">level-of-detail</span> (or <span class="st300_term term">LOD</span>) switching. A basic requirement for an LOD system is that when the viewer moves a certain distance away from an object, that object should be replaced with a lower-polygon version in order to reduce rendering costs. Switching from a high polygon version to a low polygon version in one frame can be visually jarring, however, so it is usually desirable to fade out one version of the object whilst fading in another version over the course of a few frames. This presents an immediate problem: It is not possible to implement traditional alpha translucency fading in a deferred rendering system, as described above.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s26ss1c2" href="#st300_p2s26ss1c2" title="Paragraph 2.26.1.2">2</a></div><div class="st300_paragraph">The <span class="st300_term term">stippling</span> technique attempts to provide an alternative to alpha translucency. The technique is simple: Simply discard some pixels of an object when the object is rendered into the <a class="st300_link" href="#di.deferred.geom">geometry buffer</a>. By progressively discarding more pixels over the course of a few frames, the object can be made to fade . If the pattern of discarded pixels is randomized and the fading time is short, the result is visually acceptable for implementing <span class="st300_term term">LOD</span> systems.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s26ss1c3" href="#st300_p2s26ss1c3" title="Formal item 2.26.1.3: Stippling">2.26.1.3 Stippling</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Progressive stippling" src="images/stipple.png"/></div></div></div><div class="st300_subsection_container"><a id="di.stippling.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s26ss2" href="#st300_p2s26ss2" title="Subsection 2.26.2: Algorithm">2.26.2</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s26ss2c1" href="#st300_p2s26ss2c1" title="Paragraph 2.26.2.1">1</a></div><div class="st300_paragraph">The stippling algorithm is very simple:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s26ss2c2" href="#st300_p2s26ss2c2" title="Formal item 2.26.2.2: Algorithm">2.26.2.2 Algorithm</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Tile a pattern texture <span class="st300_term variable">t</span> over the entire screen.</li><li class="st300_list_item">For each pixel with screen coordinates <span class="st300_term variable">p</span> in the object currently being rendered, sample a value <span class="st300_term variable">x</span> from <span class="st300_term variable">t</span> at <span class="st300_term variable">p</span>.</li><li class="st300_list_item">If <span class="st300_term variable">x</span> is less than the defined stippling threshold <span class="st300_term variable">s</span>, discard the pixel.</li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s26ss2c3" href="#st300_p2s26ss2c3" title="Paragraph 2.26.2.3">3</a></div><div class="st300_paragraph">In practice, for good visual results when fading between two objects, the programmer should use two complementary stippling patterns for the objects. For example, using a checkerboard stippling pattern for the first object and an inverted copy of the pattern for the other. This guarantees that at no point are the same pixels from both objects discarded.</div></div></div><div class="st300_subsection_container"><a id="di.stippling.types"/><div class="st300_subsection_title_number"><a id="st300_p2s26ss3" href="#st300_p2s26ss3" title="Subsection 2.26.3: Types">2.26.3</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s26ss3c1" href="#st300_p2s26ss3c1" title="Paragraph 2.26.3.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the stippling effect is provided by shaders such as <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/provided/R2SurfaceShaderBasicStippledSingle.html">R2SurfaceShaderBasicStippledSingle</a>.</div></div></div></div><div class="st300_section_container"><a id="di.generic-refraction"/><div class="st300_section_title_number"><a id="st300_p2s27" href="#st300_p2s27" title="Section 2.27: Generic Refraction">2.27</a></div><div class="st300_section_title">Generic Refraction</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss1" title="Link to subsection 2.27.1: Overview">2.27.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss2" title="Link to subsection 2.27.2: Algorithm">2.27.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss3" title="Link to subsection 2.27.3: Sources">2.27.3. Sources</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss4" title="Link to subsection 2.27.4: Vectors">2.27.4. Vectors</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss5" title="Link to subsection 2.27.5: Colors">2.27.5. Colors</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss6" title="Link to subsection 2.27.6: Masking">2.27.6. Masking</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s27ss7" title="Link to subsection 2.27.7: Types">2.27.7. Types</a></li></ul><div class="st300_subsection_container"><a id="di.generic-refraction.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss1" href="#st300_p2s27ss1" title="Subsection 2.27.1: Overview">2.27.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss1c1" href="#st300_p2s27ss1c1" title="Paragraph 2.27.1.1">1</a></div><div class="st300_paragraph">The <span class="st300_term package">r2</span> package implements the generic refraction effect described in <a class="st300_link_external" href="http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter19.html">GPU Gems 2</a>. The technique lends itself to a huge range of effects such as lenses, glass, heat haze, and water - simply by varying the meshes and textures used when performing refraction.</div></div></div><div class="st300_subsection_container"><a id="di.generic-refraction.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss2" href="#st300_p2s27ss2" title="Subsection 2.27.2: Algorithm">2.27.2</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss2c1" href="#st300_p2s27ss2c1" title="Paragraph 2.27.2.1">1</a></div><div class="st300_paragraph">For a given instance, the process to render the instance is as follows:</div></div><div class="st300_formal_item"><a id="di.generic-refraction.algorithm.formal"/><div class="st300_formal_item_title"><a id="st300_p2s27ss2c2" href="#st300_p2s27ss2c2" title="Formal item 2.27.2.2: Algorithm">2.27.2.2 Algorithm</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Produce a <a class="st300_link" href="#di.generic-refraction.masking">mask</a>, if necessary.</li><li class="st300_list_item">Render the instance using a given <a class="st300_link" href="#di.generic-refraction.source">source image</a>, <a class="st300_link" href="#di.generic-refraction.vectors">vector texture</a>, <a class="st300_link" href="#di.generic-refraction.color">color</a>, and <a class="st300_link" href="#di.generic-refraction.masking">mask image</a>.</li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss2c3" href="#st300_p2s27ss2c3" title="Paragraph 2.27.2.3">3</a></div><div class="st300_paragraph">The actual rendering technique is very simple: Given a screen-space position <span class="st300_term expression">(x, y)</span>, sample the color from a <a class="st300_link" href="#di.generic-refraction.source">source</a> image at <span class="st300_term expression">(x + s, y + t)</span>, where <span class="st300_term expression">(s, t)</span> are signed per-pixel offset values that are sampled from textures or derived from an associated <a class="st300_link" href="#di.generic-refraction.vectors">vector</a> texture.</div></div></div><div class="st300_subsection_container"><a id="di.generic-refraction.source"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss3" href="#st300_p2s27ss3" title="Subsection 2.27.3: Sources">2.27.3</a></div><div class="st300_subsection_title">Sources</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss3c1" href="#st300_p2s27ss3c1" title="Paragraph 2.27.3.1">1</a></div><div class="st300_paragraph">The refraction effect typically uses a (possibly downsized) image of the scene as a source image. The <span class="st300_term package">r2</span> allows for use of an arbitrary image.</div></div></div><div class="st300_subsection_container"><a id="di.generic-refraction.vectors"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss4" href="#st300_p2s27ss4" title="Subsection 2.27.4: Vectors">2.27.4</a></div><div class="st300_subsection_title">Vectors</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss4c1" href="#st300_p2s27ss4c1" title="Paragraph 2.27.4.1">1</a></div><div class="st300_paragraph">Refraction vectors are sampled from the red and green components of a delta texture. The sampled values are scaled by the material's scale factor and used directly to calculate <span class="st300_term expression">(x + s, y + t)</span>. For example, a simple noisy red/green delta texture applied to a quad results in the following effect:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss4c2" href="#st300_p2s27ss4c2" title="Formal item 2.27.4.2: Noise quad">2.27.4.2 Noise quad</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Noise quad" src="images/refract_noise_quad.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss4c3" href="#st300_p2s27ss4c3" title="Formal item 2.27.4.3: Noise quad (texture)">2.27.4.3 Noise quad (texture)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Noise quad texture" src="images/refract_noise_quad_texture.png"/></div></div></div><div class="st300_subsection_container"><a id="di.generic-refraction.color"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss5" href="#st300_p2s27ss5" title="Subsection 2.27.5: Colors">2.27.5</a></div><div class="st300_subsection_title">Colors</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss5c1" href="#st300_p2s27ss5c1" title="Paragraph 2.27.5.1">1</a></div><div class="st300_paragraph">The sampled scene colors used to perform the refraction effect are multiplied by a constant color, specified by each material. This allows for simple colored glass effects (shown here with a specular-only instance rendered over the top of the refractive instance to provide specular highlights):</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss5c2" href="#st300_p2s27ss5c2" title="Formal item 2.27.5.2: Color 0">2.27.5.2 Color 0</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Color 0" src="images/refract_color_0.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss5c3" href="#st300_p2s27ss5c3" title="Paragraph 2.27.5.3">3</a></div><div class="st300_paragraph">Using pure RGBA white <span class="st300_term expression">(1.0, 1.0, 1.0, 1.0)</span> results in a clear glass material:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss5c4" href="#st300_p2s27ss5c4" title="Formal item 2.27.5.4: Color 1">2.27.5.4 Color 1</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Color 1" src="images/refract_color_1.png"/></div></div></div><div class="st300_subsection_container"><a id="di.generic-refraction.masking"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss6" href="#st300_p2s27ss6" title="Subsection 2.27.6: Masking">2.27.6</a></div><div class="st300_subsection_title">Masking</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss6c1" href="#st300_p2s27ss6c1" title="Paragraph 2.27.6.1">1</a></div><div class="st300_paragraph">Because refractive instances are translucent, they are normally rendered after having already rendered all of the opaque objects in the scene. Because rendering of translucent instances occurs with depth testing enabled, it is therefore possible for opaque instances to occlude refractive instances. This poses a problem for the implementation of refraction described above, because the pixels of an occluding object may be sampled when performing the refraction, as shown in the following image:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss6c2" href="#st300_p2s27ss6c2" title="Formal item 2.27.6.2: Refraction bleeding">2.27.6.2 Refraction bleeding</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Refraction bleeding" src="images/refract_bleed.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss6c3" href="#st300_p2s27ss6c3" title="Paragraph 2.27.6.3">3</a></div><div class="st300_paragraph">Note how the pixels of the opaque instances are bleeding into the refracting object, despite being conceptually in front of it. This is because the refraction effect is implemented in screen space and is just sampling pixels from the surrounding area to simulate the bending of light rays. Using a <span class="st300_term term">mask</span> prevents this:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss6c4" href="#st300_p2s27ss6c4" title="Formal item 2.27.6.4: Refraction without bleeding">2.27.6.4 Refraction without bleeding</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Refraction without bleeding" src="images/refract_nobleed.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss6c5" href="#st300_p2s27ss6c5" title="Paragraph 2.27.6.5">5</a></div><div class="st300_paragraph">A mask is produced by rendering a monochrome silhouette of the refracting object, and then using the values of this mask to linearly interpolate between the colors <span class="st300_term expression">c</span> at <span class="st300_term expression">(x, y)</span> and the colors <span class="st300_term expression">r</span> at <span class="st300_term expression">(x + s, y + t)</span>. That is, a value of <span class="st300_term expression">m = 0</span> sampled from the mask yields <span class="st300_term expression">mix c r m = mix c r 0 = c</span>, and a value of <span class="st300_term expression">m = 1</span> sampled from the mask yields <span class="st300_term expression">mix c r m = mix c r 1 = r</span>. This has the effect of preventing the refraction simulation from using pixels that fall outside of the mask area.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s27ss6c6" href="#st300_p2s27ss6c6" title="Formal item 2.27.6.6: Mask">2.27.6.6 Mask</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Mask" src="images/refract_mask.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss6c7" href="#st300_p2s27ss6c7" title="Paragraph 2.27.6.7">7</a></div><div class="st300_paragraph">The mask image can also be softened with a simple box blur to reduce artifacts in the refracted image.</div></div></div><div class="st300_subsection_container"><a id="di.generic-refraction.types"/><div class="st300_subsection_title_number"><a id="st300_p2s27ss7" href="#st300_p2s27ss7" title="Subsection 2.27.7: Types">2.27.7</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss7c1" href="#st300_p2s27ss7c1" title="Paragraph 2.27.7.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the refraction effect is provided by rendering a translucent instance with a refraction shader such as <a class="st300_link_external" href="apidocs/com/io7m/r2/core/shaders/provided/R2RefractionMaskedDeltaShaderSingle.html">R2RefractionMaskedDeltaShaderSingle</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s27ss7c2" href="#st300_p2s27ss7c2" title="Paragraph 2.27.7.2">2</a></div><div class="st300_paragraph">Masks can be produced via implementations of the <a class="st300_link_external" href="apidocs/com/io7m/r2/core/R2MaskRendererType.html">R2MaskRendererType</a> interface.</div></div></div></div><div class="st300_section_container"><a id="di.fog"/><div class="st300_section_title_number"><a id="st300_p2s28" href="#st300_p2s28" title="Section 2.28: Filter: Fog">2.28</a></div><div class="st300_section_title">Filter: Fog</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s28ss1" title="Link to subsection 2.28.1: Overview">2.28.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s28ss2" title="Link to subsection 2.28.2: Algorithm">2.28.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s28ss3" title="Link to subsection 2.28.3: Types">2.28.3. Types</a></li></ul><div class="st300_subsection_container"><a id="di.fog.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s28ss1" href="#st300_p2s28ss1" title="Subsection 2.28.1: Overview">2.28.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s28ss1c1" href="#st300_p2s28ss1c1" title="Paragraph 2.28.1.1">1</a></div><div class="st300_paragraph">The fog effect is a simple effect that is intended to simulate atmospheric fog within a scene.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s28ss1c2" href="#st300_p2s28ss1c2" title="Formal item 2.28.1.2: Fog">2.28.1.2 Fog</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Fog" src="images/fog_linear.png"/></div></div></div><div class="st300_subsection_container"><a id="di.fog.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s28ss2" href="#st300_p2s28ss2" title="Subsection 2.28.2: Algorithm">2.28.2</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s28ss2c1" href="#st300_p2s28ss2c1" title="Paragraph 2.28.2.1">1</a></div><div class="st300_paragraph">The algorithm is trivial:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s28ss2c2" href="#st300_p2s28ss2c2" title="Formal item 2.28.2.2: Algorithm">2.28.2.2 Algorithm</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">For each pixel <span class="st300_term variable">p</span> at <span class="st300_term variable">(x, y)</span> <ol class="st300_list_ordered"><li class="st300_list_item">Sample the scene's depth <span class="st300_term variable">d</span> at <span class="st300_term variable">(x, y)</span></li><li class="st300_list_item">Determine the positive eye-space Z value <span class="st300_term variable">z</span> of <span class="st300_term variable">p</span></li><li class="st300_list_item">Mix between the global fog color <span class="st300_term variable">d</span> and <span class="st300_term variable">p</span> using a mix function <span class="st300_term variable">fog(z)</span></li></ol></li></ol></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s28ss2c3" href="#st300_p2s28ss2c3" title="Paragraph 2.28.2.3">3</a></div><div class="st300_paragraph">The mix function <span class="st300_term variable">fog(z)</span> is selectable. The <span class="st300_term package">r2</span> package provides <span class="st300_term term">linear</span>, <span class="st300_term term">quadratic</span>, and <span class="st300_term term">inverse quadratic</span> fog. The definitions of the available mix functions are as follows:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s28ss2c4" href="#st300_p2s28ss2c4" title="Formal item 2.28.2.4: Fog functions">2.28.2.4 Fog functions</a></div><div class="st300_formal_item_content"><pre class="st300_verbatim">module FogFactorZ where

clamp :: Float -&gt; (Float, Float) -&gt; Float
clamp x (lower, upper) = max (min x upper) lower

fogLinear :: Float -&gt; (Float, Float) -&gt; Float
fogLinear z (near, far) =
  let r = (z - near) / (far - near) in
    clamp r (0.0, 1.0)

fogQuadratic :: Float -&gt; (Float, Float) -&gt; Float
fogQuadratic z (near, far) =
  let q = fogLinear z (near, far) in q * q

fogQuadraticInverse :: Float -&gt; (Float, Float) -&gt; Float
fogQuadraticInverse z (near, far) =
  let q = fogLinear z (near, far) in sqrt(q)
</pre></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s28ss2c5" href="#st300_p2s28ss2c5" title="Formal item 2.28.2.5: Linear Fog">2.28.2.5 Linear Fog</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Linear Fog" src="images/fog_linear.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s28ss2c6" href="#st300_p2s28ss2c6" title="Formal item 2.28.2.6: Quadratic Fog">2.28.2.6 Quadratic Fog</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Quadratic Fog" src="images/fog_quadratic.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s28ss2c7" href="#st300_p2s28ss2c7" title="Formal item 2.28.2.7: Inverse Quadratic Fog">2.28.2.7 Inverse Quadratic Fog</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Inverse Quadratic Fog" src="images/fog_quadratic_inverse.png"/></div></div></div><div class="st300_subsection_container"><a id="di.fog.types"/><div class="st300_subsection_title_number"><a id="st300_p2s28ss3" href="#st300_p2s28ss3" title="Subsection 2.28.3: Types">2.28.3</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s28ss3c1" href="#st300_p2s28ss3c1" title="Paragraph 2.28.3.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the fog effect is provided by the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2FilterFogDepth.html">R2FilterFogDepth</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.ssao"/><div class="st300_section_title_number"><a id="st300_p2s29" href="#st300_p2s29" title="Section 2.29: Filter: Screen Space Ambient Occlusion">2.29</a></div><div class="st300_section_title">Filter: Screen Space Ambient Occlusion</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss1" title="Link to subsection 2.29.1: Overview">2.29.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss2" title="Link to subsection 2.29.2: Ambient Occlusion Buffer">2.29.2. Ambient Occlusion Buffer</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss3" title="Link to subsection 2.29.3: Algorithm">2.29.3. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss4" title="Link to subsection 2.29.4: Noise Texture">2.29.4. Noise Texture</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss5" title="Link to subsection 2.29.5: Sample Kernel">2.29.5. Sample Kernel</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss6" title="Link to subsection 2.29.6: Halo Removal">2.29.6. Halo Removal</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss7" title="Link to subsection 2.29.7: Performance">2.29.7. Performance</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss8" title="Link to subsection 2.29.8: Types">2.29.8. Types</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s29ss9" title="Link to subsection 2.29.9: Shaders">2.29.9. Shaders</a></li></ul><div class="st300_subsection_container"><a id="di.ssao.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss1" href="#st300_p2s29ss1" title="Subsection 2.29.1: Overview">2.29.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss1c1" href="#st300_p2s29ss1c1" title="Paragraph 2.29.1.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Screen space ambient occlusion</span> is, unsurprisingly, an approximate algorithm for calculating <span class="st300_term term">ambient occlusion</span> in <a class="st300_link" href="#di.coords.screen">screen space</a>. Informally, ambient occlusion is a measure of how exposed a given point is to the environment's ambient light. The <span class="st300_term package">r2</span> package does not directly support ambient lighting, so instead the <a class="st300_link" href="#di.lighting.diffuse">diffuse</a> light term is typically modulated by an ambient occlusion term <span class="st300_footnote_reference">[<a href="#st300_f_22888_0" id="st300_fr_21699" title="Jump to footnote di.ssao.application (reference 0)">27</a>]</span> to produce the same overall effect.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s29ss1c2" href="#st300_p2s29ss1c2" title="Formal item 2.29.1.2: SSAO">2.29.1.2 SSAO</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="SSAO" src="images/ssao.png"/></div></div></div><div class="st300_subsection_container"><a id="di.ssao.abuffer"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss2" href="#st300_p2s29ss2" title="Subsection 2.29.2: Ambient Occlusion Buffer">2.29.2</a></div><div class="st300_subsection_title">Ambient Occlusion Buffer</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss2c1" href="#st300_p2s29ss2c1" title="Paragraph 2.29.2.1">1</a></div><div class="st300_paragraph">An <span class="st300_term term">ambient occlusion buffer</span> is a <a class="st300_link" href="#di.render-target">render target</a> in which an occlusion term is stored. In the <span class="st300_term package">r2</span> package, ambient occlusion buffers are simple single-channel 8-bit images, where <span class="st300_term constant">0</span> means <span class="st300_term term">fully occluded</span> and <span class="st300_term constant">1</span> means <span class="st300_term term">not occluded</span>.</div></div></div><div class="st300_subsection_container"><a id="di.ssao.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss3" href="#st300_p2s29ss3" title="Subsection 2.29.3: Algorithm">2.29.3</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss3c1" href="#st300_p2s29ss3c1" title="Paragraph 2.29.3.1">1</a></div><div class="st300_paragraph">The algorithm works by consuming the depth and normal values from populated <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a>. For the sake of simplicity, the algorithm will be described as if the <a class="st300_link" href="#di.ssao.abuffer">ambient occlusion buffer</a> that will contain the calculated occlusion terms will be the same size as the geometry buffer. This is not necessarily the case in practice, for performance reasons. For each pixel at <span class="st300_term expression">(x, y)</span> in the geometry buffer, the <a class="st300_link" href="#di.coords.eye">eye space Z</a> value <span class="st300_term expression">z</span> is <a class="st300_link" href="#di.deferred-position-recon.eye-space-z">reconstructed</a> for the pixel, and the eye space normal vector <span class="st300_term expression">n</span> is sampled at the same location.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss3c2" href="#st300_p2s29ss3c2" title="Paragraph 2.29.3.2">2</a></div><div class="st300_paragraph">Then, a <span class="st300_term term">sampling hemisphere</span> is placed on the surface at <span class="st300_term expression">z</span>, oriented along <span class="st300_term expression">n</span>. A list of points, known as the <a class="st300_link" href="#di.ssao.kernel">sample kernel</a>, are used to sample from random positions that fall inside the hemisphere. If a sample point appears to be inside the scene geometry, then the scene geometry is <span class="st300_term term">occluding</span> that point.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s29ss3c3" href="#st300_p2s29ss3c3" title="Formal item 2.29.3.3: Sampling Hemispheres">2.29.3.3 Sampling Hemispheres</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Sampling hemispheres" src="images/ssao_hemi.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss3c4" href="#st300_p2s29ss3c4" title="Paragraph 2.29.3.4">4</a></div><div class="st300_paragraph">Informally, the algorithm for a point at <span class="st300_term expression">(x, y)</span>:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s29ss3c5" href="#st300_p2s29ss3c5" title="Formal item 2.29.3.5: Algorithm">2.29.3.5 Algorithm</a></div><div class="st300_formal_item_content"><ol class="st300_list_ordered"><li class="st300_list_item">Reconstruct the eye space position <span class="st300_term expression">e</span> of the screen space position <span class="st300_term expression">(x, y)</span>.</li><li class="st300_list_item">Sample the normal vector <span class="st300_term expression">n</span> at <span class="st300_term expression">(x, y)</span>.</li><li class="st300_list_item">Peturb the normal vector <span class="st300_term expression">n</span> using values sampled from a random <a class="st300_link" href="#di.ssao.noise_texture">noise texture</a> that is tiled across the screen.</li><li class="st300_list_item">Produce a <a class="st300_link" href="#di.coords.eye.normal-matrix">normal matrix</a> from <span class="st300_term expression">n</span> that will transform the inherently <a class="st300_link" href="#di.normal-mapping.tangent-space">tangent space</a> sampling kernel vector to eye space. The peturbed normal vector has the effect of rotating the sampling hemisphere.</li><li class="st300_list_item">For a sampling kernel <span class="st300_term expression">k</span> of <span class="st300_term expression">m</span> points, of radius <span class="st300_term expression">r</span>, for each <span class="st300_term expression">i | 0 &lt;= i &lt; m</span>: <ol class="st300_list_ordered"><li class="st300_list_item">Calculate the eye space position <span class="st300_term expression">q</span> of the sampling point <span class="st300_term expression">k[i]</span>. This is calculated as <span class="st300_term expression">q = e + (k[i] * r)</span>.</li><li class="st300_list_item">Project <span class="st300_term expression">q</span> to screen space, use it to sample the depth buffer, and reconstruct the resulting eye space Z value <span class="st300_term expression">sz</span>. The value <span class="st300_term expression">sz</span> then represents the eye space Z value of the closest position of the surface in the geometry buffer to <span class="st300_term expression">q</span>.</li><li class="st300_list_item">If <span class="st300_term expression">abs (e.z - sz) &gt; r</span> then the point is automatically assumed not to be occluded. See <a class="st300_link" href="#di.ssao.halo_removal">halo removal</a> for details.</li><li class="st300_list_item">If <span class="st300_term expression">sz &gt;= e.z</span>, then it means that the sampling point in the hemisphere has ended up underneath the rendered surface and is therefore being occluded by it.</li></ol></li><li class="st300_list_item">Calculate the final occlusion value <span class="st300_term expression">o</span> by summing the occlusion values of each sample point, where <span class="st300_term constant">1.0</span> means the point was occluded, and <span class="st300_term constant">0.0</span> means that it was not. Return <span class="st300_term expression">1.0 - (o / m)</span>.</li></ol></div></div></div><div class="st300_subsection_container"><a id="di.ssao.noise_texture"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss4" href="#st300_p2s29ss4" title="Subsection 2.29.4: Noise Texture">2.29.4</a></div><div class="st300_subsection_title">Noise Texture</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss4c1" href="#st300_p2s29ss4c1" title="Paragraph 2.29.4.1">1</a></div><div class="st300_paragraph">The <span class="st300_term term">noise texture</span> used by the algorithm is a simple RGB texture with each texel being given by the expression <span class="st300_term expression">normalize ((random() * 2.0) - 1.0, (random() * 2.0) - 1.0, 0.0)</span>. The <a class="st300_link" href="#di.ssao.kernel">sampling kernel</a> used by the algorithm is conceptually oriented along the <a class="st300_link" href="#di.normal-mapping.tangent-space">tangent space</a>  Z axis, and therefore each texel in the noise texture effectively represents a rotation around the Z axis.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss4c2" href="#st300_p2s29ss4c2" title="Paragraph 2.29.4.2">2</a></div><div class="st300_paragraph">In the implementation of the algorithm, the texture is simply tiled across the screen and sampled using the current screen space coordinates.</div></div></div><div class="st300_subsection_container"><a id="di.ssao.kernel"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss5" href="#st300_p2s29ss5" title="Subsection 2.29.5: Sample Kernel">2.29.5</a></div><div class="st300_subsection_title">Sample Kernel</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss5c1" href="#st300_p2s29ss5c1" title="Paragraph 2.29.5.1">1</a></div><div class="st300_paragraph">A <span class="st300_term term">sample kernel</span> is a fixed-size list of random sampling points, arranged in a hemispherical pattern. For better visual results, the random points are not evenly distributed within the hemisphere but are instead clustered more densely nearer the origin.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s29ss5c2" href="#st300_p2s29ss5c2" title="Formal item 2.29.5.2: Point Distribution">2.29.5.2 Point Distribution</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Distribution of sampling points" src="images/ssao_hemi_points.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss5c3" href="#st300_p2s29ss5c3" title="Paragraph 2.29.5.3">3</a></div><div class="st300_paragraph">By using a distribution of sample points nearer the origin, samples closer to the origin have the effect of occluding more than points that are further away.</div></div></div><div class="st300_subsection_container"><a id="di.ssao.halo_removal"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss6" href="#st300_p2s29ss6" title="Subsection 2.29.6: Halo Removal">2.29.6</a></div><div class="st300_subsection_title">Halo Removal</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss6c1" href="#st300_p2s29ss6c1" title="Paragraph 2.29.6.1">1</a></div><div class="st300_paragraph">A common problem with SSAO implementations is <span class="st300_term term">haloing</span>. In practical terms, this is an issue caused by two objects being very close when considered in screen space, but that were actually far apart when considered in eye space.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s29ss6c2" href="#st300_p2s29ss6c2" title="Formal item 2.29.6.2: Halo Artifacts">2.29.6.2 Halo Artifacts</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Halo artifacts" src="images/ssao_halo.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss6c3" href="#st300_p2s29ss6c3" title="Paragraph 2.29.6.3">3</a></div><div class="st300_paragraph">The simple solution to this problem is to ignore any surface points that are at a distance greater than the sampling radius from the origin. In the actual implementation, a simple comparison of the eye-space Z values is used.</div></div></div><div class="st300_subsection_container"><a id="di.ssao.performance"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss7" href="#st300_p2s29ss7" title="Subsection 2.29.7: Performance">2.29.7</a></div><div class="st300_subsection_title">Performance</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss7c1" href="#st300_p2s29ss7c1" title="Paragraph 2.29.7.1">1</a></div><div class="st300_paragraph">The SSAO algorithm is extremely expensive; by far the most expensive algorithm implemented in the <span class="st300_term package">r2</span> package. The package provides numerous means to control the performance of the algorithm.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss7c2" href="#st300_p2s29ss7c2" title="Paragraph 2.29.7.2">2</a></div><div class="st300_paragraph">For a kernel of size <span class="st300_term expression">n</span>, an occlusion map of size <span class="st300_term expression">w * h</span> will incur at least <span class="st300_term expression">w * h * n</span> texture reads when sampling from the <a class="st300_link" href="#di.deferred.geom.gbuffer">geometry buffer</a> to calculate the occlusion term. Therefore, reducing the resolution of the <a class="st300_link" href="#di.ssao.abuffer">ambient occlusion buffer</a> is an effective way to improve the performance of the algorithm at a noticeable reduction in visual quality. The <span class="st300_term package">r2</span> package does not provide any specific support for this; the programmer simply needs to allocate a smaller ambient occlusion buffer. For the same reason, using a smaller kernel (a smaller value of <span class="st300_term expression">n</span>) will also improve performance but reduce visual quality.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss7c3" href="#st300_p2s29ss7c3" title="Paragraph 2.29.7.3">3</a></div><div class="st300_paragraph">To reduce high frequency noise introduced by the random sampling pattern used, a bilateral blur filter is often used. In the <span class="st300_term package">r2</span> package, the blur is separate from the SSAO effect and can therefore be omitted to improve performance at the cost of producing a noisier image:</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s29ss7c4" href="#st300_p2s29ss7c4" title="Formal item 2.29.7.4: SSAO (Without blur)">2.29.7.4 SSAO (Without blur)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="SSAO without blur" src="images/ssao_noise.png"/></div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss7c5" href="#st300_p2s29ss7c5" title="Paragraph 2.29.7.5">5</a></div><div class="st300_paragraph">The image displayed at the start of this section uses an ambient occlusion buffer that is exactly half the size of the screen, a kernel of size <span class="st300_term constant">64</span>, and a maximum sampling distance of <span class="st300_term constant">0.25</span> eye-space units. A single bilateral blur pass was used.</div></div></div><div class="st300_subsection_container"><a id="di.ssao.types"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss8" href="#st300_p2s29ss8" title="Subsection 2.29.8: Types">2.29.8</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss8c1" href="#st300_p2s29ss8c1" title="Paragraph 2.29.8.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the SSAO effect is provided by the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2FilterSSAO.html">R2FilterSSAO</a> type.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss8c2" href="#st300_p2s29ss8c2" title="Paragraph 2.29.8.2">2</a></div><div class="st300_paragraph">Occlusion maps can be conveniently applied to light maps with the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2FilterOcclusionApplicator.html">R2FilterOcclusionApplicator</a> filter.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss8c3" href="#st300_p2s29ss8c3" title="Paragraph 2.29.8.3">3</a></div><div class="st300_paragraph">The provided implementation of the sampling kernel is given by the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2SSAOKernel.html">R2SSAOKernel</a> type.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss8c4" href="#st300_p2s29ss8c4" title="Paragraph 2.29.8.4">4</a></div><div class="st300_paragraph">The provided implementation of the noise texture is given by the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2SSAONoiseTexture.html">R2SSAONoiseTexture</a> type.</div></div></div><div class="st300_subsection_container"><a id="di.ssao.shaders"/><div class="st300_subsection_title_number"><a id="st300_p2s29ss9" href="#st300_p2s29ss9" title="Subsection 2.29.9: Shaders">2.29.9</a></div><div class="st300_subsection_title">Shaders</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s29ss9c1" href="#st300_p2s29ss9c1" title="Paragraph 2.29.9.1">1</a></div><div class="st300_paragraph">The shader implementation of the SSAO algorithm is the <a class="st300_link_external" href="doxygen/io7m-r2-shaders-0.2.0/R2SSAO_8frag_source.html">R2SSAO</a> shader.</div></div></div></div><div class="st300_section_container"><a id="di.emission"/><div class="st300_section_title_number"><a id="st300_p2s30" href="#st300_p2s30" title="Section 2.30: Filter: Emission">2.30</a></div><div class="st300_section_title">Filter: Emission</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s30ss1" title="Link to subsection 2.30.1: Overview">2.30.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s30ss2" title="Link to subsection 2.30.2: Algorithm">2.30.2. Algorithm</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s30ss3" title="Link to subsection 2.30.3: Types">2.30.3. Types</a></li></ul><div class="st300_subsection_container"><a id="di.emission.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s30ss1" href="#st300_p2s30ss1" title="Subsection 2.30.1: Overview">2.30.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s30ss1c1" href="#st300_p2s30ss1c1" title="Paragraph 2.30.1.1">1</a></div><div class="st300_paragraph">An <span class="st300_term term">emissive</span> surface is a surface that appears to emit light. The <span class="st300_term package">r2</span> package offers emission as a visual effect implemented as a filter. An optional <span class="st300_term term">glow</span> effect is provided to allow emissive surfaces to appear to have a configurable <a class="st300_link_external" href="http://en.wikipedia.org/wiki/Halo_%28optical_phenomenon%29">aura</a>.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s30ss1c2" href="#st300_p2s30ss1c2" title="Paragraph 2.30.1.2">2</a></div><div class="st300_paragraph">The emission effect is obviously not physically accurate - surfaces do not really emit light. The user is expected to make intelligent use of the standard <a class="st300_link" href="#di.deferred.light">light sources</a> to provide lighting, and to use the emission effect to complement them.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s30ss1c3" href="#st300_p2s30ss1c3" title="Formal item 2.30.1.3: Emission">2.30.1.3 Emission</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Emission" src="images/emission.png"/></div></div></div><div class="st300_subsection_container"><a id="di.emission.algorithm"/><div class="st300_subsection_title_number"><a id="st300_p2s30ss2" href="#st300_p2s30ss2" title="Subsection 2.30.2: Algorithm">2.30.2</a></div><div class="st300_subsection_title">Algorithm</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s30ss2c1" href="#st300_p2s30ss2c1" title="Paragraph 2.30.2.1">1</a></div><div class="st300_paragraph">The plain emission effect without <span class="st300_term term">glow</span> is implemented as trivially as possible by sampling the <a class="st300_link" href="#di.deferred.geom.gbuffer">emission</a> value from a rendered scene's <span class="st300_term term">geometry buffer</span>, multiplying it by the <span class="st300_term term">albedo</span> color and then simply adding the result to the current pixel color.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s30ss2c2" href="#st300_p2s30ss2c2" title="Paragraph 2.30.2.2">2</a></div><div class="st300_paragraph">The emission effect with <span class="st300_term term">glow</span> is implemented similarly, except that the <span class="st300_term expression">albedo * emission</span> term is stored in a separate image, and that image is blurred with a configurable <span class="st300_term term">box blur</span> before being additively blended over the original scene. Higher levels of blurring can give the impression of a dusty atmosphere.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s30ss2c3" href="#st300_p2s30ss2c3" title="Formal item 2.30.2.3: Emission (Glow)">2.30.2.3 Emission (Glow)</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Emission (Glow)" src="images/emission_glow.png"/></div></div></div><div class="st300_subsection_container"><a id="di.emission.types"/><div class="st300_subsection_title_number"><a id="st300_p2s30ss3" href="#st300_p2s30ss3" title="Subsection 2.30.3: Types">2.30.3</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s30ss3c1" href="#st300_p2s30ss3c1" title="Paragraph 2.30.3.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the emission effect is provided by the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2FilterEmission.html">R2FilterEmission</a> type.</div></div></div></div><div class="st300_section_container"><a id="di.fxaa"/><div class="st300_section_title_number"><a id="st300_p2s31" href="#st300_p2s31" title="Section 2.31: Filter: FXAA">2.31</a></div><div class="st300_section_title">Filter: FXAA</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s31ss1" title="Link to subsection 2.31.1: Overview">2.31.1. Overview</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s31ss2" title="Link to subsection 2.31.2: Implementation">2.31.2. Implementation</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p2s31ss3" title="Link to subsection 2.31.3: Types">2.31.3. Types</a></li></ul><div class="st300_subsection_container"><a id="di.fxaa.overview"/><div class="st300_subsection_title_number"><a id="st300_p2s31ss1" href="#st300_p2s31ss1" title="Subsection 2.31.1: Overview">2.31.1</a></div><div class="st300_subsection_title">Overview</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s31ss1c1" href="#st300_p2s31ss1c1" title="Paragraph 2.31.1.1">1</a></div><div class="st300_paragraph"><span class="st300_term term">Fast Approximate Anti-Aliasing</span> is a simple algorithm that attempts to detect and smooth <span class="st300_term term">aliasing</span> in a color image. The algorithm works with only the color components of the image in question; no other per-pixel information or knowledge of the scene is required.</div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s31ss1c2" href="#st300_p2s31ss1c2" title="Formal item 2.31.1.2: Without FXAA">2.31.1.2 Without FXAA</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="Without FXAA" src="images/fxaa_without.png"/></div></div><div class="st300_formal_item"><div class="st300_formal_item_title"><a id="st300_p2s31ss1c3" href="#st300_p2s31ss1c3" title="Formal item 2.31.1.3: With FXAA">2.31.1.3 With FXAA</a></div><div class="st300_formal_item_content"><img class="st300_image" alt="With FXAA" src="images/fxaa_with.png"/></div></div></div><div class="st300_subsection_container"><a id="di.fxaa.implementation"/><div class="st300_subsection_title_number"><a id="st300_p2s31ss2" href="#st300_p2s31ss2" title="Subsection 2.31.2: Implementation">2.31.2</a></div><div class="st300_subsection_title">Implementation</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s31ss2c1" href="#st300_p2s31ss2c1" title="Paragraph 2.31.2.1">1</a></div><div class="st300_paragraph">Unfortunately, information on the FXAA algorithm is sparse, and much of it has been lost to time. The original FXAA algorithm was published in a whitepaper by NVIDIA <span class="st300_footnote_reference">[<a href="#st300_f_23404_0" id="st300_fr_23263" title="Jump to footnote di.fxaa.whitepaper (reference 0)">28</a>]</span> and was severely optimized by the author on the suggestions of many mostly anonymous contributors. The latest published version of the algorithm (version 3.11) bears little resemblance to the original and no documentation exists on the changes. The 3.11 version of the algorithm is constructed from a maze of C preprocessor macros, and many different variations of the algorithm are possible based on how the parameter macros are defined.</div></div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s31ss2c2" href="#st300_p2s31ss2c2" title="Paragraph 2.31.2.2">2</a></div><div class="st300_paragraph">The implementation of FXAA in the <span class="st300_term package">r2</span> package is a set of GLSL expansions of the public domain <span class="st300_footnote_reference">[<a href="#st300_f_23409_0" id="st300_fr_23355" title="Jump to footnote di.fxaa.publicdomain (reference 0)">29</a>]</span> <span class="st300_term file">Fxaa3_11.h</span> header with a few minor modifications (unused parameter removals). Specifically, the <span class="st300_term term">PC</span> algorithm is used, with quality presets <span class="st300_term expression">(10, 15, 20, 25, 29, 39)</span>.</div></div></div><div class="st300_subsection_container"><a id="di.fxaa.types"/><div class="st300_subsection_title_number"><a id="st300_p2s31ss3" href="#st300_p2s31ss3" title="Subsection 2.31.3: Types">2.31.3</a></div><div class="st300_subsection_title">Types</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p2s31ss3c1" href="#st300_p2s31ss3c1" title="Paragraph 2.31.3.1">1</a></div><div class="st300_paragraph">In the <span class="st300_term package">r2</span> package, the FXAA effect is provided by the <a class="st300_link_external" href="apidocs/com/io7m/r2/filters/R2FilterFXAA.html">R2FilterFXAA</a> type.</div></div></div></div></div><div class="st300_part_container"><div class="st300_part_title_number"><a id="st300_p3" href="#st300_p3" title="Part 3: API Documentation">3</a></div><div class="st300_part_title">API Documentation</div><ul class="st300_contents st300_part_contents_outer st300_part_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_section"><a href="#st300_p3s1" title="Link to section 3.1: API Documentation">3.1. API Documentation</a><ul class="st300_contents st300_section_contents"><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p3s1ss1" title="Link to subsection 3.1.1: Javadoc">3.1.1. Javadoc</a></li><li class="st300_contents_item st300_contents_item2 st300_contents_item_subsection"><a href="#st300_p3s1ss2" title="Link to subsection 3.1.2: GLSL Doxygen">3.1.2. GLSL Doxygen</a></li></ul></li></ul><div class="st300_section_container"><a id="api"/><div class="st300_section_title_number"><a id="st300_p3s1" href="#st300_p3s1" title="Section 3.1: API Documentation">3.1</a></div><div class="st300_section_title">API Documentation</div><ul class="st300_contents st300_section_contents_outer st300_section_contents"><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p3s1ss1" title="Link to subsection 3.1.1: Javadoc">3.1.1. Javadoc</a></li><li class="st300_contents_item st300_contents_item1 st300_contents_item_subsection"><a href="#st300_p3s1ss2" title="Link to subsection 3.1.2: GLSL Doxygen">3.1.2. GLSL Doxygen</a></li></ul><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p3s1ss1" href="#st300_p3s1ss1" title="Subsection 3.1.1: Javadoc">3.1.1</a></div><div class="st300_subsection_title">Javadoc</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p3s1ss1c1" href="#st300_p3s1ss1c1" title="Paragraph 3.1.1.1">1</a></div><div class="st300_paragraph">API documentation for the package is provided via the included <a class="st300_link_external" href="apidocs">Javadoc</a>.</div></div></div><div class="st300_subsection_container"><div class="st300_subsection_title_number"><a id="st300_p3s1ss2" href="#st300_p3s1ss2" title="Subsection 3.1.2: GLSL Doxygen">3.1.2</a></div><div class="st300_subsection_title">GLSL Doxygen</div><div class="st300_paragraph_container"><div class="st300_paragraph_number"><a id="st300_p3s1ss2c1" href="#st300_p3s1ss2c1" title="Paragraph 3.1.2.1">1</a></div><div class="st300_paragraph">API documentation for the GLSL sources are provided via the included <a class="st300_link_external" href="doxygen/io7m-r2-shaders-core-0.2.0">Doxygen</a>.</div></div></div></div></div><div class="st300_footnotes"><hr/><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_906_0" href="#st300_fr_864" title="Jump back to reference 0 of footnote semver">0</a>]</div><div class="st300_footnote_body"><a class="st300_link_external" href="http://semver.org">http://semver.org</a></div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_2495_0" href="#st300_fr_2493" title="Jump back to reference 0 of footnote di.concepts.material.r1_material">1</a>]</div><div class="st300_footnote_body">The spiritual ancestor of <span class="st300_term package">r2</span>, the <a class="st300_link_external" href="http://io7m.github.io/r1">r1</a> renderer, exposed only immutable materials. While these made it easier to demonstrate the correctness of the programs using the renderer, it also increased pressure on the garbage collector. Materials in the <span class="st300_term package">r2</span> may optionally be mutable or immutable, and the user is expected understand the difference and the consequences of using one over the other.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_2566_0" href="#st300_fr_2318" title="Jump back to reference 0 of footnote di.concepts.shader.r1_material">2</a>]</div><div class="st300_footnote_body">The spiritual ancestor of <span class="st300_term package">r2</span>, the <a class="st300_link_external" href="http://io7m.github.io/r1">r1</a> renderer, exposed a fixed material system and did not expose shaders to the user at all. While this made it easier to demonstrate the correctness of the renderer implementation, it turned out to be needlessly inflexible and made it more difficult to experiment with new renderer features.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_2627_0" href="#st300_fr_2091" title="Jump back to reference 0 of footnote di.concepts.shadow_expensive">3</a>]</div><div class="st300_footnote_body">However, the <span class="st300_term package">r2</span> package places no limits on the number of lights that have shadow maps, so enabling them for all light sources is possible, if not actually advisable.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_2627_1" href="#st300_fr_13636" title="Jump back to reference 1 of footnote di.concepts.shadow_expensive">3</a>]</div><div class="st300_footnote_body">However, the <span class="st300_term package">r2</span> package places no limits on the number of lights that have shadow maps, so enabling them for all light sources is possible, if not actually advisable.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4074_0" href="#st300_fr_4027" title="Jump back to reference 0 of footnote di.coords.eye.math3dgame">4</a>]</div><div class="st300_footnote_body">See section 4.5, Transforming normal vectors .</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4081_0" href="#st300_fr_3808" title="Jump back to reference 0 of footnote di.coords.eye.anticommut">5</a>]</div><div class="st300_footnote_body">Note that matrix multiplication is not commutative.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4090_0" href="#st300_fr_3830" title="Jump back to reference 0 of footnote di.coords.eye.efficient">6</a>]</div><div class="st300_footnote_body">The reason for producing the concatenated matrix on the CPU and then passing it to the shader is efficiency; if a mesh had 1000 vertices, and the shader was passed m and v separately, the shader would repeatedly perform the same <span class="st300_term expression">mv = v * m</span> multiplication to produce mv for each vertex - yielding the exact same <span class="st300_term expression">mv</span> each time!</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4502_0" href="#st300_fr_4207" title="Jump back to reference 0 of footnote di.coords.clip.invert">7</a>]</div><div class="st300_footnote_body">Because normalized device space is a left-handed system by default, with the viewer looking towards positive Z, and because the transformation from clip space to normalized device space for a given point is the division of the components of that point by the point's own <span class="st300_term expression">w</span> component.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4678_0" href="#st300_fr_4568" title="Jump back to reference 0 of footnote di.coords.ndevice.left">8</a>]</div><div class="st300_footnote_body">The handedness of the coordinate space is dependent on the <a class="st300_link" href="#di.coords.screen.depth">depth range</a> configured for screen space.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4699_0" href="#st300_fr_4628" title="Jump back to reference 0 of footnote di.coords.ndevice.division">9</a>]</div><div class="st300_footnote_body">It is actually the division by <span class="st300_term expression">w</span> that produces the scaling effect necessary to produce the illusion of perspective in perspective projections.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4874_0" href="#st300_fr_2739" title="Jump back to reference 0 of footnote di.coords.whining">10</a>]</div><div class="st300_footnote_body">Almost all rendering systems use different names to refer to the same concepts, without ever bothering to document their conventions. This harms comprehension and generally wastes everybody's time.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_4904_0" href="#st300_fr_3562" title="Jump back to reference 0 of footnote di.coords.minecraft">11</a>]</div><div class="st300_footnote_body">A classic example of a modern game title that failed to anticipate precision issues is <a class="st300_link_external" href="http://minecraft.gamepedia.com/Far_Lands">Minecraft</a>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_5527_0" href="#st300_fr_5254" title="Jump back to reference 0 of footnote di.meshes.failure">12</a>]</div><div class="st300_footnote_body">Naturally, as is standard with OpenGL, failing to associate the correct shader attributes with the correct vertex attributes results in silent failure and/or bizarre visual results.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_6193_0" href="#st300_fr_6170" title="Jump back to reference 0 of footnote di.instances.unit_quad">13</a>]</div><div class="st300_footnote_body">Typically a simple two-polygon <span class="st300_term term">unit quad</span>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_7086_0" href="#st300_fr_6994" title="Jump back to reference 0 of footnote di.shaders.modules.classpath">14</a>]</div><div class="st300_footnote_body">The core of the <span class="st300_term package">r2</span> package depends directly on the shader package, so the correct jars will inevitably be on the classpath already.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_8557_0" href="#st300_fr_7978" title="Jump back to reference 0 of footnote di.lighting.no_ambient">15</a>]</div><div class="st300_footnote_body">The <span class="st300_term package">r2</span> package does not use ambient terms.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_8974_0" href="#st300_fr_8816" title="Jump back to reference 0 of footnote di.lighting.attenuation.geogebra">16</a>]</div><div class="st300_footnote_body">The attenuation function development is available for experimentation in the included <a class="st300_link_external" href="http://geogebra.org">GeoGebra</a> file <a class="st300_link_external" href="attenuation.ggb">attenuation.ggb</a>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_10157_0" href="#st300_fr_10011" title="Jump back to reference 0 of footnote di.lighting.projective.back_clip">17</a>]</div><div class="st300_footnote_body">The same issue occurs when performing ordinary rendering of points in a scene. The issue is solved there by clipping primitives based on their <span class="st300_term expression">w</span> component so that primitives that are "behind" the observer are not rendered.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_13206_0" href="#st300_fr_13046" title="Jump back to reference 0 of footnote di.deferred.geom.ordering.perf">18</a>]</div><div class="st300_footnote_body">For some reason, the presentation does not specify a publication date. However, inspection of the presentation's metadata suggests that it was written in October 2014, so the numbers given are likely for reasonably high-end 2014-era hardware.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_13950_0" href="#st300_fr_13914" title="Jump back to reference 0 of footnote di.deferred.light.depth">19</a>]</div><div class="st300_footnote_body">This is slightly misleading because the depth buffer is a simple heightmap and so of course only the nearest faces of each shape would be preserved by the depth buffer. Nevertheless, for the purposes of comprehension, the full shapes are shown.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_16796_0" href="#st300_fr_16386" title="Jump back to reference 0 of footnote di.deferred-position-recon.matrix-once">20</a>]</div><div class="st300_footnote_body">This step is performed once on the CPU and is only repeated when the projection matrix changes <span class="st300_footnote_reference">[<a href="#st300_f_16818_0" id="st300_fr_16815" title="Jump to footnote di.deferred-position-recon.matrix-change (reference 0)">21</a>]</span>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_16818_0" href="#st300_fr_16815" title="Jump back to reference 0 of footnote di.deferred-position-recon.matrix-change">21</a>]</div><div class="st300_footnote_body">Which, for many applications, may be once for the entire lifetime of the program.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_16834_0" href="#st300_fr_16440" title="Jump back to reference 0 of footnote di.deferred-position-recon.w">22</a>]</div><div class="st300_footnote_body">By simply setting the <span class="st300_term variable">w</span> component to <span class="st300_term constant">1</span>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_16849_0" href="#st300_fr_16655" title="Jump back to reference 0 of footnote di.deferred-position-recon.eye_negative">23</a>]</div><div class="st300_footnote_body">Which is guaranteed to be negative, as only a negative Z value could have resulted in a visible fragment in the geometry buffer.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_18280_0" href="#st300_fr_17736" title="Jump back to reference 0 of footnote di.normal-mapping.tangent-book">24</a>]</div><div class="st300_footnote_body">See section 7.8.3, "Calculating tangent vectors".</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_19245_0" href="#st300_fr_19051" title="Jump back to reference 0 of footnote di.log_depth.love_depth">25</a>]</div><div class="st300_footnote_body">See <a class="st300_link_external" href="http://www.sjbaker.org/steve/omniv/love_your_z_buffer.html">Learning To Love Your Depth Buffer</a>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_19262_0" href="#st300_fr_19224" title="Jump back to reference 0 of footnote di.log_depth.kemen">26</a>]</div><div class="st300_footnote_body">Apparently first discovered by <a class="st300_link_external" href="http://outerra.blogspot.co.uk/2012/11/maximizing-depth-buffer-range-and.html">Brano Kemen</a>.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_22888_0" href="#st300_fr_21699" title="Jump back to reference 0 of footnote di.ssao.application">27</a>]</div><div class="st300_footnote_body">The <span class="st300_term package">r2</span> package provides convenient methods to apply ambient occlusion to lighting, but does not require the programmer to use any particular method.</div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_23404_0" href="#st300_fr_23263" title="Jump back to reference 0 of footnote di.fxaa.whitepaper">28</a>]</div><div class="st300_footnote_body"><a class="st300_link_external" href="http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf">http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf</a></div></div><div class="st300_footnote_container"><div class="st300_footnote_id">[<a id="st300_f_23409_0" href="#st300_fr_23355" title="Jump back to reference 0 of footnote di.fxaa.publicdomain">29</a>]</div><div class="st300_footnote_body">The included <span class="st300_term file">Fxaa3_11.h</span> file bears an NVIDIA copyright, but was placed into the public domain by the original author.</div></div></div></div></body></html>
